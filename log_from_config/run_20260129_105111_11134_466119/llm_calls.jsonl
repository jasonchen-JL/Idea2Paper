{"ts": "2026-01-29T10:55:08.747750+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.3, "max_tokens": 300, "timeout": 180, "prompt": "\nYou are a **CRITICAL Multidimensional Pattern Scorer** for top-tier AI conferences (ICLR/NeurIPS).\nYour task is to rigorously evaluate a research pattern across THREE independent dimensions.\n‚ö†Ô∏è  IMPORTANT: Avoid clustering scores in the middle range. Be discriminative!\n\n„ÄêUser's Research Idea„Äë\n\"Propose the autoregressive image diffusion (AID) model for image sequence generation and apply it to sample the posterior for accelerated MRI reconstruction\"\n\n„ÄêPattern Information„Äë\nPattern ID: pattern_100\nName: Reframing Diffusion Sampling Efficiency\nCluster Size: 148 papers\nRepresentative Research Ideas:\n- Introduce a novel sampling method for diffusion models that significantly reduces the number of steps required while maintaining high sample quality.\n- Extend DDIM to general diffusion models by modifying the score network parameterization for improved sampling efficiency.\n- Introduce efficient samplers for diffusion models using a novel ideal derivative substitution technique to reduce neural function evaluations.\n\n„ÄêReference Examples (for calibration)„Äë\n\nExample 1 - LOW novelty, HIGH stability (Size 150):\n  \"Attention Is All You Need\" application - highly replicated, but well-known approach\n  ‚Üí stability_score: 0.85, novelty_score: 0.15\n\nExample 2 - HIGH novelty, MEDIUM stability (Size 25):\n  \"Reframing task as code generation problem\" - novel angle, but niche community\n  ‚Üí stability_score: 0.35, novelty_score: 0.75\n\nExample 3 - MEDIUM novelty, MEDIUM stability (Size 60):\n  \"Combining RAG with multi-hop reasoning\" - interesting combination, growing adoption\n  ‚Üí stability_score: 0.60, novelty_score: 0.55\n\n\n„ÄêScoring Guidelines - Be CRITICAL and DISCRIMINATIVE„Äë\n\n**Stability Score (0.0-1.0)** - How proven, mature, and widely-adopted?\nConsider: Has this approach been replicated across many papers? Are there established benchmarks?\n- 0.1-0.25: Highly experimental, niche idea, Size < 15, no standard benchmarks, high uncertainty\n- 0.3-0.45: Early-stage research, Size 15-40, some implementations but inconsistent results\n- 0.5-0.65: Maturing approach, Size 40-70, multiple independent implementations, emerging consensus\n- 0.7-0.85: Well-established, Size 70-120, standard benchmarks, widely replicated with consistent gains\n- 0.9-1.0: Foundational/canonical approach, Size > 120, ubiquitous, considered solved or foundational\nüî¥ RED FLAG: Avoid giving middle scores (0.4-0.6) to everything. Distinguish clearly.\n\n**Novelty Score (0.0-1.0)** - How original, counter-intuitive, and fresh is this?\nConsider: Is this a new perspective? Does it challenge existing assumptions? Or incremental variation?\n- 0.1-0.25: Well-trodden path, combinations of existing techniques, straightforward application\n- 0.3-0.45: Some novelty in execution or application domain, but builds on established ideas\n- 0.5-0.65: Interesting recombination or new angle on known problems, moderate originality\n- 0.7-0.85: Novel methodology, surprising insight, challenges conventional wisdom, fresh angle\n- 0.9-1.0: Paradigm shift, highly counter-intuitive, fundamentally new problem formulation\nüî¥ RED FLAG: If pattern_name suggests \"reframing\" or \"transforming\", likely 0.6+. If it's optimization/tuning, likely 0.2-0.4.\n\n**Domain Distance (0.0-1.0)** - How different from user's core idea?\nConsider semantic and methodological distance, not just application domain.\n- 0.0-0.15: Directly addresses same problem, highly relevant methodology\n- 0.2-0.35: Related domain/approach, applicable with minor adaptation\n- 0.4-0.55: Different domain but transferable insights, moderate adaptation needed\n- 0.6-0.8: Orthogonal domain, interesting cross-domain inspirations\n- 0.85-1.0: Completely different field, minimal direct relevance\nüí° TIP: Compare pattern semantics to user idea content for distance.\n\n„ÄêCRITICAL INSTRUCTIONS„Äë\n1. DO NOT give all patterns middle-range scores (0.4-0.6). Spread the distribution.\n2. DISTINGUISH between: optimization (low novelty), new methodology (medium), paradigm shift (high).\n3. Large cluster size (>100) should NOT automatically mean high stability if methodology is flawed.\n4. Small cluster size (<20) should NOT automatically mean low novelty; niche innovation exists.\n\n„ÄêOutput Format - JSON ONLY„Äë\n{\n  \"stability_score\": 0.75,\n  \"novelty_score\": 0.55,\n  \"domain_distance\": 0.25,\n  \"reasoning\": \"Example: Established approach (Size 82), novel reframing angle, same-domain application\"\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 4406}, "response": {"ok": true, "text": "```json\n{\n  \"stability_score\": 0.90,\n  \"novelty_score\": 0.25,\n  \"domain_distance\": 0.10,\n  \"reasoning\": \"The pattern represents a highly mature and crowded research area (Cluster Size 148) focused on optimizing diffusion sampling steps, which is foundational and widely adopted (High Stability). As this is primarily an optimization/tuning task rather than a new paradigm, the novelty is low (Low Novelty). The user's explicit goal to 'sample the posterior' for MRI reconstruction relies directly on these efficient sampling methodologies, making the domain distance minimal (Low Domain Distance).\"\n}\n```", "latency_ms": 15579, "text_truncated": false, "text_len": 604}}}
{"ts": "2026-01-29T10:55:29.055384+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.3, "max_tokens": 300, "timeout": 180, "prompt": "\nYou are a **CRITICAL Multidimensional Pattern Scorer** for top-tier AI conferences (ICLR/NeurIPS).\nYour task is to rigorously evaluate a research pattern across THREE independent dimensions.\n‚ö†Ô∏è  IMPORTANT: Avoid clustering scores in the middle range. Be discriminative!\n\n„ÄêUser's Research Idea„Äë\n\"Propose the autoregressive image diffusion (AID) model for image sequence generation and apply it to sample the posterior for accelerated MRI reconstruction\"\n\n„ÄêPattern Information„Äë\nPattern ID: pattern_115\nName: Semantic Alignment for Compositional Generation\nCluster Size: 107 papers\nRepresentative Research Ideas:\n- Enhance compositional and attribute-binding capabilities in text-to-image synthesis by manipulating cross-attention layers using linguistic structures without additional training.\n- Adapt large vision-language models to score the visualness of text, enhancing text-to-image generation by identifying text that evokes imagery.\n- Integrate edge guidance and contrastive learning to enhance semantic image synthesis by addressing structural detail, semantic consistency, and global semantic relations.\n\n„ÄêReference Examples (for calibration)„Äë\nRecent scoring calibration:\n  pattern_100 (Size 148): stability=0.90, novelty=0.25\n\n„ÄêScoring Guidelines - Be CRITICAL and DISCRIMINATIVE„Äë\n\n**Stability Score (0.0-1.0)** - How proven, mature, and widely-adopted?\nConsider: Has this approach been replicated across many papers? Are there established benchmarks?\n- 0.1-0.25: Highly experimental, niche idea, Size < 15, no standard benchmarks, high uncertainty\n- 0.3-0.45: Early-stage research, Size 15-40, some implementations but inconsistent results\n- 0.5-0.65: Maturing approach, Size 40-70, multiple independent implementations, emerging consensus\n- 0.7-0.85: Well-established, Size 70-120, standard benchmarks, widely replicated with consistent gains\n- 0.9-1.0: Foundational/canonical approach, Size > 120, ubiquitous, considered solved or foundational\nüî¥ RED FLAG: Avoid giving middle scores (0.4-0.6) to everything. Distinguish clearly.\n\n**Novelty Score (0.0-1.0)** - How original, counter-intuitive, and fresh is this?\nConsider: Is this a new perspective? Does it challenge existing assumptions? Or incremental variation?\n- 0.1-0.25: Well-trodden path, combinations of existing techniques, straightforward application\n- 0.3-0.45: Some novelty in execution or application domain, but builds on established ideas\n- 0.5-0.65: Interesting recombination or new angle on known problems, moderate originality\n- 0.7-0.85: Novel methodology, surprising insight, challenges conventional wisdom, fresh angle\n- 0.9-1.0: Paradigm shift, highly counter-intuitive, fundamentally new problem formulation\nüî¥ RED FLAG: If pattern_name suggests \"reframing\" or \"transforming\", likely 0.6+. If it's optimization/tuning, likely 0.2-0.4.\n\n**Domain Distance (0.0-1.0)** - How different from user's core idea?\nConsider semantic and methodological distance, not just application domain.\n- 0.0-0.15: Directly addresses same problem, highly relevant methodology\n- 0.2-0.35: Related domain/approach, applicable with minor adaptation\n- 0.4-0.55: Different domain but transferable insights, moderate adaptation needed\n- 0.6-0.8: Orthogonal domain, interesting cross-domain inspirations\n- 0.85-1.0: Completely different field, minimal direct relevance\nüí° TIP: Compare pattern semantics to user idea content for distance.\n\n„ÄêCRITICAL INSTRUCTIONS„Äë\n1. DO NOT give all patterns middle-range scores (0.4-0.6). Spread the distribution.\n2. DISTINGUISH between: optimization (low novelty), new methodology (medium), paradigm shift (high).\n3. Large cluster size (>100) should NOT automatically mean high stability if methodology is flawed.\n4. Small cluster size (<20) should NOT automatically mean low novelty; niche innovation exists.\n\n„ÄêOutput Format - JSON ONLY„Äë\n{\n  \"stability_score\": 0.75,\n  \"novelty_score\": 0.55,\n  \"domain_distance\": 0.25,\n  \"reasoning\": \"Example: Established approach (Size 82), novel reframing angle, same-domain application\"\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 4015}, "response": {"ok": true, "text": "```json\n{\n  \"stability_score\": 0.80,\n  \"novelty_score\": 0.35,\n  \"domain_distance\": 0.55,\n  \"reasoning\": \"Pattern represents a well-established research direction in generative AI (Size 107) focusing on text-to-image refinement, resulting in high stability. The novelty is moderate-to-low as it primarily involves incremental improvements to cross-attention and guidance mechanisms rather than a fundamental paradigm shift. There is significant domain distance (0.55) because the user's focus is on MRI reconstruction (an inverse problem involving physical constraints and posterior sampling), whereas the pattern focuses on semantic alignment and compositional generation in artistic text-to-image tasks; while both use generative models, the objectives (semantic fidelity vs. measurement consistency) and methodologies (text-guidance vs. autoregressive sampling) differ substantially.\"\n}\n```", "latency_ms": 20306, "text_truncated": false, "text_len": 892}}}
{"ts": "2026-01-29T10:55:50.096358+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.3, "max_tokens": 300, "timeout": 180, "prompt": "\nYou are a **CRITICAL Multidimensional Pattern Scorer** for top-tier AI conferences (ICLR/NeurIPS).\nYour task is to rigorously evaluate a research pattern across THREE independent dimensions.\n‚ö†Ô∏è  IMPORTANT: Avoid clustering scores in the middle range. Be discriminative!\n\n„ÄêUser's Research Idea„Äë\n\"Propose the autoregressive image diffusion (AID) model for image sequence generation and apply it to sample the posterior for accelerated MRI reconstruction\"\n\n„ÄêPattern Information„Äë\nPattern ID: pattern_102\nName: Text to 3D generation robustness\nCluster Size: 50 papers\nRepresentative Research Ideas:\n- Utilize pretrained 2D text-to-image diffusion models to enable text-to-3D synthesis without requiring 3D training data.\n- Utilize pure CLIP guidance for text to 3D object generation, enhancing coherence and efficiency through model ensembling and implicit voxel grid regularization.\n- Introduce a method for generating furniture layouts with fine-grained control through attribute-level conditioning, enhancing flexibility and realism in virtual environments.\n\n„ÄêReference Examples (for calibration)„Äë\nRecent scoring calibration:\n  pattern_100 (Size 148): stability=0.90, novelty=0.25\n  pattern_115 (Size 107): stability=0.80, novelty=0.35\n\n„ÄêScoring Guidelines - Be CRITICAL and DISCRIMINATIVE„Äë\n\n**Stability Score (0.0-1.0)** - How proven, mature, and widely-adopted?\nConsider: Has this approach been replicated across many papers? Are there established benchmarks?\n- 0.1-0.25: Highly experimental, niche idea, Size < 15, no standard benchmarks, high uncertainty\n- 0.3-0.45: Early-stage research, Size 15-40, some implementations but inconsistent results\n- 0.5-0.65: Maturing approach, Size 40-70, multiple independent implementations, emerging consensus\n- 0.7-0.85: Well-established, Size 70-120, standard benchmarks, widely replicated with consistent gains\n- 0.9-1.0: Foundational/canonical approach, Size > 120, ubiquitous, considered solved or foundational\nüî¥ RED FLAG: Avoid giving middle scores (0.4-0.6) to everything. Distinguish clearly.\n\n**Novelty Score (0.0-1.0)** - How original, counter-intuitive, and fresh is this?\nConsider: Is this a new perspective? Does it challenge existing assumptions? Or incremental variation?\n- 0.1-0.25: Well-trodden path, combinations of existing techniques, straightforward application\n- 0.3-0.45: Some novelty in execution or application domain, but builds on established ideas\n- 0.5-0.65: Interesting recombination or new angle on known problems, moderate originality\n- 0.7-0.85: Novel methodology, surprising insight, challenges conventional wisdom, fresh angle\n- 0.9-1.0: Paradigm shift, highly counter-intuitive, fundamentally new problem formulation\nüî¥ RED FLAG: If pattern_name suggests \"reframing\" or \"transforming\", likely 0.6+. If it's optimization/tuning, likely 0.2-0.4.\n\n**Domain Distance (0.0-1.0)** - How different from user's core idea?\nConsider semantic and methodological distance, not just application domain.\n- 0.0-0.15: Directly addresses same problem, highly relevant methodology\n- 0.2-0.35: Related domain/approach, applicable with minor adaptation\n- 0.4-0.55: Different domain but transferable insights, moderate adaptation needed\n- 0.6-0.8: Orthogonal domain, interesting cross-domain inspirations\n- 0.85-1.0: Completely different field, minimal direct relevance\nüí° TIP: Compare pattern semantics to user idea content for distance.\n\n„ÄêCRITICAL INSTRUCTIONS„Äë\n1. DO NOT give all patterns middle-range scores (0.4-0.6). Spread the distribution.\n2. DISTINGUISH between: optimization (low novelty), new methodology (medium), paradigm shift (high).\n3. Large cluster size (>100) should NOT automatically mean high stability if methodology is flawed.\n4. Small cluster size (<20) should NOT automatically mean low novelty; niche innovation exists.\n\n„ÄêOutput Format - JSON ONLY„Äë\n{\n  \"stability_score\": 0.75,\n  \"novelty_score\": 0.55,\n  \"domain_distance\": 0.25,\n  \"reasoning\": \"Example: Established approach (Size 82), novel reframing angle, same-domain application\"\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 4015}, "response": {"ok": true, "text": "```json\n{\n  \"stability_score\": 0.65,\n  \"novelty_score\": 0.45,\n  \"domain_distance\": 0.75,\n  \"reasoning\": \"The pattern (Text-to-3D) represents a maturing sub-field with a solid cluster size (50), fitting the 0.5-0.65 stability range, though it lacks the ubiquity of foundational methods. Novelty is moderate (0.45) as the field has moved past the initial paradigm shift (DreamFusion) into refining robustness and consistency. Domain distance is high (0.75) because the user's focus on MRI reconstruction (inverse problems, medical physics) and autoregressive sequences is methodologically and semantically distinct from Text-to-3D generation (computer graphics, CLIP guidance), sharing only the broad tool of diffusion models.\"\n}\n```", "latency_ms": 21039, "text_truncated": false, "text_len": 731}}}
{"ts": "2026-01-29T10:56:08.613600+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.3, "max_tokens": 300, "timeout": 180, "prompt": "\nYou are a **CRITICAL Multidimensional Pattern Scorer** for top-tier AI conferences (ICLR/NeurIPS).\nYour task is to rigorously evaluate a research pattern across THREE independent dimensions.\n‚ö†Ô∏è  IMPORTANT: Avoid clustering scores in the middle range. Be discriminative!\n\n„ÄêUser's Research Idea„Äë\n\"Propose the autoregressive image diffusion (AID) model for image sequence generation and apply it to sample the posterior for accelerated MRI reconstruction\"\n\n„ÄêPattern Information„Äë\nPattern ID: pattern_49\nName: Reframing Inverse Problems with Diffusion\nCluster Size: 15 papers\nRepresentative Research Ideas:\n- Introduce a method to enhance problem-agnostic diffusion models for inverse problems by directly estimating conditional scores from measurement models without additional training.\n- Extend diffusion models to handle structured noise in inverse problems through joint conditional reverse diffusion processes.\n- Extend diffusion models to handle noisy nonlinear inverse problems using a Laplace approximation for posterior sampling.\n\n„ÄêReference Examples (for calibration)„Äë\nRecent scoring calibration:\n  pattern_100 (Size 148): stability=0.90, novelty=0.25\n  pattern_115 (Size 107): stability=0.80, novelty=0.35\n  pattern_102 (Size 50): stability=0.65, novelty=0.45\n\n„ÄêScoring Guidelines - Be CRITICAL and DISCRIMINATIVE„Äë\n\n**Stability Score (0.0-1.0)** - How proven, mature, and widely-adopted?\nConsider: Has this approach been replicated across many papers? Are there established benchmarks?\n- 0.1-0.25: Highly experimental, niche idea, Size < 15, no standard benchmarks, high uncertainty\n- 0.3-0.45: Early-stage research, Size 15-40, some implementations but inconsistent results\n- 0.5-0.65: Maturing approach, Size 40-70, multiple independent implementations, emerging consensus\n- 0.7-0.85: Well-established, Size 70-120, standard benchmarks, widely replicated with consistent gains\n- 0.9-1.0: Foundational/canonical approach, Size > 120, ubiquitous, considered solved or foundational\nüî¥ RED FLAG: Avoid giving middle scores (0.4-0.6) to everything. Distinguish clearly.\n\n**Novelty Score (0.0-1.0)** - How original, counter-intuitive, and fresh is this?\nConsider: Is this a new perspective? Does it challenge existing assumptions? Or incremental variation?\n- 0.1-0.25: Well-trodden path, combinations of existing techniques, straightforward application\n- 0.3-0.45: Some novelty in execution or application domain, but builds on established ideas\n- 0.5-0.65: Interesting recombination or new angle on known problems, moderate originality\n- 0.7-0.85: Novel methodology, surprising insight, challenges conventional wisdom, fresh angle\n- 0.9-1.0: Paradigm shift, highly counter-intuitive, fundamentally new problem formulation\nüî¥ RED FLAG: If pattern_name suggests \"reframing\" or \"transforming\", likely 0.6+. If it's optimization/tuning, likely 0.2-0.4.\n\n**Domain Distance (0.0-1.0)** - How different from user's core idea?\nConsider semantic and methodological distance, not just application domain.\n- 0.0-0.15: Directly addresses same problem, highly relevant methodology\n- 0.2-0.35: Related domain/approach, applicable with minor adaptation\n- 0.4-0.55: Different domain but transferable insights, moderate adaptation needed\n- 0.6-0.8: Orthogonal domain, interesting cross-domain inspirations\n- 0.85-1.0: Completely different field, minimal direct relevance\nüí° TIP: Compare pattern semantics to user idea content for distance.\n\n„ÄêCRITICAL INSTRUCTIONS„Äë\n1. DO NOT give all patterns middle-range scores (0.4-0.6). Spread the distribution.\n2. DISTINGUISH between: optimization (low novelty), new methodology (medium), paradigm shift (high).\n3. Large cluster size (>100) should NOT automatically mean high stability if methodology is flawed.\n4. Small cluster size (<20) should NOT automatically mean low novelty; niche innovation exists.\n\n„ÄêOutput Format - JSON ONLY„Äë\n{\n  \"stability_score\": 0.75,\n  \"novelty_score\": 0.55,\n  \"domain_distance\": 0.25,\n  \"reasoning\": \"Example: Established approach (Size 82), novel reframing angle, same-domain application\"\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 4048}, "response": {"ok": true, "text": "```json\n{\n  \"stability_score\": 0.35,\n  \"novelty_score\": 0.70,\n  \"domain_distance\": 0.10,\n  \"reasoning\": \"The pattern represents an early-stage but specific methodological shift (Cluster Size 15), placing it at the lower end of early-stage research stability. The 'Reframing' in the name and the focus on posterior sampling via Laplace approximation or conditional scores indicate a high degree of novelty (0.70), distinct from standard denoising applications. The user's proposal for MRI reconstruction using diffusion for posterior sampling is a direct application of this pattern, resulting in a very low domain distance (0.10).\"\n}\n```", "latency_ms": 18516, "text_truncated": false, "text_len": 637}}}
{"ts": "2026-01-29T10:56:35.798292+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.3, "max_tokens": 300, "timeout": 180, "prompt": "\nYou are a **CRITICAL Multidimensional Pattern Scorer** for top-tier AI conferences (ICLR/NeurIPS).\nYour task is to rigorously evaluate a research pattern across THREE independent dimensions.\n‚ö†Ô∏è  IMPORTANT: Avoid clustering scores in the middle range. Be discriminative!\n\n„ÄêUser's Research Idea„Äë\n\"Propose the autoregressive image diffusion (AID) model for image sequence generation and apply it to sample the posterior for accelerated MRI reconstruction\"\n\n„ÄêPattern Information„Äë\nPattern ID: pattern_114\nName: Reframing Video Generation Challenges\nCluster Size: 44 papers\nRepresentative Research Ideas:\n- Leverage a pretrained text-to-image model to efficiently train a large-scale text-to-video generation model, enhancing performance and reducing training costs.\n- Introduce a video transformer model that leverages vector-quantized latent dynamics for efficient long-term video prediction with improved temporal consistency.\n- Enhance video generation by integrating advanced spatial-temporal operations and a unified ControlNet model for diverse conditions.\n\n„ÄêReference Examples (for calibration)„Äë\nRecent scoring calibration:\n  pattern_100 (Size 148): stability=0.90, novelty=0.25\n  pattern_115 (Size 107): stability=0.80, novelty=0.35\n  pattern_102 (Size 50): stability=0.65, novelty=0.45\n\n„ÄêScoring Guidelines - Be CRITICAL and DISCRIMINATIVE„Äë\n\n**Stability Score (0.0-1.0)** - How proven, mature, and widely-adopted?\nConsider: Has this approach been replicated across many papers? Are there established benchmarks?\n- 0.1-0.25: Highly experimental, niche idea, Size < 15, no standard benchmarks, high uncertainty\n- 0.3-0.45: Early-stage research, Size 15-40, some implementations but inconsistent results\n- 0.5-0.65: Maturing approach, Size 40-70, multiple independent implementations, emerging consensus\n- 0.7-0.85: Well-established, Size 70-120, standard benchmarks, widely replicated with consistent gains\n- 0.9-1.0: Foundational/canonical approach, Size > 120, ubiquitous, considered solved or foundational\nüî¥ RED FLAG: Avoid giving middle scores (0.4-0.6) to everything. Distinguish clearly.\n\n**Novelty Score (0.0-1.0)** - How original, counter-intuitive, and fresh is this?\nConsider: Is this a new perspective? Does it challenge existing assumptions? Or incremental variation?\n- 0.1-0.25: Well-trodden path, combinations of existing techniques, straightforward application\n- 0.3-0.45: Some novelty in execution or application domain, but builds on established ideas\n- 0.5-0.65: Interesting recombination or new angle on known problems, moderate originality\n- 0.7-0.85: Novel methodology, surprising insight, challenges conventional wisdom, fresh angle\n- 0.9-1.0: Paradigm shift, highly counter-intuitive, fundamentally new problem formulation\nüî¥ RED FLAG: If pattern_name suggests \"reframing\" or \"transforming\", likely 0.6+. If it's optimization/tuning, likely 0.2-0.4.\n\n**Domain Distance (0.0-1.0)** - How different from user's core idea?\nConsider semantic and methodological distance, not just application domain.\n- 0.0-0.15: Directly addresses same problem, highly relevant methodology\n- 0.2-0.35: Related domain/approach, applicable with minor adaptation\n- 0.4-0.55: Different domain but transferable insights, moderate adaptation needed\n- 0.6-0.8: Orthogonal domain, interesting cross-domain inspirations\n- 0.85-1.0: Completely different field, minimal direct relevance\nüí° TIP: Compare pattern semantics to user idea content for distance.\n\n„ÄêCRITICAL INSTRUCTIONS„Äë\n1. DO NOT give all patterns middle-range scores (0.4-0.6). Spread the distribution.\n2. DISTINGUISH between: optimization (low novelty), new methodology (medium), paradigm shift (high).\n3. Large cluster size (>100) should NOT automatically mean high stability if methodology is flawed.\n4. Small cluster size (<20) should NOT automatically mean low novelty; niche innovation exists.\n\n„ÄêOutput Format - JSON ONLY„Äë\n{\n  \"stability_score\": 0.75,\n  \"novelty_score\": 0.55,\n  \"domain_distance\": 0.25,\n  \"reasoning\": \"Example: Established approach (Size 82), novel reframing angle, same-domain application\"\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 4071}, "response": {"ok": true, "text": "```json\n{\n  \"stability_score\": 0.55,\n  \"novelty_score\": 0.70,\n  \"domain_distance\": 0.10,\n  \"reasoning\": \"Cluster size 44 indicates a maturing approach but not yet canonical (Size 40-70). The pattern focuses on 'reframing' video generation, representing a novel methodological shift (Diffusion/Transformers) challenging older temporal modeling paradigms. The user's task of 'image sequence generation' maps directly to the pattern's core (video generation), resulting in minimal domain distance.\"\n}\n```", "latency_ms": 27183, "text_truncated": false, "text_len": 501}}}
{"ts": "2026-01-29T10:56:50.259392+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.3, "max_tokens": 300, "timeout": 180, "prompt": "\nYou are a **CRITICAL Multidimensional Pattern Scorer** for top-tier AI conferences (ICLR/NeurIPS).\nYour task is to rigorously evaluate a research pattern across THREE independent dimensions.\n‚ö†Ô∏è  IMPORTANT: Avoid clustering scores in the middle range. Be discriminative!\n\n„ÄêUser's Research Idea„Äë\n\"Propose the autoregressive image diffusion (AID) model for image sequence generation and apply it to sample the posterior for accelerated MRI reconstruction\"\n\n„ÄêPattern Information„Äë\nPattern ID: pattern_57\nName: Preference Alignment Through Distributional Modeling\nCluster Size: 111 papers\nRepresentative Research Ideas:\n- Address overoptimization in composite reward models by using constrained reinforcement learning to dynamically adjust weights, maintaining effectiveness as proxies for human evaluation.\n- Introduce fine-grained quality signals to improve alignment of large language models with human preferences beyond imitation learning.\n- Introduce Statistical Rejection Sampling Optimization to enhance preference data sourcing, improving the estimation of optimal policies in language models.\n\n„ÄêReference Examples (for calibration)„Äë\nRecent scoring calibration:\n  pattern_100 (Size 148): stability=0.90, novelty=0.25\n  pattern_115 (Size 107): stability=0.80, novelty=0.35\n  pattern_102 (Size 50): stability=0.65, novelty=0.45\n\n„ÄêScoring Guidelines - Be CRITICAL and DISCRIMINATIVE„Äë\n\n**Stability Score (0.0-1.0)** - How proven, mature, and widely-adopted?\nConsider: Has this approach been replicated across many papers? Are there established benchmarks?\n- 0.1-0.25: Highly experimental, niche idea, Size < 15, no standard benchmarks, high uncertainty\n- 0.3-0.45: Early-stage research, Size 15-40, some implementations but inconsistent results\n- 0.5-0.65: Maturing approach, Size 40-70, multiple independent implementations, emerging consensus\n- 0.7-0.85: Well-established, Size 70-120, standard benchmarks, widely replicated with consistent gains\n- 0.9-1.0: Foundational/canonical approach, Size > 120, ubiquitous, considered solved or foundational\nüî¥ RED FLAG: Avoid giving middle scores (0.4-0.6) to everything. Distinguish clearly.\n\n**Novelty Score (0.0-1.0)** - How original, counter-intuitive, and fresh is this?\nConsider: Is this a new perspective? Does it challenge existing assumptions? Or incremental variation?\n- 0.1-0.25: Well-trodden path, combinations of existing techniques, straightforward application\n- 0.3-0.45: Some novelty in execution or application domain, but builds on established ideas\n- 0.5-0.65: Interesting recombination or new angle on known problems, moderate originality\n- 0.7-0.85: Novel methodology, surprising insight, challenges conventional wisdom, fresh angle\n- 0.9-1.0: Paradigm shift, highly counter-intuitive, fundamentally new problem formulation\nüî¥ RED FLAG: If pattern_name suggests \"reframing\" or \"transforming\", likely 0.6+. If it's optimization/tuning, likely 0.2-0.4.\n\n**Domain Distance (0.0-1.0)** - How different from user's core idea?\nConsider semantic and methodological distance, not just application domain.\n- 0.0-0.15: Directly addresses same problem, highly relevant methodology\n- 0.2-0.35: Related domain/approach, applicable with minor adaptation\n- 0.4-0.55: Different domain but transferable insights, moderate adaptation needed\n- 0.6-0.8: Orthogonal domain, interesting cross-domain inspirations\n- 0.85-1.0: Completely different field, minimal direct relevance\nüí° TIP: Compare pattern semantics to user idea content for distance.\n\n„ÄêCRITICAL INSTRUCTIONS„Äë\n1. DO NOT give all patterns middle-range scores (0.4-0.6). Spread the distribution.\n2. DISTINGUISH between: optimization (low novelty), new methodology (medium), paradigm shift (high).\n3. Large cluster size (>100) should NOT automatically mean high stability if methodology is flawed.\n4. Small cluster size (<20) should NOT automatically mean low novelty; niche innovation exists.\n\n„ÄêOutput Format - JSON ONLY„Äë\n{\n  \"stability_score\": 0.75,\n  \"novelty_score\": 0.55,\n  \"domain_distance\": 0.25,\n  \"reasoning\": \"Example: Established approach (Size 82), novel reframing angle, same-domain application\"\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 4110}, "response": {"ok": true, "text": "```json\n{\n  \"stability_score\": 0.80,\n  \"novelty_score\": 0.30,\n  \"domain_distance\": 0.85,\n  \"reasoning\": \"The pattern represents a well-established cluster (Size 111) in the LLM alignment field, focusing on standard RLHF refinements like constrained RL and rejection sampling (High Stability). The ideas are largely incremental optimizations of existing preference learning pipelines rather than paradigm shifts (Low Novelty). There is a significant semantic and methodological gap between the user's work on generative diffusion for MRI reconstruction and this pattern's focus on reinforcement learning for human preference alignment in text (High Domain Distance).\"\n}\n```", "latency_ms": 14460, "text_truncated": false, "text_len": 672}}}
{"ts": "2026-01-29T10:57:14.465962+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.3, "max_tokens": 300, "timeout": 180, "prompt": "\nYou are a **CRITICAL Multidimensional Pattern Scorer** for top-tier AI conferences (ICLR/NeurIPS).\nYour task is to rigorously evaluate a research pattern across THREE independent dimensions.\n‚ö†Ô∏è  IMPORTANT: Avoid clustering scores in the middle range. Be discriminative!\n\n„ÄêUser's Research Idea„Äë\n\"Propose the autoregressive image diffusion (AID) model for image sequence generation and apply it to sample the posterior for accelerated MRI reconstruction\"\n\n„ÄêPattern Information„Äë\nPattern ID: pattern_94\nName: Reframing Generation Through Multi-Feature Integration\nCluster Size: 34 papers\nRepresentative Research Ideas:\n- Utilize StyleGAN2 to generate more natural talking face animations by integrating diverse feature sets beyond audio cues.\n- Enhance the generalizability and fidelity of NeRF-based 3D talking face synthesis by leveraging a large lip-reading corpus and domain adaptive techniques.\n- Adapt diffusion models for human motion generation by predicting samples directly, enabling the use of geometric losses for improved expressiveness and quality.\n\n„ÄêReference Examples (for calibration)„Äë\nRecent scoring calibration:\n  pattern_100 (Size 148): stability=0.90, novelty=0.25\n  pattern_115 (Size 107): stability=0.80, novelty=0.35\n  pattern_102 (Size 50): stability=0.65, novelty=0.45\n\n„ÄêScoring Guidelines - Be CRITICAL and DISCRIMINATIVE„Äë\n\n**Stability Score (0.0-1.0)** - How proven, mature, and widely-adopted?\nConsider: Has this approach been replicated across many papers? Are there established benchmarks?\n- 0.1-0.25: Highly experimental, niche idea, Size < 15, no standard benchmarks, high uncertainty\n- 0.3-0.45: Early-stage research, Size 15-40, some implementations but inconsistent results\n- 0.5-0.65: Maturing approach, Size 40-70, multiple independent implementations, emerging consensus\n- 0.7-0.85: Well-established, Size 70-120, standard benchmarks, widely replicated with consistent gains\n- 0.9-1.0: Foundational/canonical approach, Size > 120, ubiquitous, considered solved or foundational\nüî¥ RED FLAG: Avoid giving middle scores (0.4-0.6) to everything. Distinguish clearly.\n\n**Novelty Score (0.0-1.0)** - How original, counter-intuitive, and fresh is this?\nConsider: Is this a new perspective? Does it challenge existing assumptions? Or incremental variation?\n- 0.1-0.25: Well-trodden path, combinations of existing techniques, straightforward application\n- 0.3-0.45: Some novelty in execution or application domain, but builds on established ideas\n- 0.5-0.65: Interesting recombination or new angle on known problems, moderate originality\n- 0.7-0.85: Novel methodology, surprising insight, challenges conventional wisdom, fresh angle\n- 0.9-1.0: Paradigm shift, highly counter-intuitive, fundamentally new problem formulation\nüî¥ RED FLAG: If pattern_name suggests \"reframing\" or \"transforming\", likely 0.6+. If it's optimization/tuning, likely 0.2-0.4.\n\n**Domain Distance (0.0-1.0)** - How different from user's core idea?\nConsider semantic and methodological distance, not just application domain.\n- 0.0-0.15: Directly addresses same problem, highly relevant methodology\n- 0.2-0.35: Related domain/approach, applicable with minor adaptation\n- 0.4-0.55: Different domain but transferable insights, moderate adaptation needed\n- 0.6-0.8: Orthogonal domain, interesting cross-domain inspirations\n- 0.85-1.0: Completely different field, minimal direct relevance\nüí° TIP: Compare pattern semantics to user idea content for distance.\n\n„ÄêCRITICAL INSTRUCTIONS„Äë\n1. DO NOT give all patterns middle-range scores (0.4-0.6). Spread the distribution.\n2. DISTINGUISH between: optimization (low novelty), new methodology (medium), paradigm shift (high).\n3. Large cluster size (>100) should NOT automatically mean high stability if methodology is flawed.\n4. Small cluster size (<20) should NOT automatically mean low novelty; niche innovation exists.\n\n„ÄêOutput Format - JSON ONLY„Äë\n{\n  \"stability_score\": 0.75,\n  \"novelty_score\": 0.55,\n  \"domain_distance\": 0.25,\n  \"reasoning\": \"Example: Established approach (Size 82), novel reframing angle, same-domain application\"\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 4072}, "response": {"ok": true, "text": "```json\n{\n  \"stability_score\": 0.35,\n  \"novelty_score\": 0.65,\n  \"domain_distance\": 0.30,\n  \"reasoning\": \"Cluster size 34 places this in the early-stage research bracket (0.3-0.45). The pattern explicitly involves 'reframing' generative models by integrating auxiliary features (e.g., audio, geometry), which the guidelines flag for higher novelty scores (0.6+). While the user's MRI application differs from the pattern's computer vision focus (faces/motion), the underlying methodology of conditioning generative models on multi-feature inputs for inverse problems is highly transferable with moderate adaptation.\"\n}\n```", "latency_ms": 24205, "text_truncated": false, "text_len": 621}}}
{"ts": "2026-01-29T10:57:31.132520+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.3, "max_tokens": 300, "timeout": 180, "prompt": "\nYou are a **CRITICAL Multidimensional Pattern Scorer** for top-tier AI conferences (ICLR/NeurIPS).\nYour task is to rigorously evaluate a research pattern across THREE independent dimensions.\n‚ö†Ô∏è  IMPORTANT: Avoid clustering scores in the middle range. Be discriminative!\n\n„ÄêUser's Research Idea„Äë\n\"Propose the autoregressive image diffusion (AID) model for image sequence generation and apply it to sample the posterior for accelerated MRI reconstruction\"\n\n„ÄêPattern Information„Äë\nPattern ID: pattern_68\nName: Language Model Driven Planning Paradigms\nCluster Size: 20 papers\nRepresentative Research Ideas:\n- Leverage large language models to extend their capabilities into symbolic reasoning for automated planning across diverse domains.\n- Introduce an adaptive search method that dynamically adjusts planning horizons using subgoal generation and verification to improve efficiency in complex reasoning tasks.\n- Integrate commonsense knowledge into procedural planning by using neuro-symbolic methods to improve generalization in large language models.\n\n„ÄêReference Examples (for calibration)„Äë\nRecent scoring calibration:\n  pattern_100 (Size 148): stability=0.90, novelty=0.25\n  pattern_115 (Size 107): stability=0.80, novelty=0.35\n  pattern_102 (Size 50): stability=0.65, novelty=0.45\n\n„ÄêScoring Guidelines - Be CRITICAL and DISCRIMINATIVE„Äë\n\n**Stability Score (0.0-1.0)** - How proven, mature, and widely-adopted?\nConsider: Has this approach been replicated across many papers? Are there established benchmarks?\n- 0.1-0.25: Highly experimental, niche idea, Size < 15, no standard benchmarks, high uncertainty\n- 0.3-0.45: Early-stage research, Size 15-40, some implementations but inconsistent results\n- 0.5-0.65: Maturing approach, Size 40-70, multiple independent implementations, emerging consensus\n- 0.7-0.85: Well-established, Size 70-120, standard benchmarks, widely replicated with consistent gains\n- 0.9-1.0: Foundational/canonical approach, Size > 120, ubiquitous, considered solved or foundational\nüî¥ RED FLAG: Avoid giving middle scores (0.4-0.6) to everything. Distinguish clearly.\n\n**Novelty Score (0.0-1.0)** - How original, counter-intuitive, and fresh is this?\nConsider: Is this a new perspective? Does it challenge existing assumptions? Or incremental variation?\n- 0.1-0.25: Well-trodden path, combinations of existing techniques, straightforward application\n- 0.3-0.45: Some novelty in execution or application domain, but builds on established ideas\n- 0.5-0.65: Interesting recombination or new angle on known problems, moderate originality\n- 0.7-0.85: Novel methodology, surprising insight, challenges conventional wisdom, fresh angle\n- 0.9-1.0: Paradigm shift, highly counter-intuitive, fundamentally new problem formulation\nüî¥ RED FLAG: If pattern_name suggests \"reframing\" or \"transforming\", likely 0.6+. If it's optimization/tuning, likely 0.2-0.4.\n\n**Domain Distance (0.0-1.0)** - How different from user's core idea?\nConsider semantic and methodological distance, not just application domain.\n- 0.0-0.15: Directly addresses same problem, highly relevant methodology\n- 0.2-0.35: Related domain/approach, applicable with minor adaptation\n- 0.4-0.55: Different domain but transferable insights, moderate adaptation needed\n- 0.6-0.8: Orthogonal domain, interesting cross-domain inspirations\n- 0.85-1.0: Completely different field, minimal direct relevance\nüí° TIP: Compare pattern semantics to user idea content for distance.\n\n„ÄêCRITICAL INSTRUCTIONS„Äë\n1. DO NOT give all patterns middle-range scores (0.4-0.6). Spread the distribution.\n2. DISTINGUISH between: optimization (low novelty), new methodology (medium), paradigm shift (high).\n3. Large cluster size (>100) should NOT automatically mean high stability if methodology is flawed.\n4. Small cluster size (<20) should NOT automatically mean low novelty; niche innovation exists.\n\n„ÄêOutput Format - JSON ONLY„Äë\n{\n  \"stability_score\": 0.75,\n  \"novelty_score\": 0.55,\n  \"domain_distance\": 0.25,\n  \"reasoning\": \"Example: Established approach (Size 82), novel reframing angle, same-domain application\"\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 4063}, "response": {"ok": true, "text": "```json\n{\n  \"stability_score\": 0.35,\n  \"novelty_score\": 0.55,\n  \"domain_distance\": 0.75,\n  \"reasoning\": \"Early-stage research (Size 20) with inconsistent implementations in applying LLMs to symbolic planning; moderate novelty in bridging neural and symbolic reasoning for automated tasks; high domain distance as the user focuses on continuous generative modeling (Diffusion/MRI), whereas the pattern deals with discrete symbolic reasoning and NLP-based planning.\"\n}\n```", "latency_ms": 16665, "text_truncated": false, "text_len": 470}}}
{"ts": "2026-01-29T10:58:01.077066+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.3, "max_tokens": 300, "timeout": 180, "prompt": "\nYou are a **CRITICAL Multidimensional Pattern Scorer** for top-tier AI conferences (ICLR/NeurIPS).\nYour task is to rigorously evaluate a research pattern across THREE independent dimensions.\n‚ö†Ô∏è  IMPORTANT: Avoid clustering scores in the middle range. Be discriminative!\n\n„ÄêUser's Research Idea„Äë\n\"Propose the autoregressive image diffusion (AID) model for image sequence generation and apply it to sample the posterior for accelerated MRI reconstruction\"\n\n„ÄêPattern Information„Äë\nPattern ID: pattern_7\nName: Reframing Audio Understanding Through Multimodal and Probabilistic Learning\nCluster Size: 41 papers\nRepresentative Research Ideas:\n- Integrate Bayesian neural networks into probabilistic modeling to enhance unsupervised signal separation.\n- Utilize visual modality and noise invariant training to achieve text-queried sound separation using only noisy unlabeled videos.\n- Develop an auto-regressive model to generate high-fidelity audio samples conditioned on text inputs, overcoming challenges of source separation and data scarcity.\n\n„ÄêReference Examples (for calibration)„Äë\nRecent scoring calibration:\n  pattern_100 (Size 148): stability=0.90, novelty=0.25\n  pattern_115 (Size 107): stability=0.80, novelty=0.35\n  pattern_102 (Size 50): stability=0.65, novelty=0.45\n\n„ÄêScoring Guidelines - Be CRITICAL and DISCRIMINATIVE„Äë\n\n**Stability Score (0.0-1.0)** - How proven, mature, and widely-adopted?\nConsider: Has this approach been replicated across many papers? Are there established benchmarks?\n- 0.1-0.25: Highly experimental, niche idea, Size < 15, no standard benchmarks, high uncertainty\n- 0.3-0.45: Early-stage research, Size 15-40, some implementations but inconsistent results\n- 0.5-0.65: Maturing approach, Size 40-70, multiple independent implementations, emerging consensus\n- 0.7-0.85: Well-established, Size 70-120, standard benchmarks, widely replicated with consistent gains\n- 0.9-1.0: Foundational/canonical approach, Size > 120, ubiquitous, considered solved or foundational\nüî¥ RED FLAG: Avoid giving middle scores (0.4-0.6) to everything. Distinguish clearly.\n\n**Novelty Score (0.0-1.0)** - How original, counter-intuitive, and fresh is this?\nConsider: Is this a new perspective? Does it challenge existing assumptions? Or incremental variation?\n- 0.1-0.25: Well-trodden path, combinations of existing techniques, straightforward application\n- 0.3-0.45: Some novelty in execution or application domain, but builds on established ideas\n- 0.5-0.65: Interesting recombination or new angle on known problems, moderate originality\n- 0.7-0.85: Novel methodology, surprising insight, challenges conventional wisdom, fresh angle\n- 0.9-1.0: Paradigm shift, highly counter-intuitive, fundamentally new problem formulation\nüî¥ RED FLAG: If pattern_name suggests \"reframing\" or \"transforming\", likely 0.6+. If it's optimization/tuning, likely 0.2-0.4.\n\n**Domain Distance (0.0-1.0)** - How different from user's core idea?\nConsider semantic and methodological distance, not just application domain.\n- 0.0-0.15: Directly addresses same problem, highly relevant methodology\n- 0.2-0.35: Related domain/approach, applicable with minor adaptation\n- 0.4-0.55: Different domain but transferable insights, moderate adaptation needed\n- 0.6-0.8: Orthogonal domain, interesting cross-domain inspirations\n- 0.85-1.0: Completely different field, minimal direct relevance\nüí° TIP: Compare pattern semantics to user idea content for distance.\n\n„ÄêCRITICAL INSTRUCTIONS„Äë\n1. DO NOT give all patterns middle-range scores (0.4-0.6). Spread the distribution.\n2. DISTINGUISH between: optimization (low novelty), new methodology (medium), paradigm shift (high).\n3. Large cluster size (>100) should NOT automatically mean high stability if methodology is flawed.\n4. Small cluster size (<20) should NOT automatically mean low novelty; niche innovation exists.\n\n„ÄêOutput Format - JSON ONLY„Äë\n{\n  \"stability_score\": 0.75,\n  \"novelty_score\": 0.55,\n  \"domain_distance\": 0.25,\n  \"reasoning\": \"Example: Established approach (Size 82), novel reframing angle, same-domain application\"\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 4052}, "response": {"ok": true, "text": "```json\n{\n  \"stability_score\": 0.50,\n  \"novelty_score\": 0.70,\n  \"domain_distance\": 0.45,\n  \"reasoning\": \"Maturing approach (Size 41) with specific focus on audio, high novelty due to 'reframing' understanding via multimodal/generative methods, moderate domain distance (Audio vs. MRI) requiring adaptation of autoregressive/probabilistic principles.\"\n}\n```", "latency_ms": 29943, "text_truncated": false, "text_len": 356}}}
{"ts": "2026-01-29T10:58:24.786015+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.3, "max_tokens": 300, "timeout": 180, "prompt": "\nYou are a **CRITICAL Multidimensional Pattern Scorer** for top-tier AI conferences (ICLR/NeurIPS).\nYour task is to rigorously evaluate a research pattern across THREE independent dimensions.\n‚ö†Ô∏è  IMPORTANT: Avoid clustering scores in the middle range. Be discriminative!\n\n„ÄêUser's Research Idea„Äë\n\"Propose the autoregressive image diffusion (AID) model for image sequence generation and apply it to sample the posterior for accelerated MRI reconstruction\"\n\n„ÄêPattern Information„Äë\nPattern ID: pattern_99\nName: Frequency Aware Adaptive Restoration\nCluster Size: 23 papers\nRepresentative Research Ideas:\n- Introduce a dynamic, content-aware frequency decomposition approach to enhance image restoration by selectively accentuating informative frequency components.\n- Introduce Soft Score Matching to effectively learn score functions for a wide range of linear corruption processes, achieving superior performance and computational efficiency.\n- Utilize Fourier domain characteristics to enhance ultra-high-definition low-light images by separately processing amplitude and phase.\n\n„ÄêReference Examples (for calibration)„Äë\nRecent scoring calibration:\n  pattern_100 (Size 148): stability=0.90, novelty=0.25\n  pattern_115 (Size 107): stability=0.80, novelty=0.35\n  pattern_102 (Size 50): stability=0.65, novelty=0.45\n\n„ÄêScoring Guidelines - Be CRITICAL and DISCRIMINATIVE„Äë\n\n**Stability Score (0.0-1.0)** - How proven, mature, and widely-adopted?\nConsider: Has this approach been replicated across many papers? Are there established benchmarks?\n- 0.1-0.25: Highly experimental, niche idea, Size < 15, no standard benchmarks, high uncertainty\n- 0.3-0.45: Early-stage research, Size 15-40, some implementations but inconsistent results\n- 0.5-0.65: Maturing approach, Size 40-70, multiple independent implementations, emerging consensus\n- 0.7-0.85: Well-established, Size 70-120, standard benchmarks, widely replicated with consistent gains\n- 0.9-1.0: Foundational/canonical approach, Size > 120, ubiquitous, considered solved or foundational\nüî¥ RED FLAG: Avoid giving middle scores (0.4-0.6) to everything. Distinguish clearly.\n\n**Novelty Score (0.0-1.0)** - How original, counter-intuitive, and fresh is this?\nConsider: Is this a new perspective? Does it challenge existing assumptions? Or incremental variation?\n- 0.1-0.25: Well-trodden path, combinations of existing techniques, straightforward application\n- 0.3-0.45: Some novelty in execution or application domain, but builds on established ideas\n- 0.5-0.65: Interesting recombination or new angle on known problems, moderate originality\n- 0.7-0.85: Novel methodology, surprising insight, challenges conventional wisdom, fresh angle\n- 0.9-1.0: Paradigm shift, highly counter-intuitive, fundamentally new problem formulation\nüî¥ RED FLAG: If pattern_name suggests \"reframing\" or \"transforming\", likely 0.6+. If it's optimization/tuning, likely 0.2-0.4.\n\n**Domain Distance (0.0-1.0)** - How different from user's core idea?\nConsider semantic and methodological distance, not just application domain.\n- 0.0-0.15: Directly addresses same problem, highly relevant methodology\n- 0.2-0.35: Related domain/approach, applicable with minor adaptation\n- 0.4-0.55: Different domain but transferable insights, moderate adaptation needed\n- 0.6-0.8: Orthogonal domain, interesting cross-domain inspirations\n- 0.85-1.0: Completely different field, minimal direct relevance\nüí° TIP: Compare pattern semantics to user idea content for distance.\n\n„ÄêCRITICAL INSTRUCTIONS„Äë\n1. DO NOT give all patterns middle-range scores (0.4-0.6). Spread the distribution.\n2. DISTINGUISH between: optimization (low novelty), new methodology (medium), paradigm shift (high).\n3. Large cluster size (>100) should NOT automatically mean high stability if methodology is flawed.\n4. Small cluster size (<20) should NOT automatically mean low novelty; niche innovation exists.\n\n„ÄêOutput Format - JSON ONLY„Äë\n{\n  \"stability_score\": 0.75,\n  \"novelty_score\": 0.55,\n  \"domain_distance\": 0.25,\n  \"reasoning\": \"Example: Established approach (Size 82), novel reframing angle, same-domain application\"\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 4087}, "response": {"ok": true, "text": "```json\n{\n  \"stability_score\": 0.35,\n  \"novelty_score\": 0.40,\n  \"domain_distance\": 0.20,\n  \"reasoning\": \"Cluster size 23 indicates early-stage research with niche adoption; while frequency analysis is classical, the specific 'content-aware adaptive' implementations are still maturing. The pattern offers moderate novelty through techniques like Soft Score Matching and amplitude/phase separation, representing an interesting recombination rather than a paradigm shift. Domain distance is low because MRI reconstruction is inherently a frequency-domain (k-space) problem, making the pattern's focus on Fourier characteristics highly relevant to the user's application.\"\n}\n```", "latency_ms": 23707, "text_truncated": false, "text_len": 675}}}
{"ts": "2026-01-29T10:59:01.432914+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.7, "max_tokens": 1500, "timeout": 180, "prompt": "\nYou are a senior paper author at a top AI conference. Generate a structured paper story based on the user's idea and writing template.\n\n„ÄêSTEP 1: Extract Core Concepts from User Idea„Äë\nUser Idea: \"Propose the autoregressive image diffusion (AID) model for image sequence generation and apply it to sample the posterior for accelerated MRI reconstruction\"\n\nBefore writing anything, identify the CORE ENTITIES in the user idea (e.g., \"Agent\", \"Reflection\", \"Memory\", \"Self-Evolution\").\nThese are the TRUE subjects of your paper. Write them down:\nCore Concepts: [Extract 2-4 key concepts from the user idea above]\n\n‚ö†Ô∏è „ÄêCRITICAL: User Idea Protection Rules„Äë\n1. **The Core Concepts above are the PROTAGONISTS** of your story. They must appear in the title, abstract, problem_framing, gap_pattern, and all innovation claims.\n2. **Pattern's techniques are TOOLS, NOT the hero**: The writing template below provides technical approaches (e.g., RL, neural models) as \"means to implement the user's core concepts\". They should NEVER become the main focus.\n3. **Title & Abstract must highlight Core Concepts**: Technical terms can only appear as modifiers (e.g., \"Self-Evolution of Agents via X\" ‚úÖ, \"X-based Framework\" ‚ùå).\n4. **Method serves Core Concepts**: method_skeleton should describe \"how to use Pattern's techniques to realize the user's core concepts\", not list technique names.\n\n„ÄêWriting Template„ÄëReframing Diffusion Sampling Efficiency (contains 148 papers)\n\n„Äê‰ª£Ë°®ÊÄßÁ†îÁ©∂ÊÉ≥Ê≥ï„Äë\n1. Introduce a novel sampling method for diffusion models that significantly reduces the number of steps required while maintaining high sample quality.\n2. Extend DDIM to general diffusion models by modifying the score network parameterization for improved sampling efficiency.\n3. Introduce efficient samplers for diffusion models using a novel ideal derivative substitution technique to reduce neural function evaluations.\n\n\n„ÄêËØ•Ê®°Âºè‰∏ãÂ∏∏ËßÅÁöÑÁ†îÁ©∂ÈóÆÈ¢ò„Äë\n1. Diffusion models require a slow and computationally expensive sampling process with hundreds to thousands of steps to achieve high-fidelity samples.\n2. Existing denoising diffusion models are limited to isotropic diffusions and lack efficient sampling methods for general diffusion processes.\n3. Diffusion generative models require a large number of neural function evaluations during synthesis, making them computationally expensive.\n\n\n„ÄêSolution Approaches„Äë(Extract and adapt these technical solutions for your method)\n‚ö†Ô∏è CRITICAL: These solutions are the TECHNICAL MEANS to implement the User Idea.\nUse them to construct your method_skeleton, but always frame them as \"how they serve the user's core concepts\".\n\n1. Develop the Diffusion Exponential Integrator Sampler (DEIS) using an exponential integrator for discretizing ODEs, leveraging the semilinear structure of diffusion processes to minimize discretization error and reduce the number of required steps.\n2. Modify the score network parameterization in DDIM to extend its applicability to general diffusion models, enabling efficient deterministic sampling.\n3. Develop quasi-Taylor samplers using numerical schemes based on Taylor expansion, employing an 'ideal derivative substitution' to simplify the computation of higher-order derivatives.\n\n\n„ÄêStory Packaging Strategy„Äë(Learn how to PACKAGE the solutions into your narrative)\n‚ö†Ô∏è CRITICAL: These show how to REFRAME technical solutions as TRANSFORMATIVE INSIGHTS.\nUse these patterns to write problem_framing, gap_pattern, and claims, always connecting back to User Idea.\n\n1. Transform the challenge of slow sampling in diffusion models by reframing it as an opportunity to innovate on numerical methods, introducing a scalable approach that enhances efficiency without sacrificing quality, thus pushing the boundaries of generative modeling capabilities.\n2. Reframe diffusion model sampling from a stochastic process to a deterministic one by leveraging numerical insights, thus broadening the applicability and efficiency of diffusion models beyond isotropic cases.\n\n\n\n\n\n\n„ÄêTask Requirements„Äë\nGenerate structured content (JSON format) that tells a compelling story about the User Idea.\n\n„ÄêSTEP 2: How to Use the Writing Template„Äë\n\n**Part 1: Extract Technical Solutions from „ÄêSolution Approaches„Äë**\n- These are concrete technical methods you will use to implement the User Idea\n- Extract and adapt them into your method_skeleton\n- BUT: Always describe them as \"means to realize [Core Concept]\", not as standalone techniques\n\n**Part 2: Learn Packaging Strategy from „ÄêStory Packaging Strategy„Äë**\n- These show the \"Reframe X as Y\" narrative pattern\n- Use this pattern to write:\n  * problem_framing: \"Reframe [Core Concept] from [old view] to [new transformative view]\"\n  * gap_pattern: \"Current methods for [Core Concept] fail because...\"\n  * innovation_claims: \"Our approach transforms [Core Concept] by...\"\n- The pattern demonstrates how to position technical solutions as TRANSFORMATIVE INSIGHTS, not just methods\n\n**Part 3: Reference „ÄêÂèÇËÄÉËÆ∫ÊñáÁöÑÂåÖË£ÖÁ≠ñÁï•„Äë for storytelling examples**\n- See how real papers package their problem, gap, and method narratives\n- Learn the FLOW: problem ‚Üí gap ‚Üí solution ‚Üí transformation\n\nKey Guidelines:\n- **Core Principle**: User Idea is the protagonist; Pattern's techniques are tools\n- **Method Construction**: Use „ÄêSolution Approaches„Äë to build concrete steps, framed as \"implementing [Core Concept]\"\n- **Story Packaging**: Use „ÄêStory Packaging Strategy„Äë to write problem_framing, gap_pattern, claims with \"Reframe/Transform\" narratives\n- **Integration**: If „ÄêÂøÖÈ°ªËûçÂêàÁöÑÊäÄÂ∑ß„Äë is provided, integrate them as additional means to realize Core Concepts\n- **Avoid Technique Focus**: Never let technical terms overshadow the Core Concepts\n\nOutput Fields (ALL IN ENGLISH):\n1. title: Paper title (MUST highlight User Idea's core concepts; technique names only as modifiers)\n2. abstract: Abstract (150-200 words, User Idea as main thread, describe both the VISION and the SOLUTION)\n3. problem_framing: How to introduce the problem (100-150 words, use \"Reframe/Transform\" pattern, center on core concepts)\n4. gap_pattern: How to critique existing methods (100-150 words, show why current approaches fail for core concepts, use \"Reframe\" pattern)\n5. solution: Overall methodology description (150-200 words, narrative style using „ÄêStory Packaging Strategy„Äë, emphasize how solutions serve Core Concepts, more descriptive than method_skeleton)\n6. method_skeleton: Technical architecture (3-5 implementation steps separated by semicolons, extract from „ÄêSolution Approaches„Äë, focused on concrete technical structure)\n7. innovation_claims: 3 core contribution points (list format, use \"Transform/Reframe\" pattern from „ÄêStory Packaging Strategy„Äë, each claim MUST mention core concepts AND show transformation)\n8. experiments_plan: Experiment design (50-80 words)\n\nOutput Format (pure JSON, no other text):\n{\n  \"title\": \"...\",\n  \"abstract\": \"...\",\n  \"problem_framing\": \"...\",\n  \"gap_pattern\": \"...\",\n  \"solution\": \"...\",\n  \"method_skeleton\": \"Step 1; Step 2; Step 3...\",\n  \"innovation_claims\": [\"Contribution 1\", \"Contribution 2\", \"Contribution 3\"],\n  \"experiments_plan\": \"...\"\n}\n\nCritical Notes on Each Field:\n- title: MUST highlight Core Concepts (e.g., \"Self-Evolution of Agents via Reflection and Memory\")\n- abstract: Start with User Idea vision, then describe the technical realization\n- problem_framing: Use \"Reframe [Core Concept] from X to Y\" pattern learned from „ÄêStory Packaging Strategy„Äë\n- gap_pattern: Critique existing methods for Core Concepts, use \"Reframe\" pattern\n- solution: **NEW FIELD** - Describe the overall solution methodology with narrative packaging (150-200 words, more descriptive, emphasizes HOW solution approaches serve Core Concepts)\n- method_skeleton: Technical architecture with concrete implementation steps from „ÄêSolution Approaches„Äë (focused on structure, 3-5 steps)\n- innovation_claims: **CRITICAL** - Must use \"Transform/Reframe\" pattern:\n  * Good example: \"Transform agent self-evolution from passive RL training to an active reflection-memory paradigm by integrating episodic memory with self-assessment mechanisms, enabling autonomous improvement\"\n  * Bad example: \"Propose a novel state-space model architecture\" (technique-focused, not idea-focused)\n  * Each claim MUST: mention Core Concept + describe transformation + specify technical means + show benefit\n\n‚ö†Ô∏è LANGUAGE REQUIREMENT: Output ENTIRELY IN ENGLISH. No Chinese characters allowed.\n", "simulated": false, "prompt_truncated": false, "prompt_len": 8408}, "response": {"ok": true, "text": "```json\n{\n  \"title\": \"Autoregressive Image Diffusion via Exponential Integrators for Efficient Posterior Sampling in Accelerated MRI Reconstruction\",\n  \"abstract\": \"Accelerated MRI reconstruction fundamentally requires generating high-fidelity image sequences from undersampled k-space data, a task that demands both precise posterior sampling and computational efficiency. We propose Autoregressive Image Diffusion (AID), a novel generative framework that models the temporal dependencies of dynamic MRI through a sequence-aware diffusion process. To address the prohibitive computational cost typically associated with diffusion sampling in clinical settings, we integrate a Diffusion Exponential Integrator Sampler (DEIS). This approach reframes the sampling trajectory as a semilinear ordinary differential equation (ODE), allowing for significant reduction in function evaluations without sacrificing image quality. By combining the generative strength of autoregressive modeling with the numerical efficiency of exponential integrators, AID achieves rapid, high-quality posterior sampling, effectively bridging the gap between advanced generative theory and practical medical imaging requirements.\",\n  \"problem_framing\": \"We reframe accelerated MRI reconstruction from a simple static inverse problem to a complex task of dynamic temporal sequence generation requiring precise posterior sampling. Traditional methods often overlook the intricate temporal correlations inherent in dynamic MRI or rely on optimization strategies that fail to capture the full distribution of plausible solutions. By treating the reconstruction as an autoregressive image diffusion process, we transform the challenge into generating coherent, high-fidelity sequences that effectively sample the true posterior distribution defined by the physics of MRI acquisition.\",\n  \"gap_pattern\": \"Current diffusion-based generative models fail in clinical MRI applications because they require hundreds to thousands of expensive neural function evaluations, making real-time reconstruction infeasible. Furthermore, existing methods often treat image frames independently, lacking the autoregressive structure necessary to maintain temporal consistency in dynamic sequences. We identify a critical gap where the need for high-fidelity posterior sampling clashes with the computational inefficiency of standard stochastic sampling techniques and the lack of sequence-aware modeling.\",\n  \"solution\": \"Our solution introduces Autoregressive Image Diffusion (AID), which leverages the semilinear structure of diffusion processes to enable efficient, high-fidelity sequence generation. We implement the Diffusion Exponential Integrator Sampler (DEIS) as the core engine to discretize the probability flow ODE, minimizing discretization error and drastically reducing the number of required steps. This approach transforms the sampling process from a slow stochastic walk into a rapid, deterministic trajectory that respects the autoregressive nature of the data. By modifying the score network parameterization, we ensure that the model not only generates sharp images but also maintains temporal coherence across the sequence, all while adhering to the physical constraints of the MRI measurements.\",\n  \"method_skeleton\": \"Construct the Autoregressive Image Diffusion (AID) architecture by factorizing the joint distribution of image sequences into conditional diffusion steps; Formulate the accelerated MRI reconstruction task as a constrained posterior sampling problem within the AID framework; Implement the Diffusion Exponential Integrator Sampler (DEIS) to discretize the probability flow ODE, leveraging the semilinear structure to minimize discretization error across autoregressive steps; Optimize the score network parameterization to support efficient deterministic sampling while maintaining temporal consistency.\",\n  \"innovation_claims\": [\n    \"Transform accelerated MRI reconstruction from static optimization to dynamic Autoregressive Image Diffusion, enabling the generation of temporally coherent image sequences that accurately sample the complex posterior distribution.\",\n    \"Reframe the computationally prohibitive sampling process by integrating the Diffusion Exponential Integrator Sampler (DEIS), which exploits the semilinear structure of diffusion ODEs to drastically reduce neural function evaluations while maintaining fidelity.\",\n    \"Shift the paradigm of posterior sampling by combining autoregressive modeling with exponential integrators, bridging the gap between theoretical generative capabilities and the strict time constraints of clinical MRI workflows.\"\n  ],\n  \"experiments_plan\": \"We evaluate AID on retrospective undersampled dynamic cardiac and brain MRI datasets. Comparisons include state-of-the-art diffusion-based reconstruction methods and traditional compressed sensing techniques. Metrics include PSNR, SSIM for image quality, and sampling time steps/inference time to demonstrate the efficiency gains from the DEIS integration.\"\n}\n```", "latency_ms": 36645, "text_truncated": false, "text_len": 5055}}}
{"ts": "2026-01-29T10:59:37.170824+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.3, "max_tokens": 1000, "timeout": 180, "prompt": "\nTranslate the following research paper story from English to Chinese. Keep the translation natural and accurate.\n\nTitle: Autoregressive Image Diffusion via Exponential Integrators for Efficient Posterior Sampling in Accelerated MRI Reconstruction\nAbstract: Accelerated MRI reconstruction fundamentally requires generating high-fidelity image sequences from undersampled k-space data, a task that demands both precise posterior sampling and computational efficiency. We propose Autoregressive Image Diffusion (AID), a novel generative framework that models the temporal dependencies of dynamic MRI through a sequence-aware diffusion process. To address the prohibitive computational cost typically associated with diffusion sampling in clinical settings, we integrate a Diffusion Exponential Integrator Sampler (DEIS). This approach reframes the sampling trajectory as a semilinear ordinary differential equation (ODE), allowing for significant reduction in function evaluations without sacrificing image quality. By combining the generative strength of autoregressive modeling with the numerical efficiency of exponential integrators, AID achieves rapid, high-quality posterior sampling, effectively bridging the gap between advanced generative theory and practical medical imaging requirements.\nProblem Framing: We reframe accelerated MRI reconstruction from a simple static inverse problem to a complex task of dynamic temporal sequence generation requiring precise posterior sampling. Traditional methods often overlook the intricate temporal correlations inherent in dynamic MRI or rely on optimization strategies that fail to capture the full distribution of plausible solutions. By treating the reconstruction as an autoregressive image diffusion process, we transform the challenge into generating coherent, high-fidelity sequences that effectively sample the true posterior distribution defined by the physics of MRI acquisition.\nGap Pattern: Current diffusion-based generative models fail in clinical MRI applications because they require hundreds to thousands of expensive neural function evaluations, making real-time reconstruction infeasible. Furthermore, existing methods often treat image frames independently, lacking the autoregressive structure necessary to maintain temporal consistency in dynamic sequences. We identify a critical gap where the need for high-fidelity posterior sampling clashes with the computational inefficiency of standard stochastic sampling techniques and the lack of sequence-aware modeling.\nSolution: Our solution introduces Autoregressive Image Diffusion (AID), which leverages the semilinear structure of diffusion processes to enable efficient, high-fidelity sequence generation. We implement the Diffusion Exponential Integrator Sampler (DEIS) as the core engine to discretize the probability flow ODE, minimizing discretization error and drastically reducing the number of required steps. This approach transforms the sampling process from a slow stochastic walk into a rapid, deterministic trajectory that respects the autoregressive nature of the data. By modifying the score network parameterization, we ensure that the model not only generates sharp images but also maintains temporal coherence across the sequence, all while adhering to the physical constraints of the MRI measurements.\nMethod Skeleton: Construct the Autoregressive Image Diffusion (AID) architecture by factorizing the joint distribution of image sequences into conditional diffusion steps; Formulate the accelerated MRI reconstruction task as a constrained posterior sampling problem within the AID framework; Implement the Diffusion Exponential Integrator Sampler (DEIS) to discretize the probability flow ODE, leveraging the semilinear structure to minimize discretization error across autoregressive steps; Optimize the score network parameterization to support efficient deterministic sampling while maintaining temporal consistency.\nInnovation Claims:\n- Transform accelerated MRI reconstruction from static optimization to dynamic Autoregressive Image Diffusion, enabling the generation of temporally coherent image sequences that accurately sample the complex posterior distribution.\n- Reframe the computationally prohibitive sampling process by integrating the Diffusion Exponential Integrator Sampler (DEIS), which exploits the semilinear structure of diffusion ODEs to drastically reduce neural function evaluations while maintaining fidelity.\n- Shift the paradigm of posterior sampling by combining autoregressive modeling with exponential integrators, bridging the gap between theoretical generative capabilities and the strict time constraints of clinical MRI workflows.\nExperiments Plan: We evaluate AID on retrospective undersampled dynamic cardiac and brain MRI datasets. Comparisons include state-of-the-art diffusion-based reconstruction methods and traditional compressed sensing techniques. Metrics include PSNR, SSIM for image quality, and sampling time steps/inference time to demonstrate the efficiency gains from the DEIS integration.\n\nOutput ONLY a JSON format (no other text):\n{\n  \"title\": \"...\",\n  \"abstract\": \"...\",\n  \"problem_framing\": \"...\",\n  \"gap_pattern\": \"...\",\n  \"solution\": \"...\",\n  \"method_skeleton\": \"...\",\n  \"innovation_claims\": [\"...\", \"...\", \"...\"],\n  \"experiments_plan\": \"...\"\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 5344}, "response": {"ok": true, "text": "```json\n{\n  \"title\": \"Âü∫‰∫éÊåáÊï∞ÁßØÂàÜÂô®ÁöÑËá™ÂõûÂΩíÂõæÂÉèÊâ©Êï£Áî®‰∫éÂä†ÈÄüMRIÈáçÂª∫‰∏≠ÁöÑÈ´òÊïàÂêéÈ™åÈááÊ†∑\",\n  \"abstract\": \"Âä†ÈÄü MRI ÈáçÂª∫‰ªéÊ†πÊú¨‰∏äË¶ÅÊ±Ç‰ªéÊ¨†ÈááÊ†∑ÁöÑ k Á©∫Èó¥Êï∞ÊçÆ‰∏≠ÁîüÊàêÈ´ò‰øùÁúüÂõæÂÉèÂ∫èÂàóÔºåËøôÊòØ‰∏ÄÈ°πÊó¢ÈúÄË¶ÅÁ≤æÁ°ÆÂêéÈ™åÈááÊ†∑ÂèàÈúÄË¶ÅËÆ°ÁÆóÊïàÁéáÁöÑ‰ªªÂä°„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫ÜËá™ÂõûÂΩíÂõæÂÉèÊâ©Êï£ÔºàAIDÔºâÔºåËøôÊòØ‰∏ÄÁßçÊñ∞È¢ñÁöÑÁîüÊàêÊ°ÜÊû∂ÔºåÈÄöËøáÂ∫èÂàóÊÑüÁü•ÁöÑÊâ©Êï£ËøáÁ®ãÊù•Âª∫Ê®°Âä®ÊÄÅ MRI ÁöÑÊó∂Èó¥‰æùËµñÊÄß„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥‰∏¥Â∫äÁéØÂ¢É‰∏≠ÈÄöÂ∏∏‰∏éÊâ©Êï£ÈááÊ†∑Áõ∏ÂÖ≥ÁöÑËøáÈ´òËÆ°ÁÆóÊàêÊú¨ÔºåÊàë‰ª¨ÈõÜÊàê‰∫ÜÊâ©Êï£ÊåáÊï∞ÁßØÂàÜÈááÊ†∑Âô®ÔºàDEISÔºâ„ÄÇËøôÁßçÊñπÊ≥ïÂ∞ÜÈááÊ†∑ËΩ®ËøπÈáçÊûÑ‰∏∫ÂçäÁ∫øÊÄßÂ∏∏ÂæÆÂàÜÊñπÁ®ãÔºàODEÔºâÔºåÂÖÅËÆ∏Âú®‰∏çÁâ∫Áâ≤ÂõæÂÉèË¥®ÈáèÁöÑÊÉÖÂÜµ‰∏ãÊòæËëóÂáèÂ∞ëÂáΩÊï∞ËØÑ‰º∞Ê¨°Êï∞„ÄÇÈÄöËøáÁªìÂêàËá™ÂõûÂΩíÂª∫Ê®°ÁöÑÁîüÊàê‰ºòÂäø‰∏éÊåáÊï∞ÁßØÂàÜÂô®ÁöÑÊï∞ÂÄºÊïàÁéáÔºåAID ÂÆûÁé∞‰∫ÜÂø´ÈÄü„ÄÅÈ´òË¥®ÈáèÁöÑÂêéÈ™åÈááÊ†∑ÔºåÊúâÊïàÂú∞Âº•Âêà‰∫ÜÂÖàËøõÁîüÊàêÁêÜËÆ∫‰∏éÂÆûÈôÖÂåªÂ≠¶ÊàêÂÉèÈúÄÊ±Ç‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇ\",\n  \"problem_framing\": \"Êàë‰ª¨Â∞ÜÂä†ÈÄü MRI ÈáçÂª∫‰ªé‰∏Ä‰∏™ÁÆÄÂçïÁöÑÈùôÊÄÅÈÄÜÈóÆÈ¢òÈáçÊûÑ‰∏∫‰∏ÄÈ°πÈúÄË¶ÅÁ≤æÁ°ÆÂêéÈ™åÈááÊ†∑ÁöÑÂ§çÊùÇÂä®ÊÄÅÊó∂Èó¥Â∫èÂàóÁîüÊàê‰ªªÂä°„ÄÇ‰º†ÁªüÊñπÊ≥ïÂæÄÂæÄÂøΩÁï•‰∫ÜÂä®ÊÄÅ MRI Âõ∫ÊúâÁöÑÂ§çÊùÇÊó∂Èó¥Áõ∏ÂÖ≥ÊÄßÔºåÊàñËÄÖ‰æùËµñ‰∫éÊó†Ê≥ïÊçïÊçâÂêàÁêÜËß£ÂÆåÊï¥ÂàÜÂ∏ÉÁöÑ‰ºòÂåñÁ≠ñÁï•„ÄÇÈÄöËøáÂ∞ÜÈáçÂª∫ËßÜ‰∏∫Ëá™ÂõûÂΩíÂõæÂÉèÊâ©Êï£ËøáÁ®ãÔºåÊàë‰ª¨Â∞ÜËøô‰∏ÄÊåëÊàòËΩ¨Âåñ‰∏∫ÁîüÊàêËøûË¥Ø„ÄÅÈ´ò‰øùÁúüÁöÑÂ∫èÂàóÔºåËøô‰∫õÂ∫èÂàóÊúâÊïàÂú∞ÂØπÁî± MRI ÈááÈõÜÁâ©ÁêÜÂéüÁêÜÂÆö‰πâÁöÑÁúüÂÆûÂêéÈ™åÂàÜÂ∏ÉËøõË°åÈááÊ†∑„ÄÇ\",\n  \"gap_pattern\": \"ÂΩìÂâçÁöÑÂü∫‰∫éÊâ©Êï£ÁöÑÁîüÊàêÊ®°ÂûãÂú®‰∏¥Â∫ä MRI Â∫îÁî®‰∏≠Ë°®Áé∞‰∏ç‰Ω≥ÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ÈúÄË¶ÅÊï∞ÁôæÂà∞Êï∞ÂçÉÊ¨°ÊòÇË¥µÁöÑÁ•ûÁªèÁΩëÁªúÂáΩÊï∞ËØÑ‰º∞Ôºå‰ΩøÂæóÂÆûÊó∂ÈáçÂª∫ÂèòÂæó‰∏çÂèØË°å„ÄÇÊ≠§Â§ñÔºåÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏Áã¨Á´ãÂ§ÑÁêÜÂõæÂÉèÂ∏ßÔºåÁº∫‰πèÁª¥ÊåÅÂä®ÊÄÅÂ∫èÂàóÊó∂Èó¥‰∏ÄËá¥ÊÄßÊâÄÈúÄÁöÑËá™ÂõûÂΩíÁªìÊûÑ„ÄÇÊàë‰ª¨ÂèëÁé∞‰∫Ü‰∏Ä‰∏™ÂÖ≥ÈîÆÂ∑ÆË∑ùÔºåÂç≥ÂØπÈ´ò‰øùÁúüÂêéÈ™åÈááÊ†∑ÁöÑÈúÄÊ±Ç‰∏éÊ†áÂáÜÈöèÊú∫ÈááÊ†∑ÊäÄÊúØÁöÑËÆ°ÁÆó‰ΩéÊïà‰ª•ÂèäÁº∫‰πèÂ∫èÂàóÊÑüÁü•Âª∫Ê®°‰πãÈó¥Â≠òÂú®ÂÜ≤Á™Å„ÄÇ\",\n  \"solution\": \"Êàë‰ª¨ÁöÑËß£ÂÜ≥ÊñπÊ°àÂºïÂÖ•‰∫ÜËá™ÂõûÂΩíÂõæÂÉèÊâ©Êï£ÔºàAIDÔºâÔºåÂÆÉÂà©Áî®Êâ©Êï£ËøáÁ®ãÁöÑÂçäÁ∫øÊÄßÁªìÊûÑÊù•ÂÆûÁé∞È´òÊïà„ÄÅÈ´ò‰øùÁúüÁöÑÂ∫èÂàóÁîüÊàê„ÄÇÊàë‰ª¨ÂÆûÊñΩÊâ©Êï£ÊåáÊï∞ÁßØÂàÜÈááÊ†∑Âô®ÔºàDEISÔºâ‰Ωú‰∏∫Ê†∏ÂøÉÂºïÊìéÊù•Á¶ªÊï£ÂåñÊ¶ÇÁéáÊµÅ ODEÔºå‰ªéËÄåÊúÄÂ∞èÂåñÁ¶ªÊï£ÂåñËØØÂ∑ÆÂπ∂Â§ßÂπÖÂáèÂ∞ëÊâÄÈúÄÊ≠•È™§Êï∞„ÄÇËøôÁßçÊñπÊ≥ïÂ∞ÜÈááÊ†∑ËøáÁ®ã‰ªéÁºìÊÖ¢ÁöÑÈöèÊú∫Ê∏∏Ëµ∞ËΩ¨Âèò‰∏∫Â∞äÈáçÊï∞ÊçÆËá™ÂõûÂΩíÊÄßË¥®ÁöÑÂø´ÈÄüÁ°ÆÂÆöÊÄßËΩ®Ëøπ„ÄÇÈÄöËøá‰øÆÊîπËØÑÂàÜÁΩëÁªúÂèÇÊï∞ÂåñÔºåÊàë‰ª¨Á°Æ‰øùÊ®°Âûã‰∏ç‰ªÖÁîüÊàêÊ∏ÖÊô∞ÁöÑÂõæÂÉèÔºåËÄå‰∏îÂú®Êï¥‰∏™Â∫èÂàó‰∏≠‰øùÊåÅÊó∂Èó¥Áõ∏Âπ≤ÊÄßÔºåÂêåÊó∂ÈÅµÂÆà MRI ÊµãÈáèÁöÑÁâ©ÁêÜÁ∫¶Êùü„ÄÇ\",\n  \"method_skeleton\": \"ÈÄöËøáÂ∞ÜÂõæÂÉèÂ∫èÂàóÁöÑËÅîÂêàÂàÜÂ∏ÉÂàÜËß£‰∏∫Êù°‰ª∂Êâ©Êï£Ê≠•È™§Êù•ÊûÑÂª∫Ëá™ÂõûÂΩíÂõæÂÉèÊâ©Êï£ÔºàAIDÔºâÊû∂ÊûÑÔºõÂú® AID Ê°ÜÊû∂ÂÜÖÂ∞ÜÂä†ÈÄü MRI ÈáçÂª∫‰ªªÂä°Ë°®Ëø∞‰∏∫Á∫¶ÊùüÂêéÈ™åÈááÊ†∑ÈóÆÈ¢òÔºõÂÆûÊñΩÊâ©Êï£ÊåáÊï∞ÁßØÂàÜÈááÊ†∑Âô®ÔºàDEISÔºâ‰ª•Á¶ªÊï£ÂåñÊ¶ÇÁéáÊµÅ ODEÔºåÂà©Áî®ÂçäÁ∫øÊÄßÁªìÊûÑÊúÄÂ∞èÂåñËá™ÂõûÂΩíÊ≠•È™§‰∏≠ÁöÑÁ¶ªÊï£ÂåñËØØÂ∑ÆÔºõ‰ºòÂåñËØÑÂàÜÁΩëÁªúÂèÇÊï∞Âåñ‰ª•ÊîØÊåÅÈ´òÊïàÁöÑÁ°ÆÂÆöÊÄßÈááÊ†∑ÔºåÂêåÊó∂‰øùÊåÅÊó∂Èó¥‰∏ÄËá¥ÊÄß„ÄÇ\",\n  \"innovation_claims\": [\n    \"Â∞ÜÂä†ÈÄü MRI ÈáçÂª∫‰ªéÈùôÊÄÅ‰ºòÂåñËΩ¨Âèò‰∏∫Âä®ÊÄÅËá™ÂõûÂΩíÂõæÂÉèÊâ©Êï£Ôºå‰ªéËÄåËÉΩÂ§üÁîüÊàêÊó∂Èó¥ËøûË¥ØÁöÑÂõæÂÉèÂ∫èÂàóÔºåÂπ∂ÂáÜÁ°ÆÂú∞ÂØπÂ§çÊùÇÁöÑÂêéÈ™åÂàÜÂ∏ÉËøõË°åÈááÊ†∑„ÄÇ\",\n    \"ÈÄöËøáÈõÜÊàêÊâ©Êï£ÊåáÊï∞ÁßØÂàÜÈááÊ†∑Âô®ÔºàDEISÔºâÈáçÊûÑËÆ°ÁÆóÊàêÊú¨È´òÊòÇÁöÑÈááÊ†∑ËøáÁ®ãÔºåÂà©Áî®Êâ©Êï£ ODE ÁöÑÂçäÁ∫øÊÄßÁªìÊûÑÂú®‰øùÊåÅ‰øùÁúüÂ∫¶ÁöÑÂêåÊó∂Â§ßÂπÖÂáèÂ∞ëÁ•ûÁªèÁΩëÁªúÂáΩÊï∞ËØÑ‰º∞„ÄÇ\",\n    \"ÈÄöËøáÁªìÂêàËá™ÂõûÂΩíÂª∫Ê®°‰∏éÊåáÊï∞ÁßØÂàÜÂô®ÔºåËΩ¨ÂèòÂêéÈ™åÈááÊ†∑ÁöÑËåÉÂºèÔºåÂº•Âêà‰∫ÜÁêÜËÆ∫ÁîüÊàêËÉΩÂäõ‰∏é‰∏¥Â∫ä MRI Â∑•‰ΩúÊµÅÁ®ã‰∏•Ê†ºÊó∂Èó¥ÈôêÂà∂‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇ\"\n  ],\n  \"experiments_plan\": \"Êàë‰ª¨Âú®ÂõûÈ°æÊÄßÊ¨†ÈááÊ†∑ÁöÑÂä®ÊÄÅÂøÉËÑèÂíåÂ§ßËÑë MRI Êï∞ÊçÆÈõÜ‰∏äËØÑ‰º∞ AID„ÄÇÂØπÊØîÂåÖÊã¨ÊúÄÂÖàËøõÁöÑÂü∫‰∫éÊâ©Êï£ÁöÑÈáçÂª∫ÊñπÊ≥ïÂíå‰º†ÁªüÁöÑÂéãÁº©ÊÑüÁü•ÊäÄÊúØ„ÄÇËØÑ‰º∞ÊåáÊ†áÂåÖÊã¨Áî®‰∫éÂõæÂÉèË¥®ÈáèÁöÑ PSNR Âíå SSIMÔºå‰ª•ÂèäÈááÊ†∑Êó∂Èó¥Ê≠•Êï∞/Êé®ÁêÜÊó∂Èó¥Ôºå‰ª•Â±ïÁ§∫ÈõÜÊàê DEIS Â∏¶Êù•ÁöÑÊïàÁéáÊèêÂçá„ÄÇ\"\n}\n```", "latency_ms": 35736, "text_truncated": false, "text_len": 1540}}}
{"ts": "2026-01-29T11:00:45.911058+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.0, "max_tokens": 800, "timeout": 180, "prompt": "\nYou are a strict reviewer (Methodology) for top-tier ML/NLP conferences.\nYou must NOT output a direct score. Only compare the Story against anchor papers with real review scores.\n\nAnchors (score10 comes from real review statistics):\n- paper_id: HyjIEf90Tn | title: Glauber Generative Model: Discrete Diffusion Models via Binary Classification | score10: 5.9\n- paper_id: spDUv05cEq | title: Flow-based Variational Mutual Information: Fast and Flexible Approximations | score10: 6.0\n- paper_id: RZHdb7FnqlY | title: Towards the Detection of Diffusion Model Deepfakes | score10: 6.2\n- paper_id: RaR3ETzyKp | title: Easing Training Process of Rectified Flow Models Via Lengthening Inter-Path Distance | score10: 6.5\n- paper_id: zWy7dqOcel | title: Sampling with Mollified Interaction Energy Descent | score10: 7.1\n- paper_id: r5njV3BsuD | title: Nearly $d$-Linear Convergence Bounds for Diffusion Models via Stochastic Localization | score10: 6.5\n- paper_id: PP1rudnxiW | title: Transport meets Variational Inference: Controlled Monte Carlo Diffusions | score10: 6.4\n\nStory:\nTitle: Autoregressive Image Diffusion via Exponential Integrators for Efficient Posterior Sampling in Accelerated MRI Reconstruction\nAbstract: Accelerated MRI reconstruction fundamentally requires generating high-fidelity image sequences from undersampled k-space data, a task that demands both precise posterior sampling and computational efficiency. We propose Autoregressive Image Diffusion (AID), a novel generative framework that models the temporal dependencies of dynamic MRI through a sequence-aware diffusion process. To address the prohibitive computational cost typically associated with diffusion sampling in clinical settings, we integrate a Diffusion Exponential Integrator Sampler (DEIS). This approach reframes the sampling trajectory as a semilinear ordinary differential equation (ODE), allowing for significant reduction in function evaluations without sacrificing image quality. By combining the generative strength of autoregressive modeling with the numerical efficiency of exponential integrators, AID achieves rapid, high-quality posterior sampling, effectively bridging the gap between advanced generative theory and practical medical imaging requirements.\nProblem: We reframe accelerated MRI reconstruction from a simple static inverse problem to a complex task of dynamic temporal sequence generation requiring precise posterior sampling. Traditional methods often overlook the intricate temporal correlations inherent in dynamic MRI or rely on optimization strategies that fail to capture the full distribution of plausible solutions. By treating the reconstruction as an autoregressive image diffusion process, we transform the challenge into generating coherent, high-fidelity sequences that effectively sample the true posterior distribution defined by the physics of MRI acquisition.\nMethod: Construct the Autoregressive Image Diffusion (AID) architecture by factorizing the joint distribution of image sequences into conditional diffusion steps; Formulate the accelerated MRI reconstruction task as a constrained posterior sampling problem within the AID framework; Implement the Diffusion Exponential Integrator Sampler (DEIS) to discretize the probability flow ODE, leveraging the semilinear structure to minimize discretization error across autoregressive steps; Optimize the score network parameterization to support efficient deterministic sampling while maintaining temporal consistency.\nClaims: Transform accelerated MRI reconstruction from static optimization to dynamic Autoregressive Image Diffusion, enabling the generation of temporally coherent image sequences that accurately sample the complex posterior distribution., Reframe the computationally prohibitive sampling process by integrating the Diffusion Exponential Integrator Sampler (DEIS), which exploits the semilinear structure of diffusion ODEs to drastically reduce neural function evaluations while maintaining fidelity., Shift the paradigm of posterior sampling by combining autoregressive modeling with exponential integrators, bridging the gap between theoretical generative capabilities and the strict time constraints of clinical MRI workflows.\nExperiments: We evaluate AID on retrospective undersampled dynamic cardiac and brain MRI datasets. Comparisons include state-of-the-art diffusion-based reconstruction methods and traditional compressed sensing techniques. Metrics include PSNR, SSIM for image quality, and sampling time steps/inference time to demonstrate the efficiency gains from the DEIS integration.\n\nTask:\nFor each anchor, decide whether the Story is better, tie, or worse on Methodology, and provide confidence (0-1).\nYou must mention the anchor's score10 in the rationale using the format \"score10: X.X\".\nComparisons must include every anchor exactly once.\nEach rationale must be ONE sentence (<=25 words).\n\nOutput JSON ONLY. No markdown, no extra text:\n{\n  \"comparisons\": [\n    {\"paper_id\":\"...\", \"judgement\":\"better|tie|worse\", \"confidence\":0.0-1.0, \"rationale\":\"...score10: X.X...\"}\n  ],\n  \"main_gaps\": [\"gap1\", \"gap2\", \"gap3\"]\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 5135}, "response": {"ok": true, "text": "```json\n{\n  \"comparisons\": [\n    {\"paper_id\":\"HyjIEf90Tn\",\"judgement\":\"better\",\"confidence\":0.8,\"rationale\":\"AID's autoregressive diffusion with exponential integrators surpasses binary classification approach. score10: 5.9\"},\n    {\"paper_id\":\"spDUv05cEq\",\"judgement\":\"better\",\"confidence\":0.7,\"rationale\":\"AID's MRI-specific methodology exceeds flow-based variational mutual information. score10: 6.0\"},\n    {\"paper_id\":\"RZHdb7FnqlY\",\"judgement\":\"better\",\"confidence\":0.7,\"rationale\":\"AID's reconstruction methodology outperforms deepfake detection approach. score10: 6.2\"},\n    {\"paper_id\":\"RaR3ETzyKp\",\"judgement\":\"worse\",\"confidence\":0.6,\"rationale\":\"Anchor's rectified flow training approach demonstrates stronger methodology. score10: 6.5\"},\n    {\"paper_id\":\"zWy7dqOcel\",\"judgement\":\"worse\",\"confidence\":0.7,\"rationale\":\"Anchor's novel sampling method exceeds AID's application-specific approach. score10: 7.1\"},\n    {\"paper_id\":\"r5njV3BsuD\",\"judgement\":\"worse\",\"confidence\":0.7,\"rationale\":\"Anchor's theoretical convergence bounds surpass AID's application focus. score10: 6.5\"},\n    {\"paper_id\":\"PP1rudnxiW\",\"judgement\":\"worse\",\"confidence\":0.6,\"rationale\":\"Anchor's transport-variational integration demonstrates stronger methodology. score10: 6.4\"}\n  ],\n  \"main_gaps\": [\"Theoretical foundations lacking convergence guarantees\", \"Limited generalizability beyond MRI reconstruction\", \"Insufficient comparison with comprehensive state-of-the-art methods\"]\n}\n```", "latency_ms": 68738, "text_truncated": false, "text_len": 1468}}}
{"ts": "2026-01-29T11:01:58.675439+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.0, "max_tokens": 800, "timeout": 180, "prompt": "\nYou are a strict reviewer (Novelty) for top-tier ML/NLP conferences.\nYou must NOT output a direct score. Only compare the Story against anchor papers with real review scores.\n\nAnchors (score10 comes from real review statistics):\n- paper_id: HyjIEf90Tn | title: Glauber Generative Model: Discrete Diffusion Models via Binary Classification | score10: 5.9\n- paper_id: spDUv05cEq | title: Flow-based Variational Mutual Information: Fast and Flexible Approximations | score10: 6.0\n- paper_id: RZHdb7FnqlY | title: Towards the Detection of Diffusion Model Deepfakes | score10: 6.2\n- paper_id: RaR3ETzyKp | title: Easing Training Process of Rectified Flow Models Via Lengthening Inter-Path Distance | score10: 6.5\n- paper_id: zWy7dqOcel | title: Sampling with Mollified Interaction Energy Descent | score10: 7.1\n- paper_id: r5njV3BsuD | title: Nearly $d$-Linear Convergence Bounds for Diffusion Models via Stochastic Localization | score10: 6.5\n- paper_id: PP1rudnxiW | title: Transport meets Variational Inference: Controlled Monte Carlo Diffusions | score10: 6.4\n\nStory:\nTitle: Autoregressive Image Diffusion via Exponential Integrators for Efficient Posterior Sampling in Accelerated MRI Reconstruction\nAbstract: Accelerated MRI reconstruction fundamentally requires generating high-fidelity image sequences from undersampled k-space data, a task that demands both precise posterior sampling and computational efficiency. We propose Autoregressive Image Diffusion (AID), a novel generative framework that models the temporal dependencies of dynamic MRI through a sequence-aware diffusion process. To address the prohibitive computational cost typically associated with diffusion sampling in clinical settings, we integrate a Diffusion Exponential Integrator Sampler (DEIS). This approach reframes the sampling trajectory as a semilinear ordinary differential equation (ODE), allowing for significant reduction in function evaluations without sacrificing image quality. By combining the generative strength of autoregressive modeling with the numerical efficiency of exponential integrators, AID achieves rapid, high-quality posterior sampling, effectively bridging the gap between advanced generative theory and practical medical imaging requirements.\nProblem: We reframe accelerated MRI reconstruction from a simple static inverse problem to a complex task of dynamic temporal sequence generation requiring precise posterior sampling. Traditional methods often overlook the intricate temporal correlations inherent in dynamic MRI or rely on optimization strategies that fail to capture the full distribution of plausible solutions. By treating the reconstruction as an autoregressive image diffusion process, we transform the challenge into generating coherent, high-fidelity sequences that effectively sample the true posterior distribution defined by the physics of MRI acquisition.\nMethod: Construct the Autoregressive Image Diffusion (AID) architecture by factorizing the joint distribution of image sequences into conditional diffusion steps; Formulate the accelerated MRI reconstruction task as a constrained posterior sampling problem within the AID framework; Implement the Diffusion Exponential Integrator Sampler (DEIS) to discretize the probability flow ODE, leveraging the semilinear structure to minimize discretization error across autoregressive steps; Optimize the score network parameterization to support efficient deterministic sampling while maintaining temporal consistency.\nClaims: Transform accelerated MRI reconstruction from static optimization to dynamic Autoregressive Image Diffusion, enabling the generation of temporally coherent image sequences that accurately sample the complex posterior distribution., Reframe the computationally prohibitive sampling process by integrating the Diffusion Exponential Integrator Sampler (DEIS), which exploits the semilinear structure of diffusion ODEs to drastically reduce neural function evaluations while maintaining fidelity., Shift the paradigm of posterior sampling by combining autoregressive modeling with exponential integrators, bridging the gap between theoretical generative capabilities and the strict time constraints of clinical MRI workflows.\nExperiments: We evaluate AID on retrospective undersampled dynamic cardiac and brain MRI datasets. Comparisons include state-of-the-art diffusion-based reconstruction methods and traditional compressed sensing techniques. Metrics include PSNR, SSIM for image quality, and sampling time steps/inference time to demonstrate the efficiency gains from the DEIS integration.\n\nTask:\nFor each anchor, decide whether the Story is better, tie, or worse on Novelty, and provide confidence (0-1).\nYou must mention the anchor's score10 in the rationale using the format \"score10: X.X\".\nComparisons must include every anchor exactly once.\nEach rationale must be ONE sentence (<=25 words).\n\nOutput JSON ONLY. No markdown, no extra text:\n{\n  \"comparisons\": [\n    {\"paper_id\":\"...\", \"judgement\":\"better|tie|worse\", \"confidence\":0.0-1.0, \"rationale\":\"...score10: X.X...\"}\n  ],\n  \"main_gaps\": [\"gap1\", \"gap2\", \"gap3\"]\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 5127}, "response": {"ok": true, "text": "```json\n{\n  \"comparisons\": [\n    {\"paper_id\":\"HyjIEf90Tn\",\"judgement\":\"tie\",\"confidence\":0.7,\"rationale\":\"Story's autoregressive diffusion for MRI is equally novel as binary classification for discrete diffusion. score10: 5.9\"},\n    {\"paper_id\":\"spDUv05cEq\",\"judgement\":\"better\",\"confidence\":0.7,\"rationale\":\"Story's autoregressive diffusion with exponential integrators for medical imaging is more novel than flow-based mutual information. score10: 6.0\"},\n    {\"paper_id\":\"RZHdb7FnqlY\",\"judgement\":\"better\",\"confidence\":0.7,\"rationale\":\"Story's novel framework for dynamic MRI reconstruction is more innovative than diffusion deepfake detection. score10: 6.2\"},\n    {\"paper_id\":\"RaR3ETzyKp\",\"judgement\":\"better\",\"confidence\":0.7,\"rationale\":\"Story's autoregressive modeling with exponential integrators for medical imaging is more novel than rectified flow training improvements. score10: 6.5\"},\n    {\"paper_id\":\"zWy7dqOcel\",\"judgement\":\"worse\",\"confidence\":0.7,\"rationale\":\"Story's combination for medical imaging is less novel than Mollified Interaction Energy Descent. score10: 7.1\"},\n    {\"paper_id\":\"r5njV3BsuD\",\"judgement\":\"worse\",\"confidence\":0.7,\"rationale\":\"Story's application to MRI reconstruction is less novel than theoretical convergence bounds. score10: 6.5\"},\n    {\"paper_id\":\"PP1rudnxiW\",\"judgement\":\"worse\",\"confidence\":0.7,\"rationale\":\"Story's autoregressive modeling with exponential integrators is less novel than transport-variational inference combination. score10: 6.4\"}\n  ],\n  \"main_gaps\": [\n    \"Limited theoretical analysis of the proposed method's convergence properties\",\n    \"Lack of comparison with other autoregressive approaches for MRI reconstruction\",\n    \"Potential scalability issues for longer temporal sequences not addressed\"\n  ]\n}\n```", "latency_ms": 72761, "text_truncated": false, "text_len": 1776}}}
{"ts": "2026-01-29T11:05:22.691598+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.0, "max_tokens": 800, "timeout": 180, "prompt": "\nYou are a strict reviewer (Storyteller) for top-tier ML/NLP conferences.\nYou must NOT output a direct score. Only compare the Story against anchor papers with real review scores.\n\nAnchors (score10 comes from real review statistics):\n- paper_id: HyjIEf90Tn | title: Glauber Generative Model: Discrete Diffusion Models via Binary Classification | score10: 5.9\n- paper_id: spDUv05cEq | title: Flow-based Variational Mutual Information: Fast and Flexible Approximations | score10: 6.0\n- paper_id: RZHdb7FnqlY | title: Towards the Detection of Diffusion Model Deepfakes | score10: 6.2\n- paper_id: RaR3ETzyKp | title: Easing Training Process of Rectified Flow Models Via Lengthening Inter-Path Distance | score10: 6.5\n- paper_id: zWy7dqOcel | title: Sampling with Mollified Interaction Energy Descent | score10: 7.1\n- paper_id: r5njV3BsuD | title: Nearly $d$-Linear Convergence Bounds for Diffusion Models via Stochastic Localization | score10: 6.5\n- paper_id: PP1rudnxiW | title: Transport meets Variational Inference: Controlled Monte Carlo Diffusions | score10: 6.4\n\nStory:\nTitle: Autoregressive Image Diffusion via Exponential Integrators for Efficient Posterior Sampling in Accelerated MRI Reconstruction\nAbstract: Accelerated MRI reconstruction fundamentally requires generating high-fidelity image sequences from undersampled k-space data, a task that demands both precise posterior sampling and computational efficiency. We propose Autoregressive Image Diffusion (AID), a novel generative framework that models the temporal dependencies of dynamic MRI through a sequence-aware diffusion process. To address the prohibitive computational cost typically associated with diffusion sampling in clinical settings, we integrate a Diffusion Exponential Integrator Sampler (DEIS). This approach reframes the sampling trajectory as a semilinear ordinary differential equation (ODE), allowing for significant reduction in function evaluations without sacrificing image quality. By combining the generative strength of autoregressive modeling with the numerical efficiency of exponential integrators, AID achieves rapid, high-quality posterior sampling, effectively bridging the gap between advanced generative theory and practical medical imaging requirements.\nProblem: We reframe accelerated MRI reconstruction from a simple static inverse problem to a complex task of dynamic temporal sequence generation requiring precise posterior sampling. Traditional methods often overlook the intricate temporal correlations inherent in dynamic MRI or rely on optimization strategies that fail to capture the full distribution of plausible solutions. By treating the reconstruction as an autoregressive image diffusion process, we transform the challenge into generating coherent, high-fidelity sequences that effectively sample the true posterior distribution defined by the physics of MRI acquisition.\nMethod: Construct the Autoregressive Image Diffusion (AID) architecture by factorizing the joint distribution of image sequences into conditional diffusion steps; Formulate the accelerated MRI reconstruction task as a constrained posterior sampling problem within the AID framework; Implement the Diffusion Exponential Integrator Sampler (DEIS) to discretize the probability flow ODE, leveraging the semilinear structure to minimize discretization error across autoregressive steps; Optimize the score network parameterization to support efficient deterministic sampling while maintaining temporal consistency.\nClaims: Transform accelerated MRI reconstruction from static optimization to dynamic Autoregressive Image Diffusion, enabling the generation of temporally coherent image sequences that accurately sample the complex posterior distribution., Reframe the computationally prohibitive sampling process by integrating the Diffusion Exponential Integrator Sampler (DEIS), which exploits the semilinear structure of diffusion ODEs to drastically reduce neural function evaluations while maintaining fidelity., Shift the paradigm of posterior sampling by combining autoregressive modeling with exponential integrators, bridging the gap between theoretical generative capabilities and the strict time constraints of clinical MRI workflows.\nExperiments: We evaluate AID on retrospective undersampled dynamic cardiac and brain MRI datasets. Comparisons include state-of-the-art diffusion-based reconstruction methods and traditional compressed sensing techniques. Metrics include PSNR, SSIM for image quality, and sampling time steps/inference time to demonstrate the efficiency gains from the DEIS integration.\n\nTask:\nFor each anchor, decide whether the Story is better, tie, or worse on Storyteller, and provide confidence (0-1).\nYou must mention the anchor's score10 in the rationale using the format \"score10: X.X\".\nComparisons must include every anchor exactly once.\nEach rationale must be ONE sentence (<=25 words).\n\nOutput JSON ONLY. No markdown, no extra text:\n{\n  \"comparisons\": [\n    {\"paper_id\":\"...\", \"judgement\":\"better|tie|worse\", \"confidence\":0.0-1.0, \"rationale\":\"...score10: X.X...\"}\n  ],\n  \"main_gaps\": [\"gap1\", \"gap2\", \"gap3\"]\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 5135}, "response": {"ok": true, "text": "```json\n{\n  \"comparisons\": [\n    {\"paper_id\":\"HyjIEf90Tn\", \"judgement\":\"better\", \"confidence\":0.7, \"rationale\":\"Story combines multiple novel techniques for medical application, more practical impact than discrete diffusion models. score10: 5.9\"},\n    {\"paper_id\":\"spDUv05cEq\", \"judgement\":\"better\", \"confidence\":0.65, \"rationale\":\"Story addresses critical medical imaging problem with novel approach, more applied impact than mutual information. score10: 6.0\"},\n    {\"paper_id\":\"RZHdb7FnqlY\", \"judgement\":\"better\", \"confidence\":0.6, \"rationale\":\"Story introduces novel combination of techniques for MRI, more technically innovative than deepfake detection. score10: 6.2\"},\n    {\"paper_id\":\"RaR3ETzyKp\", \"judgement\":\"tie\", \"confidence\":0.55, \"rationale\":\"Both papers improve diffusion models, Story for specific application, anchor for general training. score10: 6.5\"},\n    {\"paper_id\":\"zWy7dqOcel\", \"judgement\":\"worse\", \"confidence\":0.6, \"rationale\":\"Anchor introduces more fundamental sampling method with higher score, Story applies existing techniques. score10: 7.1\"},\n    {\"paper_id\":\"r5njV3BsuD\", \"judgement\":\"worse\", \"confidence\":0.65, \"rationale\":\"Anchor provides strong theoretical contributions, Story more applied with less theoretical depth. score10: 6.5\"},\n    {\"paper_id\":\"PP1rudnxiW\", \"judgement\":\"worse\", \"confidence\":0.6, \"rationale\":\"Both combine techniques, but anchor has slightly higher score suggesting stronger contribution. score10: 6.4\"}\n  ],\n  \"main_gaps\": [\"Limited experimental evaluation on only retrospective datasets\", \"No comparison with other autoregressive models for MRI\", \"Lack of theoretical analysis for the proposed method\", \"No discussion of limitations or failure cases\", \"No evaluation on prospective clinical data\"]\n}\n```", "latency_ms": 204013, "text_truncated": false, "text_len": 1764}}}
{"ts": "2026-01-29T11:06:11.695757+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.0, "max_tokens": 800, "timeout": 180, "prompt": "\nYou are a strict reviewer (Methodology) for top-tier ML/NLP conferences.\nYou must NOT output a direct score. Only compare the Story against anchor papers with real review scores.\n\nAnchors (score10 comes from real review statistics):\n- paper_id: HyjIEf90Tn | title: Glauber Generative Model: Discrete Diffusion Models via Binary Classification | score10: 5.9\n- paper_id: spDUv05cEq | title: Flow-based Variational Mutual Information: Fast and Flexible Approximations | score10: 6.0\n- paper_id: RZHdb7FnqlY | title: Towards the Detection of Diffusion Model Deepfakes | score10: 6.2\n- paper_id: RaR3ETzyKp | title: Easing Training Process of Rectified Flow Models Via Lengthening Inter-Path Distance | score10: 6.5\n- paper_id: zWy7dqOcel | title: Sampling with Mollified Interaction Energy Descent | score10: 7.1\n- paper_id: r5njV3BsuD | title: Nearly $d$-Linear Convergence Bounds for Diffusion Models via Stochastic Localization | score10: 6.5\n- paper_id: PP1rudnxiW | title: Transport meets Variational Inference: Controlled Monte Carlo Diffusions | score10: 6.4\n- paper_id: eLgK35G3A5d | title: Annealed Fisher Implicit Sampler | score10: 5.8\n- paper_id: OlzB6LnXcS | title: One Step Diffusion via Shortcut Models | score10: 6.7\n\nStory:\nTitle: Autoregressive Image Diffusion via Exponential Integrators for Efficient Posterior Sampling in Accelerated MRI Reconstruction\nAbstract: Accelerated MRI reconstruction fundamentally requires generating high-fidelity image sequences from undersampled k-space data, a task that demands both precise posterior sampling and computational efficiency. We propose Autoregressive Image Diffusion (AID), a novel generative framework that models the temporal dependencies of dynamic MRI through a sequence-aware diffusion process. To address the prohibitive computational cost typically associated with diffusion sampling in clinical settings, we integrate a Diffusion Exponential Integrator Sampler (DEIS). This approach reframes the sampling trajectory as a semilinear ordinary differential equation (ODE), allowing for significant reduction in function evaluations without sacrificing image quality. By combining the generative strength of autoregressive modeling with the numerical efficiency of exponential integrators, AID achieves rapid, high-quality posterior sampling, effectively bridging the gap between advanced generative theory and practical medical imaging requirements.\nProblem: We reframe accelerated MRI reconstruction from a simple static inverse problem to a complex task of dynamic temporal sequence generation requiring precise posterior sampling. Traditional methods often overlook the intricate temporal correlations inherent in dynamic MRI or rely on optimization strategies that fail to capture the full distribution of plausible solutions. By treating the reconstruction as an autoregressive image diffusion process, we transform the challenge into generating coherent, high-fidelity sequences that effectively sample the true posterior distribution defined by the physics of MRI acquisition.\nMethod: Construct the Autoregressive Image Diffusion (AID) architecture by factorizing the joint distribution of image sequences into conditional diffusion steps; Formulate the accelerated MRI reconstruction task as a constrained posterior sampling problem within the AID framework; Implement the Diffusion Exponential Integrator Sampler (DEIS) to discretize the probability flow ODE, leveraging the semilinear structure to minimize discretization error across autoregressive steps; Optimize the score network parameterization to support efficient deterministic sampling while maintaining temporal consistency.\nClaims: Transform accelerated MRI reconstruction from static optimization to dynamic Autoregressive Image Diffusion, enabling the generation of temporally coherent image sequences that accurately sample the complex posterior distribution., Reframe the computationally prohibitive sampling process by integrating the Diffusion Exponential Integrator Sampler (DEIS), which exploits the semilinear structure of diffusion ODEs to drastically reduce neural function evaluations while maintaining fidelity., Shift the paradigm of posterior sampling by combining autoregressive modeling with exponential integrators, bridging the gap between theoretical generative capabilities and the strict time constraints of clinical MRI workflows.\nExperiments: We evaluate AID on retrospective undersampled dynamic cardiac and brain MRI datasets. Comparisons include state-of-the-art diffusion-based reconstruction methods and traditional compressed sensing techniques. Metrics include PSNR, SSIM for image quality, and sampling time steps/inference time to demonstrate the efficiency gains from the DEIS integration.\n\nTask:\nFor each anchor, decide whether the Story is better, tie, or worse on Methodology, and provide confidence (0-1).\nYou must mention the anchor's score10 in the rationale using the format \"score10: X.X\".\nComparisons must include every anchor exactly once.\nEach rationale must be ONE sentence (<=25 words).\n\nOutput JSON ONLY. No markdown, no extra text:\n{\n  \"comparisons\": [\n    {\"paper_id\":\"...\", \"judgement\":\"better|tie|worse\", \"confidence\":0.0-1.0, \"rationale\":\"...score10: X.X...\"}\n  ],\n  \"main_gaps\": [\"gap1\", \"gap2\", \"gap3\"]\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 5302}, "response": {"ok": true, "text": "```json\n{\n  \"comparisons\": [\n    {\"paper_id\":\"HyjIEf90Tn\", \"judgement\":\"better\", \"confidence\":0.7, \"rationale\":\"Story combines multiple techniques, more comprehensive than binary classification approach, score10: 5.9\"},\n    {\"paper_id\":\"spDUv05cEq\", \"judgement\":\"better\", \"confidence\":0.7, \"rationale\":\"Story integrates advanced techniques for MRI reconstruction, more complex than flow-based mutual information, score10: 6.0\"},\n    {\"paper_id\":\"RZHdb7FnqlY\", \"judgement\":\"better\", \"confidence\":0.7, \"rationale\":\"Story's autoregressive diffusion with exponential integrators is more innovative than deepfake detection methodology, score10: 6.2\"},\n    {\"paper_id\":\"RaR3ETzyKp\", \"judgement\":\"better\", \"confidence\":0.6, \"rationale\":\"Story combines multiple techniques for MRI reconstruction, more comprehensive than rectified flow training improvements, score10: 6.5\"},\n    {\"paper_id\":\"zWy7dqOcel\", \"judgement\":\"worse\", \"confidence\":0.6, \"rationale\":\"Anchor's novel sampling technique has stronger theoretical foundation than Story's applied approach, score10: 7.1\"},\n    {\"paper_id\":\"r5njV3BsuD\", \"judgement\":\"worse\", \"confidence\":0.6, \"rationale\":\"Anchor's theoretical convergence analysis provides stronger methodology than Story's applied approach, score10: 6.5\"},\n    {\"paper_id\":\"PP1rudnxiW\", \"judgement\":\"tie\", \"confidence\":0.5, \"rationale\":\"Both papers combine multiple techniques with different applications and similar methodological complexity, score10: 6.4\"},\n    {\"paper_id\":\"eLgK35G3A5d\", \"judgement\":\"better\", \"confidence\":0.7, \"rationale\":\"Story's comprehensive combination of techniques exceeds the annealed Fisher implicit sampler approach, score10: 5.8\"},\n    {\"paper_id\":\"OlzB6LnXcS\", \"judgement\":\"tie\", \"confidence\":0.5, \"rationale\":\"Both papers focus on efficient diffusion sampling with different approaches and similar methodological quality, score10: 6.7\"}\n  ],\n  \"main_gaps\": [\"Limited theoretical analysis of convergence properties\", \"Unclear generalizability beyond MRI reconstruction\", \"Missing detailed ablation studies for method components\", \"Potential lack of comprehensive comparison with latest state-of-the-art\", \"Insufficient computational complexity analysis\"]\n}\n```", "latency_ms": 49001, "text_truncated": false, "text_len": 2202}}}
{"ts": "2026-01-29T11:06:46.396695+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.0, "max_tokens": 800, "timeout": 180, "prompt": "\nYou are a strict reviewer (Novelty) for top-tier ML/NLP conferences.\nYou must NOT output a direct score. Only compare the Story against anchor papers with real review scores.\n\nAnchors (score10 comes from real review statistics):\n- paper_id: HyjIEf90Tn | title: Glauber Generative Model: Discrete Diffusion Models via Binary Classification | score10: 5.9\n- paper_id: spDUv05cEq | title: Flow-based Variational Mutual Information: Fast and Flexible Approximations | score10: 6.0\n- paper_id: RZHdb7FnqlY | title: Towards the Detection of Diffusion Model Deepfakes | score10: 6.2\n- paper_id: RaR3ETzyKp | title: Easing Training Process of Rectified Flow Models Via Lengthening Inter-Path Distance | score10: 6.5\n- paper_id: zWy7dqOcel | title: Sampling with Mollified Interaction Energy Descent | score10: 7.1\n- paper_id: r5njV3BsuD | title: Nearly $d$-Linear Convergence Bounds for Diffusion Models via Stochastic Localization | score10: 6.5\n- paper_id: PP1rudnxiW | title: Transport meets Variational Inference: Controlled Monte Carlo Diffusions | score10: 6.4\n- paper_id: eLgK35G3A5d | title: Annealed Fisher Implicit Sampler | score10: 5.8\n- paper_id: OlzB6LnXcS | title: One Step Diffusion via Shortcut Models | score10: 6.7\n\nStory:\nTitle: Autoregressive Image Diffusion via Exponential Integrators for Efficient Posterior Sampling in Accelerated MRI Reconstruction\nAbstract: Accelerated MRI reconstruction fundamentally requires generating high-fidelity image sequences from undersampled k-space data, a task that demands both precise posterior sampling and computational efficiency. We propose Autoregressive Image Diffusion (AID), a novel generative framework that models the temporal dependencies of dynamic MRI through a sequence-aware diffusion process. To address the prohibitive computational cost typically associated with diffusion sampling in clinical settings, we integrate a Diffusion Exponential Integrator Sampler (DEIS). This approach reframes the sampling trajectory as a semilinear ordinary differential equation (ODE), allowing for significant reduction in function evaluations without sacrificing image quality. By combining the generative strength of autoregressive modeling with the numerical efficiency of exponential integrators, AID achieves rapid, high-quality posterior sampling, effectively bridging the gap between advanced generative theory and practical medical imaging requirements.\nProblem: We reframe accelerated MRI reconstruction from a simple static inverse problem to a complex task of dynamic temporal sequence generation requiring precise posterior sampling. Traditional methods often overlook the intricate temporal correlations inherent in dynamic MRI or rely on optimization strategies that fail to capture the full distribution of plausible solutions. By treating the reconstruction as an autoregressive image diffusion process, we transform the challenge into generating coherent, high-fidelity sequences that effectively sample the true posterior distribution defined by the physics of MRI acquisition.\nMethod: Construct the Autoregressive Image Diffusion (AID) architecture by factorizing the joint distribution of image sequences into conditional diffusion steps; Formulate the accelerated MRI reconstruction task as a constrained posterior sampling problem within the AID framework; Implement the Diffusion Exponential Integrator Sampler (DEIS) to discretize the probability flow ODE, leveraging the semilinear structure to minimize discretization error across autoregressive steps; Optimize the score network parameterization to support efficient deterministic sampling while maintaining temporal consistency.\nClaims: Transform accelerated MRI reconstruction from static optimization to dynamic Autoregressive Image Diffusion, enabling the generation of temporally coherent image sequences that accurately sample the complex posterior distribution., Reframe the computationally prohibitive sampling process by integrating the Diffusion Exponential Integrator Sampler (DEIS), which exploits the semilinear structure of diffusion ODEs to drastically reduce neural function evaluations while maintaining fidelity., Shift the paradigm of posterior sampling by combining autoregressive modeling with exponential integrators, bridging the gap between theoretical generative capabilities and the strict time constraints of clinical MRI workflows.\nExperiments: We evaluate AID on retrospective undersampled dynamic cardiac and brain MRI datasets. Comparisons include state-of-the-art diffusion-based reconstruction methods and traditional compressed sensing techniques. Metrics include PSNR, SSIM for image quality, and sampling time steps/inference time to demonstrate the efficiency gains from the DEIS integration.\n\nTask:\nFor each anchor, decide whether the Story is better, tie, or worse on Novelty, and provide confidence (0-1).\nYou must mention the anchor's score10 in the rationale using the format \"score10: X.X\".\nComparisons must include every anchor exactly once.\nEach rationale must be ONE sentence (<=25 words).\n\nOutput JSON ONLY. No markdown, no extra text:\n{\n  \"comparisons\": [\n    {\"paper_id\":\"...\", \"judgement\":\"better|tie|worse\", \"confidence\":0.0-1.0, \"rationale\":\"...score10: X.X...\"}\n  ],\n  \"main_gaps\": [\"gap1\", \"gap2\", \"gap3\"]\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 5294}, "response": {"ok": true, "text": "```json\n{\n  \"comparisons\": [\n    {\"paper_id\":\"HyjIEf90Tn\",\"judgement\":\"better\",\"confidence\":0.7,\"rationale\":\"AID's novel integration of autoregressive modeling with diffusion for MRI reconstruction exceeds binary classification approach. score10: 5.9\"},\n    {\"paper_id\":\"spDUv05cEq\",\"judgement\":\"better\",\"confidence\":0.7,\"rationale\":\"AID's novel application to MRI reconstruction surpasses flow-based mutual information estimation. score10: 6.0\"},\n    {\"paper_id\":\"RZHdb7FnqlY\",\"judgement\":\"better\",\"confidence\":0.7,\"rationale\":\"AID's novel framework for MRI reconstruction exceeds deepfake detection application. score10: 6.2\"},\n    {\"paper_id\":\"RaR3ETzyKp\",\"judgement\":\"better\",\"confidence\":0.6,\"rationale\":\"AID's novel integration of autoregressive modeling with exponential integrators surpasses rectified flow training improvement. score10: 6.5\"},\n    {\"paper_id\":\"zWy7dqOcel\",\"judgement\":\"worse\",\"confidence\":0.6,\"rationale\":\"Mollified interaction energy descent offers more novel sampling approach than AID's application. score10: 7.1\"},\n    {\"paper_id\":\"r5njV3BsuD\",\"judgement\":\"worse\",\"confidence\":0.6,\"rationale\":\"Theoretical convergence bounds provide more novel contribution than AID's application. score10: 6.5\"},\n    {\"paper_id\":\"PP1rudnxiW\",\"judgement\":\"tie\",\"confidence\":0.5,\"rationale\":\"Both papers offer similar novelty in combining different techniques. score10: 6.4\"},\n    {\"paper_id\":\"eLgK35G3A5d\",\"judgement\":\"better\",\"confidence\":0.7,\"rationale\":\"AID's novel integration of autoregressive modeling with exponential integrators exceeds annealed Fisher implicit sampler. score10: 5.8\"},\n    {\"paper_id\":\"OlzB6LnXcS\",\"judgement\":\"worse\",\"confidence\":0.6,\"rationale\":\"One-step diffusion via shortcut models offers more novel approach than AID's application. score10: 6.7\"}\n  ],\n  \"main_gaps\": [\"Limited theoretical analysis\", \"Narrow application focus\", \"Potential lack of comprehensive evaluation\"]\n}\n```", "latency_ms": 34697, "text_truncated": false, "text_len": 1924}}}
{"ts": "2026-01-29T11:07:27.774764+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.0, "max_tokens": 800, "timeout": 180, "prompt": "\nYou are a strict reviewer (Storyteller) for top-tier ML/NLP conferences.\nYou must NOT output a direct score. Only compare the Story against anchor papers with real review scores.\n\nAnchors (score10 comes from real review statistics):\n- paper_id: HyjIEf90Tn | title: Glauber Generative Model: Discrete Diffusion Models via Binary Classification | score10: 5.9\n- paper_id: spDUv05cEq | title: Flow-based Variational Mutual Information: Fast and Flexible Approximations | score10: 6.0\n- paper_id: RZHdb7FnqlY | title: Towards the Detection of Diffusion Model Deepfakes | score10: 6.2\n- paper_id: RaR3ETzyKp | title: Easing Training Process of Rectified Flow Models Via Lengthening Inter-Path Distance | score10: 6.5\n- paper_id: zWy7dqOcel | title: Sampling with Mollified Interaction Energy Descent | score10: 7.1\n- paper_id: r5njV3BsuD | title: Nearly $d$-Linear Convergence Bounds for Diffusion Models via Stochastic Localization | score10: 6.5\n- paper_id: PP1rudnxiW | title: Transport meets Variational Inference: Controlled Monte Carlo Diffusions | score10: 6.4\n- paper_id: eLgK35G3A5d | title: Annealed Fisher Implicit Sampler | score10: 5.8\n- paper_id: OlzB6LnXcS | title: One Step Diffusion via Shortcut Models | score10: 6.7\n\nStory:\nTitle: Autoregressive Image Diffusion via Exponential Integrators for Efficient Posterior Sampling in Accelerated MRI Reconstruction\nAbstract: Accelerated MRI reconstruction fundamentally requires generating high-fidelity image sequences from undersampled k-space data, a task that demands both precise posterior sampling and computational efficiency. We propose Autoregressive Image Diffusion (AID), a novel generative framework that models the temporal dependencies of dynamic MRI through a sequence-aware diffusion process. To address the prohibitive computational cost typically associated with diffusion sampling in clinical settings, we integrate a Diffusion Exponential Integrator Sampler (DEIS). This approach reframes the sampling trajectory as a semilinear ordinary differential equation (ODE), allowing for significant reduction in function evaluations without sacrificing image quality. By combining the generative strength of autoregressive modeling with the numerical efficiency of exponential integrators, AID achieves rapid, high-quality posterior sampling, effectively bridging the gap between advanced generative theory and practical medical imaging requirements.\nProblem: We reframe accelerated MRI reconstruction from a simple static inverse problem to a complex task of dynamic temporal sequence generation requiring precise posterior sampling. Traditional methods often overlook the intricate temporal correlations inherent in dynamic MRI or rely on optimization strategies that fail to capture the full distribution of plausible solutions. By treating the reconstruction as an autoregressive image diffusion process, we transform the challenge into generating coherent, high-fidelity sequences that effectively sample the true posterior distribution defined by the physics of MRI acquisition.\nMethod: Construct the Autoregressive Image Diffusion (AID) architecture by factorizing the joint distribution of image sequences into conditional diffusion steps; Formulate the accelerated MRI reconstruction task as a constrained posterior sampling problem within the AID framework; Implement the Diffusion Exponential Integrator Sampler (DEIS) to discretize the probability flow ODE, leveraging the semilinear structure to minimize discretization error across autoregressive steps; Optimize the score network parameterization to support efficient deterministic sampling while maintaining temporal consistency.\nClaims: Transform accelerated MRI reconstruction from static optimization to dynamic Autoregressive Image Diffusion, enabling the generation of temporally coherent image sequences that accurately sample the complex posterior distribution., Reframe the computationally prohibitive sampling process by integrating the Diffusion Exponential Integrator Sampler (DEIS), which exploits the semilinear structure of diffusion ODEs to drastically reduce neural function evaluations while maintaining fidelity., Shift the paradigm of posterior sampling by combining autoregressive modeling with exponential integrators, bridging the gap between theoretical generative capabilities and the strict time constraints of clinical MRI workflows.\nExperiments: We evaluate AID on retrospective undersampled dynamic cardiac and brain MRI datasets. Comparisons include state-of-the-art diffusion-based reconstruction methods and traditional compressed sensing techniques. Metrics include PSNR, SSIM for image quality, and sampling time steps/inference time to demonstrate the efficiency gains from the DEIS integration.\n\nTask:\nFor each anchor, decide whether the Story is better, tie, or worse on Storyteller, and provide confidence (0-1).\nYou must mention the anchor's score10 in the rationale using the format \"score10: X.X\".\nComparisons must include every anchor exactly once.\nEach rationale must be ONE sentence (<=25 words).\n\nOutput JSON ONLY. No markdown, no extra text:\n{\n  \"comparisons\": [\n    {\"paper_id\":\"...\", \"judgement\":\"better|tie|worse\", \"confidence\":0.0-1.0, \"rationale\":\"...score10: X.X...\"}\n  ],\n  \"main_gaps\": [\"gap1\", \"gap2\", \"gap3\"]\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 5302}, "response": {"ok": true, "text": "```json\n{\n  \"comparisons\": [\n    {\"paper_id\":\"HyjIEf90Tn\",\"judgement\":\"better\",\"confidence\":0.7,\"rationale\":\"Story combines autoregressive diffusion with exponential integrators for MRI, more innovative than binary classification approach (score10: 5.9).\"},\n    {\"paper_id\":\"spDUv05cEq\",\"judgement\":\"better\",\"confidence\":0.65,\"rationale\":\"Story applies novel combination of techniques to medical imaging, more practical than mutual information approximations (score10: 6.0).\"},\n    {\"paper_id\":\"RZHdb7FnqlY\",\"judgement\":\"better\",\"confidence\":0.6,\"rationale\":\"Story introduces more technically innovative approach combining autoregressive modeling with exponential integrators (score10: 6.2).\"},\n    {\"paper_id\":\"RaR3ETzyKp\",\"judgement\":\"tie\",\"confidence\":0.5,\"rationale\":\"Both papers improve diffusion models but in different contexts with similar technical depth (score10: 6.5).\"},\n    {\"paper_id\":\"zWy7dqOcel\",\"judgement\":\"worse\",\"confidence\":0.6,\"rationale\":\"Anchor paper introduces more fundamental sampling innovation with higher technical contribution (score10: 7.1).\"},\n    {\"paper_id\":\"r5njV3BsuD\",\"judgement\":\"tie\",\"confidence\":0.5,\"rationale\":\"Both papers contribute to diffusion models but with different focuses and similar technical depth (score10: 6.5).\"},\n    {\"paper_id\":\"PP1rudnxiW\",\"judgement\":\"tie\",\"confidence\":0.5,\"rationale\":\"Both papers combine multiple techniques in innovative ways with similar technical contribution (score10: 6.4).\"},\n    {\"paper_id\":\"eLgK35G3A5d\",\"judgement\":\"better\",\"confidence\":0.65,\"rationale\":\"Story applies novel combination of techniques to medical imaging, more practical than Fisher implicit sampling (score10: 5.8).\"},\n    {\"paper_id\":\"OlzB6LnXcS\",\"judgement\":\"worse\",\"confidence\":0.6,\"rationale\":\"Anchor paper introduces more fundamental innovation in one-step diffusion with higher technical contribution (score10: 6.7).\"}\n  ],\n  \"main_gaps\": [\"Limited theoretical analysis of convergence properties\", \"Lack of comparison with other exponential integrator methods\", \"Missing evaluation on diverse clinical scenarios\"]\n}\n```", "latency_ms": 41375, "text_truncated": false, "text_len": 2080}}}
{"ts": "2026-01-29T11:07:40.329743+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.7, "max_tokens": 500, "timeout": 120, "prompt": "\nÂàÜÊûê‰ª•‰∏ãÁ†îÁ©∂ËåÉÂºè/Ê®°ÂºèÔºåÊèêÂèñÂÖ∂Ê†∏ÂøÉ DNAÔºö\n\n„ÄêÁ†îÁ©∂ËåÉÂºè„Äë\nÂêçÁß∞: Reframing Inverse Problems with Diffusion\nÊèèËø∞:\nReframing Inverse Problems with Diffusion\nDevelop Pseudoinverse-guided Diffusion Models (Œ†GDM) that estimate conditional scores directly from the measurement model, enabling the use of problem-agnostic models without additional training.\nUtilize joint conditional reverse diffusion processes with learned scores for both noise and signal-generating distributions to improve performance in inverse problems.\n\nËØ∑‰ª• JSON Ê†ºÂºèËøîÂõû‰ª•‰∏ãÂÜÖÂÆπÔºàÊØè‰∏™100Â≠ó‰ª•ÂÜÖÔºâÔºö\n{\n  \"problem\": \"Ëøô‰∏™ËåÉÂºè‰∏ªË¶ÅËß£ÂÜ≥‰ªÄ‰πàÁ±ªÂûãÁöÑÈóÆÈ¢òÔºü\",\n  \"assumption\": \"Ëøô‰∏™ËåÉÂºèÂü∫‰∫é‰ªÄ‰πàÊ†∏ÂøÉÂÅáËÆæÊàñÊ¥ûÂØüÔºü\",\n  \"novelty_claim\": \"Ëøô‰∏™ËåÉÂºèÁõ∏ÊØîÁé∞ÊúâÊñπÊ≥ïÁöÑÊ†∏ÂøÉÂàõÊñ∞ÊòØ‰ªÄ‰πàÔºü\"\n}\n\nÂè™ËøîÂõû JSONÔºå‰∏çÈúÄË¶ÅÂÖ∂‰ªñËØ¥Êòé„ÄÇ\n", "simulated": false, "prompt_truncated": false, "prompt_len": 651}, "response": {"ok": true, "text": "```json\n{\n  \"problem\": \"Ëß£ÂÜ≥ÈÄÜÈóÆÈ¢òÔºåÈáçÁÇπÊòØÂ¶Ç‰ΩïÂú®‰∏çÈíàÂØπÁâπÂÆö‰ªªÂä°È¢ùÂ§ñËÆ≠ÁªÉÁöÑÊÉÖÂÜµ‰∏ãÔºåÂà©Áî®ÈÄöÁî®È¢ÑËÆ≠ÁªÉÊâ©Êï£Ê®°ÂûãÂÆûÁé∞È´òË¥®ÈáèÈáçÂª∫„ÄÇ\",\n  \"assumption\": \"ÂÅáËÆæÂèØÁõ¥Êé•‰ªéÊµãÈáèÊ®°Âûã‰º∞ËÆ°Êù°‰ª∂ÂàÜÊï∞Ôºå‰∏îÈÄöËøáËÅîÂêàÂª∫Ê®°‰ø°Âè∑‰∏éÂô™Â£∞ÂàÜÂ∏ÉÁöÑÂàÜÊï∞ÔºåËÉΩÊúâÊïàÂºïÂØºÊâ©Êï£ËøáÁ®ãÊ±ÇËß£ÈÄÜÈóÆÈ¢ò„ÄÇ\",\n  \"novelty_claim\": \"ÊèêÂá∫‰∫Ü‰º™ÈÄÜÂºïÂØºÊâ©Êï£Ê®°Âûã(Œ†GDM)ÔºåÊó†ÈúÄÈ¢ùÂ§ñËÆ≠ÁªÉÂç≥ÂèØÂ§çÁî®ÈÄöÁî®Ê®°ÂûãÔºåÂπ∂ÂºïÂÖ•ËÅîÂêàÊù°‰ª∂ÂèçÂêëÊâ©Êï£ËøáÁ®ã‰ª•ÊèêÂçáÈáçÂª∫ÊÄßËÉΩ„ÄÇ\"\n}\n```", "latency_ms": 12551, "text_truncated": false, "text_len": 225}}}
{"ts": "2026-01-29T11:08:09.387541+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.8, "max_tokens": 800, "timeout": 180, "prompt": "\nÂàÜÊûê‰∏§‰∏™Á†îÁ©∂ idea ‰πãÈó¥ÁöÑËûçÂêàÊΩúÂäõ„ÄÇ\n\n„ÄêUser Idea„Äë\nÈóÆÈ¢ò: We reframe accelerated MRI reconstruction from a simple static inverse problem to a complex task of dynamic temporal sequence generation requiring precise posterior sampling. Traditional methods often overlook the intricate temporal correlations inherent in dynamic MRI or rely on optimization strategies that fail to capture the full distribution of plausible solutions. By treating the reconstruction as an autoregressive image diffusion process, we transform the challenge into generating coherent, high-fidelity sequences that effectively sample the true posterior distribution defined by the physics of MRI acquisition.\nÂÅáËÆæ: Current diffusion-based generative models fail in clinical MRI applications because they require hundreds to thousands of expensive neural function evaluations, making real-time reconstruction infeasible. Furthermore, existing methods often treat image frames independently, lacking the autoregressive structure necessary to maintain temporal consistency in dynamic sequences. We identify a critical gap where the need for high-fidelity posterior sampling clashes with the computational inefficiency of standard stochastic sampling techniques and the lack of sequence-aware modeling.\nÂàõÊñ∞ÁÇπ: Our solution introduces Autoregressive Image Diffusion (AID), which leverages the semilinear structure of diffusion processes to enable efficient, high-fidelity sequence generation. We implement the Diffusion Exponential Integrator Sampler (DEIS) as the core engine to discretize the probability flow ODE, minimizing discretization error and drastically reducing the number of required steps. This approach transforms the sampling process from a slow stochastic walk into a rapid, deterministic trajectory that respects the autoregressive nature of the data. By modifying the score network parameterization, we ensure that the model not only generates sharp images but also maintains temporal coherence across the sequence, all while adhering to the physical constraints of the MRI measurements.\n\n„ÄêPattern Idea„Äë\nÂêçÁß∞: Reframing Inverse Problems with Diffusion\nÈóÆÈ¢ò: Ëß£ÂÜ≥ÈÄÜÈóÆÈ¢òÔºåÈáçÁÇπÊòØÂ¶Ç‰ΩïÂú®‰∏çÈíàÂØπÁâπÂÆö‰ªªÂä°È¢ùÂ§ñËÆ≠ÁªÉÁöÑÊÉÖÂÜµ‰∏ãÔºåÂà©Áî®ÈÄöÁî®È¢ÑËÆ≠ÁªÉÊâ©Êï£Ê®°ÂûãÂÆûÁé∞È´òË¥®ÈáèÈáçÂª∫„ÄÇ\nÂÅáËÆæ: ÂÅáËÆæÂèØÁõ¥Êé•‰ªéÊµãÈáèÊ®°Âûã‰º∞ËÆ°Êù°‰ª∂ÂàÜÊï∞Ôºå‰∏îÈÄöËøáËÅîÂêàÂª∫Ê®°‰ø°Âè∑‰∏éÂô™Â£∞ÂàÜÂ∏ÉÁöÑÂàÜÊï∞ÔºåËÉΩÊúâÊïàÂºïÂØºÊâ©Êï£ËøáÁ®ãÊ±ÇËß£ÈÄÜÈóÆÈ¢ò„ÄÇ\nÂàõÊñ∞ÁÇπ: ÊèêÂá∫‰∫Ü‰º™ÈÄÜÂºïÂØºÊâ©Êï£Ê®°Âûã(Œ†GDM)ÔºåÊó†ÈúÄÈ¢ùÂ§ñËÆ≠ÁªÉÂç≥ÂèØÂ§çÁî®ÈÄöÁî®Ê®°ÂûãÔºåÂπ∂ÂºïÂÖ•ËÅîÂêàÊù°‰ª∂ÂèçÂêëÊâ©Êï£ËøáÁ®ã‰ª•ÊèêÂçáÈáçÂª∫ÊÄßËÉΩ„ÄÇ\n\nËØ∑ÂàÜÊûê‰ª•‰∏ãÂá†ÁÇπÔºàÊØèÁÇπ50-100Â≠óÔºâÔºö\n\n1. „ÄêÈóÆÈ¢òÁ©∫Èó¥‰∫íË°•„ÄëPattern Â¶Ç‰ΩïËÉΩË°•ÂÖÖÊàñÊâ©Â±ï User Idea ÁöÑÈóÆÈ¢òÂÆö‰πâÔºü\n2. „ÄêÂÅáËÆæÁ©∫Èó¥‰∫§ÈõÜ„Äë‰∏§ËÄÖÊòØÂê¶Âü∫‰∫éÁõ∏‰ººÁöÑÈóÆÈ¢òËßÇÂØü‰ΩÜÈááÁî®‰∫Ü‰∏çÂêåÁöÑËß£ÂÜ≥ËßíÂ∫¶Ôºü\n3. „ÄêÂàõÊñ∞ÁÇπ‰πòÁßØ„ÄëÁªìÂêà‰∏§ËÄÖÁöÑÂàõÊñ∞ÁÇπÔºåËÉΩÂê¶‰∫ßÁîü1+1>2ÁöÑÊñ∞ÊÉ≥Ê≥ïÔºü\n4. „ÄêÂÖ≥ÈîÆËûçÂêàÊú∫Âà∂„ÄëÂÖ∑‰ΩìÂ¶Ç‰ΩïÂ∞Ü Pattern ÁöÑÊñπÊ≥ïËûçÂÖ• User Idea ‰∏≠Ôºå‰ΩøÂÖ∂Êàê‰∏∫ÊúâÊú∫Êï¥‰ΩìËÄåÈùûÊú∫Ê¢∞ÊãºÊé•Ôºü\n\n‰ª• JSON Ê†ºÂºèËøîÂõûÔºö\n{\n  \"problem_complement\": \"...\",\n  \"assumption_intersection\": \"...\",\n  \"innovation_product\": \"...\",\n  \"fusion_mechanism\": \"...\"\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 2623}, "response": {"ok": true, "text": "```json\n{\n  \"problem_complement\": \"User Idea‰æßÈáçÂä®ÊÄÅMRIÁöÑÊó∂ÊïàÊÄß‰∏é‰∏ÄËá¥ÊÄßÔºåPattern IdeaÂàôÊèê‰æõÂà©Áî®ÈÄöÁî®Ê®°ÂûãÊó†ÈúÄÁâπÂÆöËÆ≠ÁªÉÁöÑËßÜËßí„ÄÇPattern IdeaÂèØÊâ©Â±ïUser IdeaÁöÑÂÆö‰πâÔºåÂºïÂÖ•Â¶Ç‰ΩïÂà©Áî®Â§ßËßÑÊ®°È¢ÑËÆ≠ÁªÉÂÖàÈ™åËÄåÊó†ÈúÄÈáçËÆ≠Ê®°ÂûãÔºåËß£ÂÜ≥Êï∞ÊçÆÁ®ÄÁº∫ÊàñÊ≥õÂåñÈóÆÈ¢ò„ÄÇ\",\n  \"assumption_intersection\": \"‰∏§ËÄÖÈÉΩÂÅáËÆæÊâ©Êï£Ê®°ÂûãÁöÑÂàÜÊï∞ÂáΩÊï∞ÊòØËß£ÂÜ≥MRIÈÄÜÈóÆÈ¢òÁöÑÂÖ≥ÈîÆ„ÄÇUserÂÅáËÆæÈúÄËá™ÂõûÂΩíÁªìÊûÑ‰øùÊåÅÊó∂Èó¥‰∏ÄËá¥ÊÄßÔºåPatternÂÅáËÆæÂèØÂà©Áî®È¢ÑËÆ≠ÁªÉÂàÜÊï∞‰º∞ËÆ°„ÄÇ‰∫§ÈõÜÂú®‰∫éÔºöÈÉΩËÆ§‰∏∫ÈÄöËøáÊìçÁ∫µÊâ©Êï£ËøáÁ®ãÊàñÂàÜÊï∞‰º∞ËÆ°ÔºåËÉΩÂú®Áâ©ÁêÜÁ∫¶Êùü‰∏ãÂæóÂà∞È´ò‰øùÁúüÂêéÈ™åÈááÊ†∑„ÄÇ\",\n  \"innovation_product\": \"ÁªìÂêàDEISÁöÑÈ´òÊïàÈááÊ†∑‰∏éŒ†GDMÁöÑÊó†ËÆ≠ÁªÉÂºïÂØºÊú∫Âà∂„ÄÇÊñ∞ÊÉ≥Ê≥ïÂèØËÉΩÊòØÔºöÂà©Áî®ÈÄöÁî®È¢ÑËÆ≠ÁªÉÊâ©Êï£Ê®°Âûã‰Ωú‰∏∫ÂÖàÈ™åÔºåÈÄöËøá‰øÆÊîπÁöÑDEISÂø´ÈÄüÊ±ÇËß£‰º™ÈÄÜÂºïÂØºÁöÑODEÔºåÊó¢ÂÆûÁé∞‰∫ÜÊó†ÈúÄÁâπÂÆö‰ªªÂä°ËÆ≠ÁªÉÁöÑÂä®ÊÄÅMRIÈáçÂª∫ÔºåÂèà‰øùËØÅ‰∫ÜÂÆûÊó∂ÊÄßÂíåÊó∂Èó¥ËøûË¥ØÊÄß„ÄÇ\",\n  \"fusion_mechanism\": \"Â∞ÜŒ†GDMÁöÑ‰º™ÈÄÜÂºïÂØº‰Ωú‰∏∫Êù°‰ª∂ËûçÂÖ•UserÁöÑAIDÊ°ÜÊû∂‰∏≠„ÄÇ‰ΩøÁî®È¢ÑËÆ≠ÁªÉËßÜÈ¢ëÊâ©Êï£Ê®°ÂûãÊõø‰ª£‰∏ìÁî®Ê®°ÂûãÔºåÂà©Áî®DEISÂä†ÈÄüŒ†GDMÁöÑÊ±ÇËß£ËøáÁ®ã„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÂú®ÊØè‰∏ÄÊ≠•DEISËø≠‰ª£‰∏≠ÔºåÁªìÂêà‰∏ä‰∏ÄÂ∏ßÈöêÁä∂ÊÄÅ‰∏éMRIÊµãÈáèÂÄºÁöÑ‰º™ÈÄÜÊù•‰øÆÊ≠£ÂàÜÊï∞ÔºåÂÆûÁé∞Èõ∂Ê†∑Êú¨ÁöÑÈ´òÈÄüÂä®ÊÄÅÈáçÂª∫„ÄÇ\"\n}\n```", "latency_ms": 29056, "text_truncated": false, "text_len": 576}}}
{"ts": "2026-01-29T11:08:46.851446+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.9, "max_tokens": 1500, "timeout": 180, "prompt": "\nBased on the following analysis, generate a truly innovative fused idea (NOT a simple A+B combination).\n\n„ÄêOriginal User Idea„Äë\nPropose the autoregressive image diffusion (AID) model for image sequence generation and apply it to sample the posterior for accelerated MRI reconstruction\n\n„ÄêUser Idea DNA„Äë\n- Problem: We reframe accelerated MRI reconstruction from a simple static inverse problem to a complex task of dynamic temporal sequence generation requiring precise posterior sampling. Traditional methods often overlook the intricate temporal correlations inherent in dynamic MRI or rely on optimization strategies that fail to capture the full distribution of plausible solutions. By treating the reconstruction as an autoregressive image diffusion process, we transform the challenge into generating coherent, high-fidelity sequences that effectively sample the true posterior distribution defined by the physics of MRI acquisition.\n- Assumption: Current diffusion-based generative models fail in clinical MRI applications because they require hundreds to thousands of expensive neural function evaluations, making real-time reconstruction infeasible. Furthermore, existing methods often treat image frames independently, lacking the autoregressive structure necessary to maintain temporal consistency in dynamic sequences. We identify a critical gap where the need for high-fidelity posterior sampling clashes with the computational inefficiency of standard stochastic sampling techniques and the lack of sequence-aware modeling.\n- Innovation: Our solution introduces Autoregressive Image Diffusion (AID), which leverages the semilinear structure of diffusion processes to enable efficient, high-fidelity sequence generation. We implement the Diffusion Exponential Integrator Sampler (DEIS) as the core engine to discretize the probability flow ODE, minimizing discretization error and drastically reducing the number of required steps. This approach transforms the sampling process from a slow stochastic walk into a rapid, deterministic trajectory that respects the autoregressive nature of the data. By modifying the score network parameterization, we ensure that the model not only generates sharp images but also maintains temporal coherence across the sequence, all while adhering to the physical constraints of the MRI measurements.\n\n„ÄêPattern: Reframing Inverse Problems with Diffusion„Äë\n- Problem: Ëß£ÂÜ≥ÈÄÜÈóÆÈ¢òÔºåÈáçÁÇπÊòØÂ¶Ç‰ΩïÂú®‰∏çÈíàÂØπÁâπÂÆö‰ªªÂä°È¢ùÂ§ñËÆ≠ÁªÉÁöÑÊÉÖÂÜµ‰∏ãÔºåÂà©Áî®ÈÄöÁî®È¢ÑËÆ≠ÁªÉÊâ©Êï£Ê®°ÂûãÂÆûÁé∞È´òË¥®ÈáèÈáçÂª∫„ÄÇ\n- Assumption: ÂÅáËÆæÂèØÁõ¥Êé•‰ªéÊµãÈáèÊ®°Âûã‰º∞ËÆ°Êù°‰ª∂ÂàÜÊï∞Ôºå‰∏îÈÄöËøáËÅîÂêàÂª∫Ê®°‰ø°Âè∑‰∏éÂô™Â£∞ÂàÜÂ∏ÉÁöÑÂàÜÊï∞ÔºåËÉΩÊúâÊïàÂºïÂØºÊâ©Êï£ËøáÁ®ãÊ±ÇËß£ÈÄÜÈóÆÈ¢ò„ÄÇ\n- Innovation: ÊèêÂá∫‰∫Ü‰º™ÈÄÜÂºïÂØºÊâ©Êï£Ê®°Âûã(Œ†GDM)ÔºåÊó†ÈúÄÈ¢ùÂ§ñËÆ≠ÁªÉÂç≥ÂèØÂ§çÁî®ÈÄöÁî®Ê®°ÂûãÔºåÂπ∂ÂºïÂÖ•ËÅîÂêàÊù°‰ª∂ÂèçÂêëÊâ©Êï£ËøáÁ®ã‰ª•ÊèêÂçáÈáçÂª∫ÊÄßËÉΩ„ÄÇ\n\n„ÄêFusion Analysis„Äë\n- Problem Complement: User Idea‰æßÈáçÂä®ÊÄÅMRIÁöÑÊó∂ÊïàÊÄß‰∏é‰∏ÄËá¥ÊÄßÔºåPattern IdeaÂàôÊèê‰æõÂà©Áî®ÈÄöÁî®Ê®°ÂûãÊó†ÈúÄÁâπÂÆöËÆ≠ÁªÉÁöÑËßÜËßí„ÄÇPattern IdeaÂèØÊâ©Â±ïUser IdeaÁöÑÂÆö‰πâÔºåÂºïÂÖ•Â¶Ç‰ΩïÂà©Áî®Â§ßËßÑÊ®°È¢ÑËÆ≠ÁªÉÂÖàÈ™åËÄåÊó†ÈúÄÈáçËÆ≠Ê®°ÂûãÔºåËß£ÂÜ≥Êï∞ÊçÆÁ®ÄÁº∫ÊàñÊ≥õÂåñÈóÆÈ¢ò„ÄÇ\n- Assumption Intersection: ‰∏§ËÄÖÈÉΩÂÅáËÆæÊâ©Êï£Ê®°ÂûãÁöÑÂàÜÊï∞ÂáΩÊï∞ÊòØËß£ÂÜ≥MRIÈÄÜÈóÆÈ¢òÁöÑÂÖ≥ÈîÆ„ÄÇUserÂÅáËÆæÈúÄËá™ÂõûÂΩíÁªìÊûÑ‰øùÊåÅÊó∂Èó¥‰∏ÄËá¥ÊÄßÔºåPatternÂÅáËÆæÂèØÂà©Áî®È¢ÑËÆ≠ÁªÉÂàÜÊï∞‰º∞ËÆ°„ÄÇ‰∫§ÈõÜÂú®‰∫éÔºöÈÉΩËÆ§‰∏∫ÈÄöËøáÊìçÁ∫µÊâ©Êï£ËøáÁ®ãÊàñÂàÜÊï∞‰º∞ËÆ°ÔºåËÉΩÂú®Áâ©ÁêÜÁ∫¶Êùü‰∏ãÂæóÂà∞È´ò‰øùÁúüÂêéÈ™åÈááÊ†∑„ÄÇ\n- Innovation Product: ÁªìÂêàDEISÁöÑÈ´òÊïàÈááÊ†∑‰∏éŒ†GDMÁöÑÊó†ËÆ≠ÁªÉÂºïÂØºÊú∫Âà∂„ÄÇÊñ∞ÊÉ≥Ê≥ïÂèØËÉΩÊòØÔºöÂà©Áî®ÈÄöÁî®È¢ÑËÆ≠ÁªÉÊâ©Êï£Ê®°Âûã‰Ωú‰∏∫ÂÖàÈ™åÔºåÈÄöËøá‰øÆÊîπÁöÑDEISÂø´ÈÄüÊ±ÇËß£‰º™ÈÄÜÂºïÂØºÁöÑODEÔºåÊó¢ÂÆûÁé∞‰∫ÜÊó†ÈúÄÁâπÂÆö‰ªªÂä°ËÆ≠ÁªÉÁöÑÂä®ÊÄÅMRIÈáçÂª∫ÔºåÂèà‰øùËØÅ‰∫ÜÂÆûÊó∂ÊÄßÂíåÊó∂Èó¥ËøûË¥ØÊÄß„ÄÇ\n- Fusion Mechanism: Â∞ÜŒ†GDMÁöÑ‰º™ÈÄÜÂºïÂØº‰Ωú‰∏∫Êù°‰ª∂ËûçÂÖ•UserÁöÑAIDÊ°ÜÊû∂‰∏≠„ÄÇ‰ΩøÁî®È¢ÑËÆ≠ÁªÉËßÜÈ¢ëÊâ©Êï£Ê®°ÂûãÊõø‰ª£‰∏ìÁî®Ê®°ÂûãÔºåÂà©Áî®DEISÂä†ÈÄüŒ†GDMÁöÑÊ±ÇËß£ËøáÁ®ã„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÂú®ÊØè‰∏ÄÊ≠•DEISËø≠‰ª£‰∏≠ÔºåÁªìÂêà‰∏ä‰∏ÄÂ∏ßÈöêÁä∂ÊÄÅ‰∏éMRIÊµãÈáèÂÄºÁöÑ‰º™ÈÄÜÊù•‰øÆÊ≠£ÂàÜÊï∞ÔºåÂÆûÁé∞Èõ∂Ê†∑Êú¨ÁöÑÈ´òÈÄüÂä®ÊÄÅÈáçÂª∫„ÄÇ\n\n---\n\n„ÄêGOOD FUSION EXAMPLES - Learn from these„Äë\n\nExample 1: Image Captioning + Contrastive Learning\n‚ùå Bad Fusion: \"Use contrastive learning to improve image captioning by contrasting positive/negative image-caption pairs\"\n‚úÖ Good Fusion: \"Reframe image captioning as a contrastive reasoning task where the model learns to distinguish between visually similar scenes through their semantic differences in natural language descriptions, creating a unified vision-language alignment space rather than treating captioning as a one-way generation task.\"\nWhy Good: Redefines the TASK NATURE from generation to contrastive reasoning, creates conceptual unity.\n\nExample 2: Small Model Compression + Knowledge Distillation\n‚ùå Bad Fusion: \"Apply knowledge distillation to compress small models using teacher-student training\"\n‚úÖ Good Fusion: \"Transform model compression from a post-training reduction process into a knowledge inheritance mechanism, where the student model doesn't just mimic outputs but inherits the teacher's reasoning structure through distillation-guided architecture search, co-evolving capacity and knowledge during compression.\"\nWhy Good: Changes compression from \"reduction\" to \"inheritance\", makes distillation and compression co-evolve.\n\nExample 3: Graph Neural Networks + Attention Mechanism\n‚ùå Bad Fusion: \"Add attention mechanism to GNN to weight neighbor aggregation\"\n‚úÖ Good Fusion: \"Reframe graph neural networks as dynamic attention-driven topology learners, where attention doesn't just weight fixed edges but actively discovers latent relational structures, transforming GNNs from static structure encoders into adaptive structure-content co-learners.\"\nWhy Good: Elevates attention from a \"weighting tool\" to a \"structure discovery mechanism\", unifies topology and content learning.\n\n---\n\nNow generate YOUR fused idea following this quality standard.\n\nReturn JSON format:\n{\n  \"fused_idea_title\": \"A concise title (within 10 words)\",\n  \"fused_idea_description\": \"Brief description of the fused idea (within 150 words)\",\n  \"problem_framing\": \"Reframed problem definition (within 200 words)\",\n  \"core_assumption\": \"Core assumption of the fused idea (within 150 words)\",\n  \"novelty_claim\": \"Innovation claim (within 150 words, highlight what's NEW compared to original ideas)\",\n  \"key_innovation_points\": [\"Innovation point 1\", \"Innovation point 2\", \"Innovation point 3\"],\n  \"why_not_straightforward_combination\": \"Explain why this is NOT a simple A+B combination (within 100 words)\"\n}\n\nKEY REQUIREMENTS:\n1. The new idea should NOT sound like stacking two ideas together\n2. Should innovate in problem redefinition, assumption shift, or perspective transformation\n3. Must clearly explain why this fusion creates NEW insights\n4. Show how the two ideas CO-EVOLVE rather than CO-EXIST\n5. Avoid phrases like \"combine X with Y\" or \"integrate A and B\" - instead use \"reframe\", \"transform\", \"unify\"\n", "simulated": false, "prompt_truncated": false, "prompt_len": 6061}, "response": {"ok": true, "text": "```json\n{\n  \"fused_idea_title\": \"Zero-Shot Physics-Trajectory Synchronized Video Diffusion\",\n  \"fused_idea_description\": \"This approach reframes accelerated MRI reconstruction as synchronizing the generative trajectory of a pre-trained video diffusion model with MRI physical constraints. Instead of training or simple guidance, it utilizes a Pseudo-Inverse Exponential Integrator to dynamically align the video prior's temporal dynamics with k-space measurements in real-time, achieving high-fidelity, zero-shot dynamic reconstruction.\",\n  \"problem_framing\": \"We shift the problem from 'restoring static images' to 'aligning temporal trajectories.' The core challenge is bridging the gap between the generic generative temporal dynamics of pre-trained video models and the specific acquisition dynamics of MRI. This requires a mechanism that harmonizes these two distinct time-scales and manifolds without retraining, effectively transforming a universal video generator into a task-specific MRI emulator through trajectory control.\",\n  \"core_assumption\": \"We assume that the temporal consistency learned by generic video diffusion models is sufficiently universal to approximate physiological dynamics, and that MRI physics constraints can be satisfied not by retraining the network, but by analytically correcting the probability flow ODE's trajectory using the pseudo-inverse in real-time.\",\n  \"novelty_claim\": \"Unlike simply applying guidance to a generic model (Pattern), we integrate the pseudo-inverse directly into the sampler's structure (User) to create a 'Physics-Aware Exponential Integrator.' This transforms the pseudo-inverse from a mere gradient term into a structural component of the ODE solver, allowing the model to 'warp' its generative path to satisfy physics on the fly without extra neural function evaluations.\",\n  \"key_innovation_points\": [\n    \"Trajectory Synchronization: Unifies video generation time-steps and MRI acquisition dynamics via ODE path correction.\",\n    \"Physics-Embedded Integrator: Modifies the DEIS kernel (from User) to analytically include pseudo-inverse guidance (from Pattern), reducing reconstruction to a deterministic trajectory solving problem.\",\n    \"Zero-Shot Temporal Inheritance: Leverages pre-trained video priors for temporal coherence without task-specific training, inheriting dynamic reasoning rather than just pixel textures.\"\n  ],\n  \"why_not_straightforward_combination\": \"This is not A+B because it doesn't just 'use' a pre-trained model with AID's sampler. Instead, it fundamentally alters the sampling mechanics by absorbing the Pattern's pseudo-inverse logic into the User's exponential integrator structure, thereby co-evolving the sampling efficiency and the physics constraint satisfaction into a single unified trajectory control mechanism.\"\n}\n```", "latency_ms": 37462, "text_truncated": false, "text_len": 2820}}}
{"ts": "2026-01-29T11:09:31.862524+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.7, "max_tokens": 1500, "timeout": 180, "prompt": "\nYou are a senior paper author at a top AI conference, skilled in deeply integrating new techniques into existing methods to form innovative technical combinations.\n\n\n„ÄêUser's Original Idea - THE PROTAGONIST„Äë\n\"Propose the autoregressive image diffusion (AID) model for image sequence generation and apply it to sample the posterior for accelerated MRI reconstruction\"\n\nCore Concepts to Preserve: [Identify 2-4 key concepts from the idea above]\n\n\n‚ö†Ô∏è „ÄêCRITICAL: User Idea Protection Rules During Refinement„Äë\nWhen refining, ALWAYS remember:\n1. The user's core idea is \"Propose the autoregressive image diffusion (AID) model for image sequence generation and apply it to sample the posterior for accelerated MRI reconstruction\" - this is the PROTAGONIST of your story\n2. Technical approaches (e.g., RL, neural networks) are IMPLEMENTATION MEANS, not the main characters\n3. Title and abstract MUST always highlight the User Idea's core concepts\n4. Even when injecting new techniques, describe them from the perspective of \"how these techniques implement the User Idea\"\n\n„ÄêCurrent Story Version„Äë\nTitle: Autoregressive Image Diffusion via Exponential Integrators for Efficient Posterior Sampling in Accelerated MRI Reconstruction\nAbstract: Accelerated MRI reconstruction fundamentally requires generating high-fidelity image sequences from undersampled k-space data, a task that demands both precise posterior sampling and computational efficiency. We propose Autoregressive Image Diffusion (AID), a novel generative framework that models the temporal dependencies of dynamic MRI through a sequence-aware diffusion process. To address the prohibitive computational cost typically associated with diffusion sampling in clinical settings, we integrate a Diffusion Exponential Integrator Sampler (DEIS). This approach reframes the sampling trajectory as a semilinear ordinary differential equation (ODE), allowing for significant reduction in function evaluations without sacrificing image quality. By combining the generative strength of autoregressive modeling with the numerical efficiency of exponential integrators, AID achieves rapid, high-quality posterior sampling, effectively bridging the gap between advanced generative theory and practical medical imaging requirements.\nProblem Framing: We reframe accelerated MRI reconstruction from a simple static inverse problem to a complex task of dynamic temporal sequence generation requiring precise posterior sampling. Traditional methods often overlook the intricate temporal correlations inherent in dynamic MRI or rely on optimization strategies that fail to capture the full distribution of plausible solutions. By treating the reconstruction as an autoregressive image diffusion process, we transform the challenge into generating coherent, high-fidelity sequences that effectively sample the true posterior distribution defined by the physics of MRI acquisition.\nGap Pattern: Current diffusion-based generative models fail in clinical MRI applications because they require hundreds to thousands of expensive neural function evaluations, making real-time reconstruction infeasible. Furthermore, existing methods often treat image frames independently, lacking the autoregressive structure necessary to maintain temporal consistency in dynamic sequences. We identify a critical gap where the need for high-fidelity posterior sampling clashes with the computational inefficiency of standard stochastic sampling techniques and the lack of sequence-aware modeling.\nSolution: Our solution introduces Autoregressive Image Diffusion (AID), which leverages the semilinear structure of diffusion processes to enable efficient, high-fidelity sequence generation. We implement the Diffusion Exponential Integrator Sampler (DEIS) as the core engine to discretize the probability flow ODE, minimizing discretization error and drastically reducing the number of required steps. This approach transforms the sampling process from a slow stochastic walk into a rapid, deterministic trajectory that respects the autoregressive nature of the data. By modifying the score network parameterization, we ensure that the model not only generates sharp images but also maintains temporal coherence across the sequence, all while adhering to the physical constraints of the MRI measurements.\nMethod: Construct the Autoregressive Image Diffusion (AID) architecture by factorizing the joint distribution of image sequences into conditional diffusion steps; Formulate the accelerated MRI reconstruction task as a constrained posterior sampling problem within the AID framework; Implement the Diffusion Exponential Integrator Sampler (DEIS) to discretize the probability flow ODE, leveraging the semilinear structure to minimize discretization error across autoregressive steps; Optimize the score network parameterization to support efficient deterministic sampling while maintaining temporal consistency.\nClaims: [\"Transform accelerated MRI reconstruction from static optimization to dynamic Autoregressive Image Diffusion, enabling the generation of temporally coherent image sequences that accurately sample the complex posterior distribution.\", \"Reframe the computationally prohibitive sampling process by integrating the Diffusion Exponential Integrator Sampler (DEIS), which exploits the semilinear structure of diffusion ODEs to drastically reduce neural function evaluations while maintaining fidelity.\", \"Shift the paradigm of posterior sampling by combining autoregressive modeling with exponential integrators, bridging the gap between theoretical generative capabilities and the strict time constraints of clinical MRI workflows.\"]\n\n„ÄêReview Feedback„Äë(Read carefully, preserve well-received parts, deeply revise criticized parts)\n- Reviewer A (Methodology): 6.639999999999902ÂàÜ. ÂèçÈ¶à: Main gaps: Limited theoretical analysis of convergence properties, Unclear generalizability beyond MRI reconstruction, Missing detailed ablation studies for method components. Anchored against 9 papers....\n- Reviewer B (Novelty): 6.459999999999906ÂàÜ. ÂèçÈ¶à: Main gaps: Limited theoretical analysis, Narrow application focus, Potential lack of comprehensive evaluation. Anchored against 9 papers....\n- Reviewer C (Storyteller): 6.469999999999906ÂàÜ. ÂèçÈ¶à: Main gaps: Limited theoretical analysis of convergence properties, Lack of comparison with other exponential integrator methods, Missing evaluation on diverse clinical scenarios. Anchored against 9 papers....\n\n\n\n„Äêüí° CRITICAL: Conceptual Innovation from Idea Fusion„Äë\nTitle: Zero-Shot Physics-Trajectory Synchronized Video Diffusion\nDescription: This approach reframes accelerated MRI reconstruction as synchronizing the generative trajectory of a pre-trained video diffusion model with MRI physical constraints. Instead of training or simple guidance, it utilizes a Pseudo-Inverse Exponential Integrator to dynamically align the video prior's temporal dynamics with k-space measurements in real-time, achieving high-fidelity, zero-shot dynamic reconstruction.\n\nNew Problem Framing: We shift the problem from 'restoring static images' to 'aligning temporal trajectories.' The core challenge is bridging the gap between the generic generative temporal dynamics of pre-trained video models and the specific acquisition dynamics of MRI. This requires a mechanism that harmonizes these two distinct time-scales and manifolds without retraining, effectively transforming a universal video generator into a task-specific MRI emulator through trajectory control.\n\nNew Assumption: We assume that the temporal consistency learned by generic video diffusion models is sufficiently universal to approximate physiological dynamics, and that MRI physics constraints can be satisfied not by retraining the network, but by analytically correcting the probability flow ODE's trajectory using the pseudo-inverse in real-time.\n\nNew Novelty Claim: Unlike simply applying guidance to a generic model (Pattern), we integrate the pseudo-inverse directly into the sampler's structure (User) to create a 'Physics-Aware Exponential Integrator.' This transforms the pseudo-inverse from a mere gradient term into a structural component of the ODE solver, allowing the model to 'warp' its generative path to satisfy physics on the fly without extra neural function evaluations.\n\nWhy This is NOT Simple Combination:\nThis is not A+B because it doesn't just 'use' a pre-trained model with AID's sampler. Instead, it fundamentally alters the sampling mechanics by absorbing the Pattern's pseudo-inverse logic into the User's exponential integrator structure, thereby co-evolving the sampling efficiency and the physics constraint satisfaction into a single unified trajectory control mechanism.\n\nKey Innovation Points:\n  1. Trajectory Synchronization: Unifies video generation time-steps and MRI acquisition dynamics via ODE path correction.\n  2. Physics-Embedded Integrator: Modifies the DEIS kernel (from User) to analytically include pseudo-inverse guidance (from Pattern), reducing reconstruction to a deterministic trajectory solving problem.\n  3. Zero-Shot Temporal Inheritance: Leverages pre-trained video priors for temporal coherence without task-specific training, inheriting dynamic reasoning rather than just pixel textures.\n\n‚ö†Ô∏è CRITICAL: This fused idea represents a conceptual-level innovation, not just a technical combination.\nYour story refinement should reflect THIS NEW CONCEPTUAL INNOVATION in problem_framing, gap_pattern, and innovation_claims.\nThis is the KEY to achieving higher novelty scores - moving from \"combination of techniques\" to \"new perspective on the problem\".\n\n\n\n\n„ÄêÊ†∏ÂøÉ‰ªªÂä°ÔºöÊ¶ÇÂøµÁ∫ßÂàõÊñ∞ËûçÂêà„Äë\nËØÑÂÆ°ÊåáÂá∫ÂΩìÂâçÊñπÊ≥ïÁöÑÂàõÊñ∞ÊÄß‰∏çË∂≥„ÄÇËøôËΩÆ‰øÆÊ≠£ÁöÑÂÖ≥ÈîÆÊòØ**Ê¶ÇÂøµÂ±ÇÁöÑÊÄùÊÉ≥ÂàõÊñ∞**ÔºåËÄå‰∏ç‰ªÖ‰ªÖÊòØÊäÄÊúØÂ†ÜÁ†å„ÄÇ\nÂèÇËÄÉ‰ª•‰∏ãËûçÂêàÂêéÁöÑÂàõÊñ∞ÊÉ≥Ê≥ïÔºåÂØπÊï¥‰ΩìËÆ∫ÊñáÁöÑ problem framing„ÄÅgap pattern Âíå innovation claims ËøõË°å**Ê†πÊú¨ÊÄßÈáçÊûÑ**Ôºö\n\n  üîß „ÄêÂàõÊñ∞ËûçÂêà„ÄëZero-Shot Physics-Trajectory Synchronized Video Diffusion\n  üîß „ÄêÊñ∞ÈóÆÈ¢òÂÆö‰πâ„ÄëWe shift the problem from 'restoring static images' to 'aligning temporal trajectories.' The core ch...\n  üîß „ÄêÊñ∞ÂàõÊñ∞‰∏ªÂº†„ÄëUnlike simply applying guidance to a generic model (Pattern), we integrate the pseudo-inverse direct...\n\n„ÄêËûçÂêàÈáçÊûÑË¶ÅÊ±Ç„Äë\n1. **Ê¶ÇÂøµÈáçÊñ∞ÂÆö‰πâ**Ôºö‰∏çË¶Å‰øùÊåÅÊóßÁöÑÈóÆÈ¢òÂÆö‰πâÔºåËÄåÊòØÂü∫‰∫éËûçÂêàÂêéÁöÑÊñ∞ËßÇÁÇπÂÆåÂÖ®ÈáçÊñ∞Ê°ÜÊû∂ÂåñÈóÆÈ¢ò„ÄÇ\n2. **ÂÅáËÆæËΩ¨Âèò**Ôºö‰ΩìÁé∞ËûçÂêàÂêéÁöÑÊ†∏ÂøÉÂÅáËÆæÂ¶Ç‰Ωï‰∏éÂéüÊúâÊñπÊ≥ïÁöÑÂÅáËÆæ‰∏çÂêå„ÄÇ\n3. **ÂàõÊñ∞ÁÇπÂçáÁ∫ß**ÔºöÂú® innovation_claims ‰∏≠ÊòéÁ°ÆÊåáÂá∫ËøôÊòØ\"Ê¶ÇÂøµÁ∫ßÁöÑÂàõÊñ∞\"ËÄåÈùû\"ÊäÄÊúØÁ∫ßÁöÑÁªÑÂêà\"„ÄÇ\n\n\n„ÄêÈíàÂØπÂàõÊñ∞ÊÄßÈóÆÈ¢òÁöÑÁâπÂà´ÊåáÂØº„Äë\nÂΩìÂâçÊñπÊ≥ïË¢´ËØÑÂÆ°ËÆ§‰∏∫\"ÂàõÊñ∞ÊÄß‰∏çË∂≥\"Êàñ\"ÊäÄÊúØÁªÑÂêàÂ∏∏ËßÅ\"„ÄÇ‰Ω†ÈúÄË¶ÅÔºö\n1. Âú® method_skeleton ‰∏≠ÔºåÁ™ÅÂá∫Êñ∞Ê≥®ÂÖ•ÊäÄÊúØÁöÑ**Áã¨ÁâπÂ∫îÁî®ÊñπÂºè**ÔºåÂΩ¢Êàê‰∏é‰ºó‰∏çÂêåÁöÑÊäÄÊúØË∑ØÁ∫ø„ÄÇ\n2. Âú® innovation_claims ‰∏≠ÔºåÊòéÁ°ÆÊåáÂá∫‰Ω†ÁöÑÊäÄÊúØÁªÑÂêà‰∏éÁé∞ÊúâÂ∑•‰ΩúÁöÑ**Êú¨Ë¥®Âå∫Âà´**„ÄÇ\n3. ÈÅøÂÖç‰ΩøÁî®\"ÊèêÂçáÊÄßËÉΩ\"„ÄÅ\"Â¢ûÂº∫ÊïàÊûú\"Á≠âÊ≥õÊ≥õËÄåË∞àÁöÑÊèèËø∞ÔºåË¶ÅÂÖ∑‰ΩìËØ¥ÊòéÊäÄÊúØÂàõÊñ∞ÁÇπ„ÄÇ\n\n\n„ÄêPattern Reference„Äë(Use these to enhance technical depth and narrative)\n\nüí° Solution Approaches (add concrete technical steps if needed):\n  1. Develop the Diffusion Exponential Integrator Sampler (DEIS) using an exponential integrator for discretizing ODEs, leveraging the semilinear structure of diffusion processes to minimize discretization error and reduce the number of required steps.\n  2. Modify the score network parameterization in DDIM to extend its applicability to general diffusion models, enabling efficient deterministic sampling.\n  3. Develop quasi-Taylor samplers using numerical schemes based on Taylor expansion, employing an 'ideal derivative substitution' to simplify the computation of higher-order derivatives.\n\nüìñ Story Packaging Strategy (use 'Reframe/Transform' pattern for claims):\n  1. Transform the challenge of slow sampling in diffusion models by reframing it as an opportunity to innovate on numerical methods, introducing a scalable approach that enhances efficiency without sacrificing quality, thus pushing the boundaries of generative modeling capabilities.\n  2. Reframe diffusion model sampling from a stochastic process to a deterministic one by leveraging numerical insights, thus broadening the applicability and efficiency of diffusion models beyond isotropic cases.\n\nRemember: These are TOOLS to implement the User Idea, not the main focus.\n\n\n‚ö†Ô∏è „ÄêHOW TO USE Fused Idea Guidance„Äë\nIf you received „ÄêConceptual Innovation from Idea Fusion„Äë above, this is THE MOST IMPORTANT guidance:\n- **Title & Abstract**: Must reflect the fused conceptual innovation, not just list techniques\n- **Problem Framing**: Adopt the NEW problem perspective from the fused idea\n- **Gap Pattern**: Explain why existing methods lack this conceptual unity\n- **Innovation Claims**: Frame as \"transforming/reframing X from Y to Z\", NOT \"combining A with B\"\n- **Method**: Show how techniques CO-EVOLVE to realize the fu", "simulated": false, "prompt_truncated": true, "prompt_len": 15604}, "response": {"ok": true, "text": "```json\n{\n  \"title\": \"Autoregressive Image Diffusion via Zero-Shot Physics-Trajectory Synchronization for Accelerated MRI Reconstruction\",\n  \"abstract\": \"We propose Autoregressive Image Diffusion (AID), a novel framework for image sequence generation that achieves high-fidelity accelerated MRI reconstruction by sampling the posterior distribution through zero-shot physics-trajectory synchronization. Traditional approaches treat reconstruction as a static inverse problem or require task-specific training, failing to leverage the rich temporal dynamics of pre-trained video priors. We reframe the challenge as aligning the generative trajectory of a video diffusion model with the physical constraints of MRI acquisition in real-time. To achieve this, we introduce the Physics-Aware Exponential Integrator, a mechanism that integrates the MRI pseudo-inverse directly into the kernel of the Diffusion Exponential Integrator Sampler (DEIS). This structural integration transforms the sampling process from a stochastic walk guided by external gradients into a deterministic trajectory alignment, allowing the model to warp its generative path to satisfy k-space measurements without fine-tuning. AID not only preserves the temporal coherence inherent in the video prior but also drastically reduces neural function evaluations, bridging the gap between theoretical generative capabilities and the practical demands of clinical workflows.\",\n  \"problem_framing\": \"We reframe accelerated MRI reconstruction from a static image restoration task to a dynamic problem of temporal trajectory synchronization. The core challenge lies in bridging the gap between the generic temporal dynamics of pre-trained video diffusion models and the specific acquisition physics of MRI. Unlike traditional methods that learn static mappings, we assume that the temporal consistency learned by universal video models is sufficient to approximate physiological dynamics, but requires precise alignment with MRI physics. This shifts the objective from generating pixel-perfect frames to warping the generative ODE trajectory so that it naturally converges to solutions consistent with undersampled k-space data, effectively treating the reconstruction as a trajectory control problem.\",\n  \"gap_pattern\": \"Current diffusion-based methods fail in clinical applications due to a fundamental disconnect between generative priors and physical constraints. Existing approaches either treat frames independently, ignoring temporal correlations, or rely on task-specific training that limits generalizability. Furthermore, standard conditional guidance techniques merely nudge the output, requiring hundreds of expensive function evaluations and failing to guarantee adherence to physics. We identify a critical gap where there is no mechanism to structurally unify the generative time-steps of video models with the physical constraints of MRI, leading to inefficient sampling and poor zero-shot generalization across diverse clinical scenarios.\",\n  \"solution\": \"Our solution introduces Autoregressive Image Diffusion (AID) with a Physics-Aware Exponential Integrator, fundamentally transforming how posterior sampling is performed. Instead of relying on task-specific training, we leverage the autoregressive structure of pre-trained video models and synchronize their trajectory with MRI physics. By integrating the pseudo-inverse of the MRI forward model directly into the exponential integrator's structure, we transform the sampling process into a deterministic trajectory alignment problem. This allows the model to analytically correct its path to satisfy k-space constraints on the fly, eliminating the need for extra neural network evaluations. We effectively warp the universal video prior into a task-specific MRI emulator, achieving rapid, high-fidelity reconstruction that respects both temporal coherence and physical laws.\",\n  \"method_skeleton\": \"Adopt a pre-trained video diffusion model to provide the autoregressive prior, factorizing the joint distribution of image sequences into conditional diffusion steps; Formulate the accelerated MRI reconstruction as a constrained posterior sampling problem where the probability flow ODE is modified to include the MRI physics gradient; Develop a Physics-Aware Exponential Integrator that analytically integrates the pseudo-inverse term into the exponential integration kernel, minimizing discretization error; Perform zero-shot reconstruction by solving the modified ODE, dynamically synchronizing the generative trajectory with k-space measurements without fine-tuning the network weights.\",\n  \"innovation_claims\": [\n    \"Transform accelerated MRI reconstruction from a static inverse problem to a dynamic trajectory synchronization task by aligning the generative time-steps of pre-trained video models with MRI physical constraints.\",\n    \"Reframe constraint satisfaction from an external guidance process to an internal structural component by integrating the pseudo-inverse directly into the exponential integrator, enabling zero-shot posterior sampling with drastic efficiency gains.\",\n    \"Shift the paradigm of medical imaging from task-specific model training to general-purpose trajectory warping, achieving high-fidelity dynamic MRI reconstruction by inheriting temporal reasoning from universal video priors.\"\n  ],\n  \"experiments_plan\": \"We conduct comprehensive evaluations on diverse clinical datasets, including cardiac and abdominal MRI, comparing AID against state-of-the-art diffusion models (DDIM, standard DEIS) and specialized MRI reconstruction networks. We perform detailed ablation studies to validate the Physics-Aware Exponential Integrator, comparing its convergence properties against other exponential integrator methods to demonstrate reduced discretization error. To address theoretical concerns, we provide an analysis of the convergence rate and stability of the synchronized ODE trajectory. Finally, we evaluate generalizability by testing the zero-shot capabilities of the model across different acceleration factors and anatomical regions without retraining.\"\n}\n```", "latency_ms": 43935, "text_truncated": false, "text_len": 6135}}}
{"ts": "2026-01-29T11:10:22.357218+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.3, "max_tokens": 1000, "timeout": 180, "prompt": "\nTranslate the following research paper story from English to Chinese. Keep the translation natural and accurate.\n\nTitle: Autoregressive Image Diffusion via Zero-Shot Physics-Trajectory Synchronization for Accelerated MRI Reconstruction\nAbstract: We propose Autoregressive Image Diffusion (AID), a novel framework for image sequence generation that achieves high-fidelity accelerated MRI reconstruction by sampling the posterior distribution through zero-shot physics-trajectory synchronization. Traditional approaches treat reconstruction as a static inverse problem or require task-specific training, failing to leverage the rich temporal dynamics of pre-trained video priors. We reframe the challenge as aligning the generative trajectory of a video diffusion model with the physical constraints of MRI acquisition in real-time. To achieve this, we introduce the Physics-Aware Exponential Integrator, a mechanism that integrates the MRI pseudo-inverse directly into the kernel of the Diffusion Exponential Integrator Sampler (DEIS). This structural integration transforms the sampling process from a stochastic walk guided by external gradients into a deterministic trajectory alignment, allowing the model to warp its generative path to satisfy k-space measurements without fine-tuning. AID not only preserves the temporal coherence inherent in the video prior but also drastically reduces neural function evaluations, bridging the gap between theoretical generative capabilities and the practical demands of clinical workflows.\nProblem Framing: We reframe accelerated MRI reconstruction from a static image restoration task to a dynamic problem of temporal trajectory synchronization. The core challenge lies in bridging the gap between the generic temporal dynamics of pre-trained video diffusion models and the specific acquisition physics of MRI. Unlike traditional methods that learn static mappings, we assume that the temporal consistency learned by universal video models is sufficient to approximate physiological dynamics, but requires precise alignment with MRI physics. This shifts the objective from generating pixel-perfect frames to warping the generative ODE trajectory so that it naturally converges to solutions consistent with undersampled k-space data, effectively treating the reconstruction as a trajectory control problem.\nGap Pattern: Current diffusion-based methods fail in clinical applications due to a fundamental disconnect between generative priors and physical constraints. Existing approaches either treat frames independently, ignoring temporal correlations, or rely on task-specific training that limits generalizability. Furthermore, standard conditional guidance techniques merely nudge the output, requiring hundreds of expensive function evaluations and failing to guarantee adherence to physics. We identify a critical gap where there is no mechanism to structurally unify the generative time-steps of video models with the physical constraints of MRI, leading to inefficient sampling and poor zero-shot generalization across diverse clinical scenarios.\nSolution: Our solution introduces Autoregressive Image Diffusion (AID) with a Physics-Aware Exponential Integrator, fundamentally transforming how posterior sampling is performed. Instead of relying on task-specific training, we leverage the autoregressive structure of pre-trained video models and synchronize their trajectory with MRI physics. By integrating the pseudo-inverse of the MRI forward model directly into the exponential integrator's structure, we transform the sampling process into a deterministic trajectory alignment problem. This allows the model to analytically correct its path to satisfy k-space constraints on the fly, eliminating the need for extra neural network evaluations. We effectively warp the universal video prior into a task-specific MRI emulator, achieving rapid, high-fidelity reconstruction that respects both temporal coherence and physical laws.\nMethod Skeleton: Adopt a pre-trained video diffusion model to provide the autoregressive prior, factorizing the joint distribution of image sequences into conditional diffusion steps; Formulate the accelerated MRI reconstruction as a constrained posterior sampling problem where the probability flow ODE is modified to include the MRI physics gradient; Develop a Physics-Aware Exponential Integrator that analytically integrates the pseudo-inverse term into the exponential integration kernel, minimizing discretization error; Perform zero-shot reconstruction by solving the modified ODE, dynamically synchronizing the generative trajectory with k-space measurements without fine-tuning the network weights.\nInnovation Claims:\n- Transform accelerated MRI reconstruction from a static inverse problem to a dynamic trajectory synchronization task by aligning the generative time-steps of pre-trained video models with MRI physical constraints.\n- Reframe constraint satisfaction from an external guidance process to an internal structural component by integrating the pseudo-inverse directly into the exponential integrator, enabling zero-shot posterior sampling with drastic efficiency gains.\n- Shift the paradigm of medical imaging from task-specific model training to general-purpose trajectory warping, achieving high-fidelity dynamic MRI reconstruction by inheriting temporal reasoning from universal video priors.\nExperiments Plan: We conduct comprehensive evaluations on diverse clinical datasets, including cardiac and abdominal MRI, comparing AID against state-of-the-art diffusion models (DDIM, standard DEIS) and specialized MRI reconstruction networks. We perform detailed ablation studies to validate the Physics-Aware Exponential Integrator, comparing its convergence properties against other exponential integrator methods to demonstrate reduced discretization error. To address theoretical concerns, we provide an analysis of the convergence rate and stability of the synchronized ODE trajectory. Finally, we evaluate generalizability by testing the zero-shot capabilities of the model across different acceleration factors and anatomical regions without retraining.\n\nOutput ONLY a JSON format (no other text):\n{\n  \"title\": \"...\",\n  \"abstract\": \"...\",\n  \"problem_framing\": \"...\",\n  \"gap_pattern\": \"...\",\n  \"solution\": \"...\",\n  \"method_skeleton\": \"...\",\n  \"innovation_claims\": [\"...\", \"...\", \"...\"],\n  \"experiments_plan\": \"...\"\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 6424}, "response": {"ok": true, "text": "```json\n{\n  \"title\": \"Âü∫‰∫éÈõ∂Ê†∑Êú¨Áâ©ÁêÜ-ËΩ®ËøπÂêåÊ≠•ÁöÑËá™ÂõûÂΩíÂõæÂÉèÊâ©Êï£Âä†ÈÄüMRIÈáçÂª∫\",\n  \"abstract\": \"Êàë‰ª¨ÊèêÂá∫‰∫ÜËá™ÂõûÂΩíÂõæÂÉèÊâ©Êï£ÔºàAIDÔºâÔºåËøôÊòØ‰∏Ä‰∏™Áî®‰∫éÂõæÂÉèÂ∫èÂàóÁîüÊàêÁöÑÊñ∞È¢ñÊ°ÜÊû∂ÔºåÂÆÉÈÄöËøáÈõ∂Ê†∑Êú¨Áâ©ÁêÜ-ËΩ®ËøπÂêåÊ≠•ÂØπÂêéÈ™åÂàÜÂ∏ÉËøõË°åÈááÊ†∑Ôºå‰ªéËÄåÂÆûÁé∞È´ò‰øùÁúüÁöÑÂä†ÈÄüMRIÈáçÂª∫„ÄÇ‰º†ÁªüÊñπÊ≥ïÂ∞ÜÈáçÂª∫ËßÜ‰∏∫ÈùôÊÄÅÈÄÜÈóÆÈ¢òÊàñÈúÄË¶ÅÁâπÂÆö‰ªªÂä°ËÆ≠ÁªÉÔºåÊó†Ê≥ïÂà©Áî®È¢ÑËÆ≠ÁªÉËßÜÈ¢ëÂÖàÈ™å‰∏≠‰∏∞ÂØåÁöÑÊó∂Â∫èÂä®ÊÄÅ„ÄÇÊàë‰ª¨Â∞ÜËøô‰∏ÄÊåëÊàòÈáçÊñ∞ÊûÑÊû∂‰∏∫Â∞ÜËßÜÈ¢ëÊâ©Êï£Ê®°ÂûãÁöÑÁîüÊàêËΩ®Ëøπ‰∏éMRIÈááÈõÜÁöÑÁâ©ÁêÜÁ∫¶ÊùüËøõË°åÂÆûÊó∂ÂØπÈΩê„ÄÇ‰∏∫ÂÆûÁé∞Ëøô‰∏ÄÁõÆÊ†áÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜÁâ©ÁêÜÊÑüÁü•ÊåáÊï∞ÁßØÂàÜÂô®ÔºåËØ•Êú∫Âà∂Â∞ÜMRI‰º™ÈÄÜÁõ¥Êé•ÈõÜÊàêÂà∞Êâ©Êï£ÊåáÊï∞ÁßØÂàÜÈááÊ†∑Âô®ÔºàDEISÔºâÁöÑÊ†∏‰∏≠„ÄÇËøôÁßçÁªìÊûÑÊÄßÈõÜÊàêÂ∞ÜÈááÊ†∑ËøáÁ®ã‰ªéÁî±Â§ñÈÉ®Ê¢ØÂ∫¶ÂºïÂØºÁöÑÈöèÊú∫Ê∏∏Ëµ∞ËΩ¨Âèò‰∏∫Á°ÆÂÆöÊÄßËΩ®ËøπÂØπÈΩêÔºå‰ΩøÊ®°ÂûãËÉΩÂ§üË∞ÉÊï¥ÂÖ∂ÁîüÊàêË∑ØÂæÑ‰ª•Êª°Ë∂≥kÁ©∫Èó¥ÊµãÈáèÔºåËÄåÊó†ÈúÄÂæÆË∞É„ÄÇAID‰∏ç‰ªÖ‰øùÁïô‰∫ÜËßÜÈ¢ëÂÖàÈ™å‰∏≠Âõ∫ÊúâÁöÑÊó∂Â∫èÁõ∏Âπ≤ÊÄßÔºåËøòÂ§ßÂπÖÂáèÂ∞ë‰∫ÜÁ•ûÁªèÂáΩÊï∞ËØÑ‰º∞ÔºåÊû∂Ëµ∑‰∫ÜÁêÜËÆ∫ÁîüÊàêËÉΩÂäõ‰∏é‰∏¥Â∫äÂ∑•‰ΩúÊµÅÂÆûÈôÖÈúÄÊ±Ç‰πãÈó¥ÁöÑÊ°•Ê¢Å„ÄÇ\",\n  \"problem_framing\": \"Êàë‰ª¨Â∞ÜÂä†ÈÄüMRIÈáçÂª∫‰ªéÈùôÊÄÅÂõæÂÉèÊÅ¢Â§ç‰ªªÂä°ÈáçÊñ∞ÊûÑÊû∂‰∏∫Êó∂Â∫èËΩ®ËøπÂêåÊ≠•ÁöÑÂä®ÊÄÅÈóÆÈ¢ò„ÄÇÊ†∏ÂøÉÊåëÊàòÂú®‰∫éÂº•ÂêàÈ¢ÑËÆ≠ÁªÉËßÜÈ¢ëÊâ©Êï£Ê®°ÂûãÁöÑÈÄöÁî®Êó∂Â∫èÂä®ÊÄÅ‰∏éMRIÁâπÂÆöÈááÈõÜÁâ©ÁêÜ‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇ‰∏éÂ≠¶‰π†ÈùôÊÄÅÊò†Â∞ÑÁöÑ‰º†ÁªüÊñπÊ≥ï‰∏çÂêåÔºåÊàë‰ª¨ÂÅáËÆæÈÄöÁî®ËßÜÈ¢ëÊ®°ÂûãÂ≠¶‰π†Âà∞ÁöÑÊó∂Â∫è‰∏ÄËá¥ÊÄßË∂≥‰ª•Ëøë‰ººÁîüÁêÜÂä®ÊÄÅÔºå‰ΩÜÈúÄË¶Å‰∏éMRIÁâ©ÁêÜËøõË°åÁ≤æÁ°ÆÂØπÈΩê„ÄÇËøôÂ∞ÜÁõÆÊ†á‰ªéÁîüÊàêÂÉèÁ¥†ÂÆåÁæéÁöÑÂ∏ßËΩ¨Âèò‰∏∫Ë∞ÉÊï¥ÁîüÊàêODEËΩ®ËøπÔºå‰ΩøÂÖ∂Ëá™ÁÑ∂Êî∂ÊïõÂà∞‰∏éÊ¨†ÈááÊ†∑kÁ©∫Èó¥Êï∞ÊçÆ‰∏ÄËá¥ÁöÑËß£Ôºå‰ªéËÄåÊúâÊïàÂú∞Â∞ÜÈáçÂª∫ËßÜ‰∏∫ËΩ®ËøπÊéßÂà∂ÈóÆÈ¢ò„ÄÇ\",\n  \"gap_pattern\": \"ÂΩìÂâçÁöÑÂü∫‰∫éÊâ©Êï£ÁöÑÊñπÊ≥ïÂú®‰∏¥Â∫äÂ∫îÁî®‰∏≠Â§±Ë¥•ÔºåÂΩíÂõ†‰∫éÁîüÊàêÂÖàÈ™å‰∏éÁâ©ÁêÜÁ∫¶Êùü‰πãÈó¥Â≠òÂú®Ê†πÊú¨ÊÄßÁöÑËÑ±ËäÇ„ÄÇÁé∞ÊúâÊñπÊ≥ïË¶Å‰πàÁã¨Á´ãÂ§ÑÁêÜÂ∏ßÔºåÂøΩÁï•Êó∂Â∫èÁõ∏ÂÖ≥ÊÄßÔºåË¶Å‰πà‰æùËµñÈôêÂà∂Ê≥õÂåñËÉΩÂäõÁöÑÁâπÂÆö‰ªªÂä°ËÆ≠ÁªÉ„ÄÇÊ≠§Â§ñÔºåÊ†áÂáÜÁöÑÊù°‰ª∂ÂºïÂØºÊäÄÊúØÂè™ÊòØÂæÆË∞ÉËæìÂá∫ÔºåÈúÄË¶ÅÊï∞ÁôæÊ¨°ÊòÇË¥µÁöÑÂáΩÊï∞ËØÑ‰º∞Ôºå‰∏îÊó†Ê≥ï‰øùËØÅÈÅµÂÆàÁâ©ÁêÜËßÑÂæã„ÄÇÊàë‰ª¨ÂèëÁé∞‰∫Ü‰∏Ä‰∏™ÂÖ≥ÈîÆÁ©∫ÁôΩÔºåÂç≥Áº∫‰πè‰∏ÄÁßçÊú∫Âà∂Êù•ÁªìÊûÑÊÄßÂú∞Áªü‰∏ÄËßÜÈ¢ëÊ®°ÂûãÁöÑÁîüÊàêÊó∂Èó¥Ê≠•‰∏éMRIÁöÑÁâ©ÁêÜÁ∫¶ÊùüÔºåÂØºËá¥Âú®‰∏çÂêå‰∏¥Â∫äÂú∫ÊôØ‰∏ãÁöÑÈááÊ†∑ÊïàÁéá‰Ωé‰∏ã‰∏îÈõ∂Ê†∑Êú¨Ê≥õÂåñËÉΩÂäõÂ∑Æ„ÄÇ\",\n  \"solution\": \"Êàë‰ª¨ÁöÑËß£ÂÜ≥ÊñπÊ°àÂºïÂÖ•‰∫ÜÂ∏¶ÊúâÁâ©ÁêÜÊÑüÁü•ÊåáÊï∞ÁßØÂàÜÂô®ÁöÑËá™ÂõûÂΩíÂõæÂÉèÊâ©Êï£ÔºàAIDÔºâÔºå‰ªéÊ†πÊú¨‰∏äÊîπÂèò‰∫ÜÂêéÈ™åÈááÊ†∑ÁöÑÊâßË°åÊñπÂºè„ÄÇÊàë‰ª¨‰∏ç‰æùËµñÁâπÂÆö‰ªªÂä°ËÆ≠ÁªÉÔºåËÄåÊòØÂà©Áî®È¢ÑËÆ≠ÁªÉËßÜÈ¢ëÊ®°ÂûãÁöÑËá™ÂõûÂΩíÁªìÊûÑÔºåÂπ∂Â∞ÜÂÖ∂ËΩ®Ëøπ‰∏éMRIÁâ©ÁêÜÂêåÊ≠•„ÄÇÈÄöËøáÂ∞ÜMRIÂâçÂêëÊ®°ÂûãÁöÑ‰º™ÈÄÜÁõ¥Êé•ÈõÜÊàêÂà∞ÊåáÊï∞ÁßØÂàÜÂô®ÁöÑÁªìÊûÑ‰∏≠ÔºåÊàë‰ª¨Â∞ÜÈááÊ†∑ËøáÁ®ãËΩ¨Âåñ‰∏∫Á°ÆÂÆöÊÄßËΩ®ËøπÂØπÈΩêÈóÆÈ¢ò„ÄÇËøô‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÂç≥Êó∂Ëß£ÊûêÂú∞Ê†°Ê≠£ÂÖ∂Ë∑ØÂæÑ‰ª•Êª°Ë∂≥kÁ©∫Èó¥Á∫¶ÊùüÔºåÊ∂àÈô§‰∫ÜÈ¢ùÂ§ñÁöÑÁ•ûÁªèÁΩëÁªúËØÑ‰º∞ÈúÄÊ±Ç„ÄÇÊàë‰ª¨ÊúâÊïàÂú∞Â∞ÜÈÄöÁî®ËßÜÈ¢ëÂÖàÈ™åË∞ÉÊï¥‰∏∫ÁâπÂÆö‰ªªÂä°ÁöÑMRIÊ®°ÊãüÂô®ÔºåÂÆûÁé∞‰∫ÜÊó¢Â∞äÈáçÊó∂Â∫èÁõ∏Âπ≤ÊÄßÂèàÈÅµÂÆàÁâ©ÁêÜÂÆöÂæãÁöÑÂø´ÈÄü„ÄÅÈ´ò‰øùÁúüÈáçÂª∫„ÄÇ\",\n  \"method_skeleton\": \"ÈááÁî®È¢ÑËÆ≠ÁªÉÁöÑËßÜÈ¢ëÊâ©Êï£Ê®°ÂûãÊèê‰æõËá™ÂõûÂΩíÂÖàÈ™åÔºåÂ∞ÜÂõæÂÉèÂ∫èÂàóÁöÑËÅîÂêàÂàÜÂ∏ÉÂàÜËß£‰∏∫Êù°‰ª∂Êâ©Êï£Ê≠•È™§ÔºõÂ∞ÜÂä†ÈÄüMRIÈáçÂª∫Ë°®Ëø∞‰∏∫Á∫¶ÊùüÂêéÈ™åÈááÊ†∑ÈóÆÈ¢òÔºåÂÖ∂‰∏≠‰øÆÊîπÊ¶ÇÁéáÊµÅODE‰ª•ÂåÖÂê´MRIÁâ©ÁêÜÊ¢ØÂ∫¶ÔºõÂºÄÂèëÁâ©ÁêÜÊÑüÁü•ÊåáÊï∞ÁßØÂàÜÂô®ÔºåÂ∞Ü‰º™ÈÄÜÈ°πËß£ÊûêÂú∞ÈõÜÊàêÂà∞ÊåáÊï∞ÁßØÂàÜÊ†∏‰∏≠ÔºåÊúÄÂ∞èÂåñÁ¶ªÊï£ÂåñËØØÂ∑ÆÔºõÈÄöËøáÊ±ÇËß£‰øÆÊîπÂêéÁöÑODEÊâßË°åÈõ∂Ê†∑Êú¨ÈáçÂª∫ÔºåÂä®ÊÄÅÂêåÊ≠•ÁîüÊàêËΩ®Ëøπ‰∏ékÁ©∫Èó¥ÊµãÈáèÔºåËÄåÊó†ÈúÄÂæÆË∞ÉÁΩëÁªúÊùÉÈáç„ÄÇ\",\n  \"innovation_claims\": [\n    \"ÈÄöËøáÂ∞ÜÈ¢ÑËÆ≠ÁªÉËßÜÈ¢ëÊ®°ÂûãÁöÑÁîüÊàêÊó∂Èó¥Ê≠•‰∏éMRIÁâ©ÁêÜÁ∫¶ÊùüÂØπÈΩêÔºåÂ∞ÜÂä†ÈÄüMRIÈáçÂª∫‰ªéÈùôÊÄÅÈÄÜÈóÆÈ¢òËΩ¨Âèò‰∏∫Âä®ÊÄÅËΩ®ËøπÂêåÊ≠•‰ªªÂä°„ÄÇ\",\n    \"ÈÄöËøáÂ∞Ü‰º™ÈÄÜÁõ¥Êé•ÈõÜÊàêÂà∞ÊåáÊï∞ÁßØÂàÜÂô®‰∏≠ÔºåÂ∞ÜÁ∫¶ÊùüÊª°Ë∂≥‰ªéÂ§ñÈÉ®ÂºïÂØºËøáÁ®ãÈáçÊûÑ‰∏∫ÂÜÖÈÉ®ÁªìÊûÑÁªÑ‰ª∂Ôºå‰ªéËÄåÂÆûÁé∞ÊïàÁéáÂ§ßÂπÖÊèêÂçáÁöÑÈõ∂Ê†∑Êú¨ÂêéÈ™åÈááÊ†∑„ÄÇ\",\n    \"Â∞ÜÂåªÂ≠¶ÊàêÂÉèÁöÑËåÉÂºè‰ªéÁâπÂÆö‰ªªÂä°Ê®°ÂûãËÆ≠ÁªÉËΩ¨ÁßªÂà∞ÈÄöÁî®ËΩ®ËøπË∞ÉÊï¥ÔºåÈÄöËøáÁªßÊâøÈÄöÁî®ËßÜÈ¢ëÂÖàÈ™åÁöÑÊó∂Â∫èÊé®ÁêÜËÉΩÂäõÔºåÂÆûÁé∞È´ò‰øùÁúüÂä®ÊÄÅMRIÈáçÂª∫„ÄÇ\"\n  ],\n  \"experiments_plan\": \"Êàë‰ª¨Âú®ÂåÖÊã¨ÂøÉËÑèÂíåËÖπÈÉ®MRIÂú®ÂÜÖÁöÑÂ§öÊ†∑Âåñ‰∏¥Â∫äÊï∞ÊçÆÈõÜ‰∏äËøõË°åÂÖ®Èù¢ËØÑ‰º∞ÔºåÂ∞ÜAID‰∏éÊúÄÂÖàËøõÁöÑÊâ©Êï£Ê®°ÂûãÔºàDDIM„ÄÅÊ†áÂáÜDEISÔºâÂíå‰∏ìÁî®MRIÈáçÂª∫ÁΩëÁªúËøõË°åÊØîËæÉ„ÄÇÊàë‰ª¨ËøõË°åËØ¶ÁªÜÁöÑÊ∂àËûçÁ†îÁ©∂‰ª•È™åËØÅÁâ©ÁêÜÊÑüÁü•ÊåáÊï∞ÁßØÂàÜÂô®ÔºåÂ∞ÜÂÖ∂Êî∂ÊïõÁâπÊÄß‰∏éÂÖ∂‰ªñÊåáÊï∞ÁßØÂàÜÂô®ÊñπÊ≥ïËøõË°åÊØîËæÉÔºå‰ª•ËØÅÊòéÁ¶ªÊï£ÂåñËØØÂ∑ÆÁöÑÂáèÂ∞ë„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥ÁêÜËÆ∫‰∏äÁöÑÊãÖÂøßÔºåÊàë‰ª¨Êèê‰æõ‰∫ÜÂêåÊ≠•ODEËΩ®ËøπÁöÑÊî∂ÊïõÁéáÂíåÁ®≥ÂÆöÊÄßÂàÜÊûê„ÄÇÊúÄÂêéÔºåÊàë‰ª¨ÈÄöËøáÂú®‰∏çÈáçÊñ∞ËÆ≠ÁªÉÁöÑÊÉÖÂÜµ‰∏ãÊµãËØïÊ®°ÂûãÂú®‰∏çÂêåÂä†ÈÄüÂõ†Â≠êÂíåËß£ÂâñÂå∫ÂüüÁöÑÈõ∂Ê†∑Êú¨ËÉΩÂäõÊù•ËØÑ‰º∞Ê≥õÂåñÊÄß„ÄÇ\"\n}\n```", "latency_ms": 50492, "text_truncated": false, "text_len": 1760}}}
{"ts": "2026-01-29T11:10:47.076332+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.5, "max_tokens": 1000, "timeout": 120, "prompt": "\n‰Ω†ÊòØ‰∏Ä‰ΩçËµÑÊ∑±ÁöÑÁ†îÁ©∂ËÆ∫ÊñáÁºñËÄÖ„ÄÇÂàÜÊûê‰ª•‰∏ã‰ø°ÊÅØ‰∏≠Êóß Story„ÄÅÊñ∞ Pattern ÂíåËûçÂêà Idea Â¶Ç‰ΩïÁõ∏‰∫íÂÖ≥ËÅî„ÄÇ\n\n„ÄêÁî®Êà∑ÂéüÂßã Idea„Äë\nPropose the autoregressive image diffusion (AID) model for image sequence generation and apply it to sample the posterior for accelerated MRI reconstruction\n\n„ÄêÊóß Story ÁöÑÊ†∏ÂøÉ„Äë\nÊ†áÈ¢ò: Autoregressive Image Diffusion via Exponential Integrators for Efficient Posterior Sampling in Accelerated MRI Reconstruction\nÊëòË¶Å: Accelerated MRI reconstruction fundamentally requires generating high-fidelity image sequences from undersampled k-space data, a task that demands both precise posterior sampling and computational efficiency. We propose Autoregressive Image Diffusion (AID), a novel generative framework that models t...\nÈóÆÈ¢òÊ°ÜÊû∂: We reframe accelerated MRI reconstruction from a simple static inverse problem to a complex task of dynamic temporal sequence generation requiring precise posterior sampling. Traditional methods often...\nÂàõÊñ∞‰∏ªÂº†: [\"Transform accelerated MRI reconstruction from static optimization to dynamic Autoregressive Image Diffusion, enabling the generation of temporally coherent image sequences that accurately sample the complex posterior distribution.\", \"Reframe the computationally prohibitive sampling process by inte...\n\n„ÄêÊñ∞ Pattern ‰ø°ÊÅØ„Äë\nÂêçÁß∞: Reframing Diffusion Sampling Efficiency\nÊèèËø∞: ...\nÂÖ≥ÈîÆÊñπÊ≥ï: []...\n\n„ÄêËûçÂêàÂêéÁöÑÂàõÊñ∞ Idea„Äë\n{\"fused_idea_title\": \"Zero-Shot Physics-Trajectory Synchronized Video Diffusion\", \"fused_idea_description\": \"This approach reframes accelerated MRI reconstruction as synchronizing the generative trajectory of a pre-trained video diffusion model with MRI physical constraints. Instead of training or simple guidance, it utilizes a Pseudo-Inverse Exponential Integrator to dynamically align the video prior's temporal dynamics with k-space measurements in real-time, achieving high-fidelity, zero-shot dynamic reconstruction.\", \"problem_framing\": \"We shift the problem from 'restoring static images' to 'aligning temporal trajectories.' The core challenge is bridging the gap between the generic generative temporal dynamics of pre-trained video models and the specific acquisition dynamics of MRI. This requires a mechanism that harmonizes these two distinct time-scales and manifolds without retraining, effectively transforming a universal video generator into a task-specific MRI emulator through trajectory control.\", \"core_assumption\": \"We assume that the temporal consistency learned by generic video diffusion models is sufficiently universal to approximate physiological dynamics, and that MRI physics constraints can be satisfied not by retraining the network, but by analytically correcting the probability flow ODE's trajectory using the pseudo-inverse in real-time.\", \"novelty_claim\": \"Unlike simply applying guidance to a generic model (Pattern), we integrate the pseudo-inverse directly into the sampler's structure (User) to create a 'Physics-Aware Exponential Integrator.' This transforms the pseudo-inverse from a mere gradient term into a structural component of the ODE solver, allowing the model to 'warp' its generative path to satisfy physics on the fly without extra neural function evaluations.\", \"key_innovation_points\": [\"Trajectory Synchronization: Unifies video generation time-steps and MRI acquisition dynamics via ODE path correction.\", \"Physics-Embedded Integrator: Modifies the DEIS kernel (from User) to analytically include pseudo-inverse guidance (from Pattern), reducing reconstruction to a deterministic trajectory solving problem.\", \"Zero-Shot Temporal Inheritance: Leverages pre-trained video priors for temporal coherence without task-specific training, inheriting dynamic reasoning rather than just pixel textures.\"], \"why_not_straightforward_combination\": \"This is not A+B because it doesn't just 'use' a pre-trained model with AID's sampler. Instead, it fundamentally alters the sampling mechanics by absorbing the Pattern's pseudo-inverse logic into the User's exponential integrator structure, thereby co-evolving the sampling efficiency and the physics constraint satisfaction into a single unified trajectory control mechanism.\"}\n\nËØ∑ÊâßË°å‰ª•‰∏ãÂàÜÊûêÔºåÂπ∂ËøîÂõû JSON Ê†ºÂºèÁöÑÁªìÊûúÔºà‰∏çË¶ÅËøîÂõûÂÖ∂‰ªñÊñáÊú¨ÔºâÔºö\n\n{\n  \"old_core_concepts\": [\"Ê¶ÇÂøµ1\", \"Ê¶ÇÂøµ2\", \"...\"],  // ‰ªéÊóß Story ‰∏≠ÊèêÂèñ 2-3 ‰∏™Ê†∏ÂøÉÊ¶ÇÂøµ\n  \"pattern_core_concepts\": [\"Ê¶ÇÂøµ1\", \"Ê¶ÇÂøµ2\", \"...\"],  // ‰ªéÊñ∞ Pattern ‰∏≠ÊèêÂèñ 2-3 ‰∏™Ê†∏ÂøÉÊ¶ÇÂøµ\n  \"fusion_points\": [\n    {\n      \"old_concept\": \"Êóß Story ‰∏≠ÁöÑÊ¶ÇÂøµ\",\n      \"pattern_concept\": \"Pattern ‰∏≠ÁöÑÊ¶ÇÂøµ\",\n      \"fusion_opportunity\": \"Â¶Ç‰ΩïËûçÂêàÁöÑÊú∫‰ºöÁÇπ\",\n      \"implementation_path\": \"ÂÖ∑‰ΩìÂÆûÁé∞Ë∑ØÂæÑ\"\n    },\n    // ... Êõ¥Â§öËûçÂêàÁÇπ\n  ],\n  \"insights\": \"ÂØπËûçÂêàËøáÁ®ãÁöÑÊÄª‰ΩìÊ¥ûÂØüÔºà100-200Â≠óÔºâ\"\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 4513}, "response": {"ok": true, "text": "```json\n{\n  \"old_core_concepts\": [\n    \"Autoregressive Image Diffusion (AID)\",\n    \"Exponential Integrators (e.g., DEIS) for Sampling\",\n    \"Dynamic Temporal Sequence Generation\"\n  ],\n  \"pattern_core_concepts\": [\n    \"Pseudo-Inverse Trajectory Control\",\n    \"Zero-Shot Physics Alignment\",\n    \"ODE Path Correction\"\n  ],\n  \"fusion_points\": [\n    {\n      \"old_concept\": \"Exponential Integrators (e.g., DEIS)\",\n      \"pattern_concept\": \"Pseudo-Inverse Trajectory Control\",\n      \"fusion_opportunity\": \"Transform the sampling efficiency mechanism from a purely numerical accelerator to a physics-aware solver by embedding the pattern's constraint logic directly into the solver's structure.\",\n      \"implementation_path\": \"Modify the DEIS kernel to analytically include the pseudo-inverse guidance term, creating a 'Physics-Aware Exponential Integrator' that corrects the generative path to satisfy MRI physics on the fly without extra neural evaluations.\"\n    },\n    {\n      \"old_concept\": \"Dynamic Temporal Sequence Generation\",\n      \"pattern_concept\": \"Zero-Shot Physics Alignment\",\n      \"fusion_opportunity\": \"Replace the need for task-specific training on dynamic MRI sequences by leveraging the universal temporal consistency of pre-trained video models, controlled by the old story's sampling framework.\",\n      \"implementation_path\": \"Utilize a pre-trained video diffusion model as the generative prior and employ the AID framework to align its output dynamics with MRI acquisition dynamics, achieving 'Zero-Shot Temporal Inheritance' of physiological motion.\"\n    },\n    {\n      \"old_concept\": \"Posterior Sampling in MRI Reconstruction\",\n      \"pattern_concept\": \"ODE Path Correction\",\n      \"fusion_opportunity\": \"Reframe the reconstruction problem from restoring static pixels to synchronizing two distinct time-scales (video generation vs. MRI acquisition) via trajectory control.\",\n      \"implementation_path\": \"Formulate the reconstruction as solving a probability flow ODE where the trajectory is dynamically warped in real-time to match k-space measurements, effectively bridging the gap between generic video priors and specific MRI physics.\"\n    }\n  ],\n  \"insights\": \"The fusion represents a paradigm shift from 'training a model for a task' to 'controlling a pre-trained model for a task.' By deeply integrating the Pattern's pseudo-inverse logic into the Old Story's exponential integrator structure, the approach eliminates the computational overhead of traditional guidance methods. This creates a unified mechanism where sampling efficiency and physical fidelity are co-optimized, allowing generic video dynamics to be precisely warped into task-specific MRI reconstructions without retraining.\"\n}\n```", "latency_ms": 24716, "text_truncated": false, "text_len": 2722}}}
{"ts": "2026-01-29T11:11:16.325822+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.5, "max_tokens": 800, "timeout": 120, "prompt": "\nËØÑ‰º∞‰ª•‰∏ãËûçÂêàÁöÑÈÄªËæëËøûË¥ØÊÄß„ÄÇ‰∏Ä‰∏™ËâØÂ•ΩÁöÑËûçÂêàÂ∫îËØ•ËÉΩËá™ÁÑ∂Âú∞ËûçÂÖ•Áé∞ÊúâÊ°ÜÊû∂ÔºåËÄå‰∏çÊòØÁîüÁ°¨ÊãºÊé•„ÄÇ\n\n„ÄêÊóß Story ÁöÑÊñπÊ≥ï„Äë\nConstruct the Autoregressive Image Diffusion (AID) architecture by factorizing the joint distribution of image sequences into conditional diffusion steps; Formulate the accelerated MRI reconstruction task as a constrained posterior sampling problem within the AID framework; Implement the Diffusion Exponential Integrator Sampler (DEIS) to discretize the probability flow ODE, leveraging the semiline\n\n„ÄêËûçÂêàÁÇπ‰ø°ÊÅØ„Äë\n[\n  {\n    \"old_concept\": \"Exponential Integrators (e.g., DEIS)\",\n    \"pattern_concept\": \"Pseudo-Inverse Trajectory Control\",\n    \"fusion_opportunity\": \"Transform the sampling efficiency mechanism from a purely numerical accelerator to a physics-aware solver by embedding the pattern's constraint logic directly into the solver's structure.\",\n    \"implementation_path\": \"Modify the DEIS kernel to analytically include the pseudo-inverse guidance term, creating a 'Physics-Aware Exponential Integrator' that corrects the generative path to satisfy MRI physics on the fly without extra neural evaluations.\"\n  },\n  {\n    \"old_concept\": \"Dynamic Temporal Sequence Generation\",\n    \"pattern_concept\": \"Zero-Shot Physics Alignment\",\n    \"fusion_opportunity\": \"Replace the need for task-specific training on dynamic MRI sequences by leveraging the universal temporal consistency of pre-trained video models, controlled by the old story's sampling framework.\",\n    \"implementation_path\": \"Utilize a pre-trained video diffusion model as the generative prior and employ the AID framework to align its output dynamics with MRI acquisition dynamics, achieving 'Zero-Shot Temporal Inheritance' of physiological motion.\"\n  },\n  {\n    \"old_concept\": \"Posterior Sampling in MRI Reconstruction\",\n    \"pattern_concept\": \"ODE Path Correction\",\n    \"fusion_opportunity\": \"Reframe the reconstruction problem from restoring static pixels to synchronizing two distinct time-scales (video generation vs. MRI acquisition) via trajectory control.\",\n    \"implementation_path\": \"Formulate the reconstruction as solving a probability flow ODE where the trajectory is dynamically warped in real-time to match k-space measurements, effectively bridging the gap between generic video priors and specific MRI physics.\"\n  }\n]\n\n„ÄêÊñ∞ Pattern ÂêçÁß∞„Äë\nReframing Diffusion Sampling Efficiency\n\nËØ∑‰ªé‰ª•‰∏ãËßíÂ∫¶ÂàÜÊûêËøûË¥ØÊÄßÔºåËøîÂõû JSON Ê†ºÂºèÁöÑÁªìÊûúÔºà‰∏çË¶ÅËøîÂõûÂÖ∂‰ªñÊñáÊú¨ÔºâÔºö\n\n{\n  \"coherence_score\": 0.8,  // 0-1 ‰πãÈó¥ÁöÑËØÑÂàÜÔºåË°®Á§∫Êñ∞ÊäÄÊúØ‰∏éÁé∞ÊúâÊñπÊ≥ïÁöÑËûçÂêàÁ®ãÂ∫¶\n  \"potential_conflicts\": [\"ÂÜ≤Á™Å1\", \"ÂÜ≤Á™Å2\"],  // ÂèØËÉΩÁöÑÈÄªËæëÂÜ≤Á™ÅÊàñ‰∏çÂåπÈÖçÁÇπ\n  \"strengths\": [\"‰ºòÂäø1\", \"‰ºòÂäø2\"],  // ËûçÂêàÁöÑÂº∫Â§Ñ\n  \"analysis\": \"ËØ¶ÁªÜÂàÜÊûêÔºà200-300Â≠óÔºâÔºöËß£ÈáäËøô‰∏™ËûçÂêà‰∏∫‰ªÄ‰πàÂú®ÈÄªËæë‰∏äÊòØËøûË¥ØÁöÑÔºàÊàñÈúÄË¶ÅÊîπËøõÔºâ\"\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 2569}, "response": {"ok": true, "text": "```json\n{\n  \"coherence_score\": 0.85,\n  \"potential_conflicts\": [\n    \"AIDÁöÑËá™ÂõûÂΩíÂàÜËß£ÈÄªËæëÂèØËÉΩ‰∏éÈ¢ÑËÆ≠ÁªÉËßÜÈ¢ëÊ®°ÂûãÔºàÂ¶ÇÊ†áÂáÜDiTÔºâÁöÑÈùûËá™ÂõûÂΩíÊû∂ÊûÑÂ≠òÂú®ÁªìÊûÑÂÜ≤Á™ÅÔºåÂØºËá¥Èöæ‰ª•Áõ¥Êé•ÂµåÂÖ•„ÄÇ\",\n    \"Âú®DEISÂÜÖÊ†∏‰∏≠Âº∫Ë°åÊ∑ªÂä†‰º™ÈÄÜÈ°πÂèØËÉΩ‰ºöÁ†¥ÂùèÂéüÊúâÁöÑÊåáÊï∞ÁßØÂàÜÁ®≥ÂÆöÊÄßÔºåÂØºËá¥ODEËΩ®ËøπÂèëÊï£ÊàñÊî∂ÊïõÂà∞ÈîôËØØËß£„ÄÇ\"\n  ],\n  \"strengths\": [\n    \"Â∞ÜÁâ©ÁêÜÁ∫¶ÊùüÁõ¥Êé•ÂµåÂÖ•Ê±ÇËß£Âô®ÁªìÊûÑÔºåÂ∞ÜÈááÊ†∑ÊïàÁéá‰ªéÂçïÁ∫ØÁöÑÊï∞ÂÄºÂä†ÈÄüÊèêÂçá‰∏∫Áâ©ÁêÜ‰∏ÄËá¥ÊÄßÂä†ÈÄüÔºåÈÄªËæëÁ¥ßÂØÜ„ÄÇ\",\n    \"Âà©Áî®È¢ÑËÆ≠ÁªÉËßÜÈ¢ëÂÖàÈ™åÁªìÂêàAIDÊ°ÜÊû∂ÔºåËá™ÁÑ∂Âú∞Ëß£ÂÜ≥‰∫ÜÂä®ÊÄÅMRIÊï∞ÊçÆÁ®ÄÁº∫ÈóÆÈ¢òÔºåÂÆûÁé∞‰∫ÜÈõ∂Ê†∑Êú¨ËÉΩÂäõÁöÑËøÅÁßª„ÄÇ\",\n    \"Â∞ÜÈáçÂª∫ÈóÆÈ¢òÈáçÊûÑ‰∏∫Êó∂Èó¥Â∞∫Â∫¶ÂêåÊ≠•ÁöÑËΩ®ËøπÊéßÂà∂ÔºåÁªü‰∏Ä‰∫ÜËßÜÈ¢ëÁîüÊàê‰∏éMRIÈááÊ†∑ÁöÑÊï∞Â≠¶ÊèèËø∞ÔºåÁêÜËÆ∫Ê°ÜÊû∂Áªü‰∏Ä„ÄÇ\"\n  ],\n  \"analysis\": \"ËØ•ËûçÂêàÈÄªËæëÈ´òÂ∫¶ËøûË¥ØÔºåÊàêÂäüÂ∞ÜMRIÁâ©ÁêÜÁ∫¶Êùü‰∏éÊâ©Êï£ÈááÊ†∑Âô®ÁöÑÊï∞ÂÄºÁªìÊûÑÊ∑±Â∫¶ÁªìÂêà„ÄÇÈÄöËøá‰øÆÊîπDEISÂÜÖÊ†∏ÂºïÂÖ•‰º™ÈÄÜÈ°πÔºåÂ∞Ü'ÊïàÁéá'ÈáçÊñ∞ÂÆö‰πâ‰∏∫Áâ©ÁêÜ‰∏ÄËá¥ÊÄßÁöÑÊª°Ë∂≥ÔºåËÄåÈùûÂçïÁ∫ØÁöÑÊ≠•Êï∞ÂáèÂ∞ëÔºåËøôÁ¨¶ÂêàÁâ©ÁêÜ‰ø°ÊÅØÊú∫Âô®Â≠¶‰π†ÁöÑË∂ãÂäø„ÄÇÂêåÊó∂ÔºåÂà©Áî®AIDÊ°ÜÊû∂ÂØπÈΩêÈ¢ÑËÆ≠ÁªÉËßÜÈ¢ëÊ®°Âûã‰∏éMRIÂä®ÊÄÅÔºåÊó¢‰øùÁïô‰∫ÜÂéüÊñπÊ≥ïÁöÑÂ∫èÂàóÂ§ÑÁêÜËÉΩÂäõÔºåÂèàÂºïÂÖ•‰∫ÜÂº∫Â§ßÁöÑÈÄöÁî®ÂÖàÈ™åÔºåÂÆûÁé∞‰∫ÜÈÄªËæë‰∏äÁöÑËá™ÁÑ∂Âª∂‰º∏„ÄÇÂîØ‰∏ÄÁöÑÈ£éÈô©Âú®‰∫éÂ§ñÈÉ®ÂÖàÈ™å‰∏éÁâπÂÆöÊ±ÇËß£Âô®Êú∫Âà∂ÁöÑÂÖºÂÆπÊÄßÔºå‰ΩÜÊï¥‰ΩìÊû∂ÊûÑËÆæËÆ°ÂêàÁêÜ„ÄÇ\"\n}\n```", "latency_ms": 29248, "text_truncated": false, "text_len": 583}}}
{"ts": "2026-01-29T11:11:50.208011+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.7, "max_tokens": 1500, "timeout": 180, "prompt": "\nYou are a senior paper author at a top AI conference, skilled in deeply integrating new techniques into existing methods to form innovative technical combinations.\n\n\n„ÄêUser's Original Idea - THE PROTAGONIST„Äë\n\"Propose the autoregressive image diffusion (AID) model for image sequence generation and apply it to sample the posterior for accelerated MRI reconstruction\"\n\nCore Concepts to Preserve: [Identify 2-4 key concepts from the idea above]\n\n\n‚ö†Ô∏è „ÄêCRITICAL: User Idea Protection Rules During Refinement„Äë\nWhen refining, ALWAYS remember:\n1. The user's core idea is \"Propose the autoregressive image diffusion (AID) model for image sequence generation and apply it to sample the posterior for accelerated MRI reconstruction\" - this is the PROTAGONIST of your story\n2. Technical approaches (e.g., RL, neural networks) are IMPLEMENTATION MEANS, not the main characters\n3. Title and abstract MUST always highlight the User Idea's core concepts\n4. Even when injecting new techniques, describe them from the perspective of \"how these techniques implement the User Idea\"\n\n„ÄêCurrent Story Version„Äë\nTitle: Autoregressive Image Diffusion via Zero-Shot Physics-Trajectory Synchronization for Accelerated MRI Reconstruction\nAbstract: We propose Autoregressive Image Diffusion (AID), a novel framework for image sequence generation that achieves high-fidelity accelerated MRI reconstruction by sampling the posterior distribution through zero-shot physics-trajectory synchronization. Traditional approaches treat reconstruction as a static inverse problem or require task-specific training, failing to leverage the rich temporal dynamics of pre-trained video priors. We reframe the challenge as aligning the generative trajectory of a video diffusion model with the physical constraints of MRI acquisition in real-time. To achieve this, we introduce the Physics-Aware Exponential Integrator, a mechanism that integrates the MRI pseudo-inverse directly into the kernel of the Diffusion Exponential Integrator Sampler (DEIS). This structural integration transforms the sampling process from a stochastic walk guided by external gradients into a deterministic trajectory alignment, allowing the model to warp its generative path to satisfy k-space measurements without fine-tuning. AID not only preserves the temporal coherence inherent in the video prior but also drastically reduces neural function evaluations, bridging the gap between theoretical generative capabilities and the practical demands of clinical workflows.\nProblem Framing: We reframe accelerated MRI reconstruction from a static image restoration task to a dynamic problem of temporal trajectory synchronization. The core challenge lies in bridging the gap between the generic temporal dynamics of pre-trained video diffusion models and the specific acquisition physics of MRI. Unlike traditional methods that learn static mappings, we assume that the temporal consistency learned by universal video models is sufficient to approximate physiological dynamics, but requires precise alignment with MRI physics. This shifts the objective from generating pixel-perfect frames to warping the generative ODE trajectory so that it naturally converges to solutions consistent with undersampled k-space data, effectively treating the reconstruction as a trajectory control problem.\nGap Pattern: Current diffusion-based methods fail in clinical applications due to a fundamental disconnect between generative priors and physical constraints. Existing approaches either treat frames independently, ignoring temporal correlations, or rely on task-specific training that limits generalizability. Furthermore, standard conditional guidance techniques merely nudge the output, requiring hundreds of expensive function evaluations and failing to guarantee adherence to physics. We identify a critical gap where there is no mechanism to structurally unify the generative time-steps of video models with the physical constraints of MRI, leading to inefficient sampling and poor zero-shot generalization across diverse clinical scenarios.\nSolution: Our solution introduces Autoregressive Image Diffusion (AID) with a Physics-Aware Exponential Integrator, fundamentally transforming how posterior sampling is performed. Instead of relying on task-specific training, we leverage the autoregressive structure of pre-trained video models and synchronize their trajectory with MRI physics. By integrating the pseudo-inverse of the MRI forward model directly into the exponential integrator's structure, we transform the sampling process into a deterministic trajectory alignment problem. This allows the model to analytically correct its path to satisfy k-space constraints on the fly, eliminating the need for extra neural network evaluations. We effectively warp the universal video prior into a task-specific MRI emulator, achieving rapid, high-fidelity reconstruction that respects both temporal coherence and physical laws.\nMethod: Adopt a pre-trained video diffusion model to provide the autoregressive prior, factorizing the joint distribution of image sequences into conditional diffusion steps; Formulate the accelerated MRI reconstruction as a constrained posterior sampling problem where the probability flow ODE is modified to include the MRI physics gradient; Develop a Physics-Aware Exponential Integrator that analytically integrates the pseudo-inverse term into the exponential integration kernel, minimizing discretization error; Perform zero-shot reconstruction by solving the modified ODE, dynamically synchronizing the generative trajectory with k-space measurements without fine-tuning the network weights.\nClaims: [\"Transform accelerated MRI reconstruction from a static inverse problem to a dynamic trajectory synchronization task by aligning the generative time-steps of pre-trained video models with MRI physical constraints.\", \"Reframe constraint satisfaction from an external guidance process to an internal structural component by integrating the pseudo-inverse directly into the exponential integrator, enabling zero-shot posterior sampling with drastic efficiency gains.\", \"Shift the paradigm of medical imaging from task-specific model training to general-purpose trajectory warping, achieving high-fidelity dynamic MRI reconstruction by inheriting temporal reasoning from universal video priors.\"]\n\n„ÄêReview Feedback„Äë(Read carefully, preserve well-received parts, deeply revise criticized parts)\n- Reviewer A (Methodology): 6.639999999999902ÂàÜ. ÂèçÈ¶à: Main gaps: Limited theoretical analysis of convergence properties, Unclear generalizability beyond MRI reconstruction, Missing detailed ablation studies for method components. Anchored against 9 papers....\n- Reviewer B (Novelty): 6.459999999999906ÂàÜ. ÂèçÈ¶à: Main gaps: Limited theoretical analysis, Narrow application focus, Potential lack of comprehensive evaluation. Anchored against 9 papers....\n- Reviewer C (Storyteller): 6.469999999999906ÂàÜ. ÂèçÈ¶à: Main gaps: Limited theoretical analysis of convergence properties, Lack of comparison with other exponential integrator methods, Missing evaluation on diverse clinical scenarios. Anchored against 9 papers....\n\n\n\n„Äêüí° CRITICAL: Conceptual Innovation from Idea Fusion„Äë\nTitle: Zero-Shot Physics-Trajectory Synchronized Video Diffusion\nDescription: This approach reframes accelerated MRI reconstruction as synchronizing the generative trajectory of a pre-trained video diffusion model with MRI physical constraints. Instead of training or simple guidance, it utilizes a Pseudo-Inverse Exponential Integrator to dynamically align the video prior's temporal dynamics with k-space measurements in real-time, achieving high-fidelity, zero-shot dynamic reconstruction.\n\nNew Problem Framing: We shift the problem from 'restoring static images' to 'aligning temporal trajectories.' The core challenge is bridging the gap between the generic generative temporal dynamics of pre-trained video models and the specific acquisition dynamics of MRI. This requires a mechanism that harmonizes these two distinct time-scales and manifolds without retraining, effectively transforming a universal video generator into a task-specific MRI emulator through trajectory control.\n\nNew Assumption: We assume that the temporal consistency learned by generic video diffusion models is sufficiently universal to approximate physiological dynamics, and that MRI physics constraints can be satisfied not by retraining the network, but by analytically correcting the probability flow ODE's trajectory using the pseudo-inverse in real-time.\n\nNew Novelty Claim: Unlike simply applying guidance to a generic model (Pattern), we integrate the pseudo-inverse directly into the sampler's structure (User) to create a 'Physics-Aware Exponential Integrator.' This transforms the pseudo-inverse from a mere gradient term into a structural component of the ODE solver, allowing the model to 'warp' its generative path to satisfy physics on the fly without extra neural function evaluations.\n\nWhy This is NOT Simple Combination:\nThis is not A+B because it doesn't just 'use' a pre-trained model with AID's sampler. Instead, it fundamentally alters the sampling mechanics by absorbing the Pattern's pseudo-inverse logic into the User's exponential integrator structure, thereby co-evolving the sampling efficiency and the physics constraint satisfaction into a single unified trajectory control mechanism.\n\nKey Innovation Points:\n  1. Trajectory Synchronization: Unifies video generation time-steps and MRI acquisition dynamics via ODE path correction.\n  2. Physics-Embedded Integrator: Modifies the DEIS kernel (from User) to analytically include pseudo-inverse guidance (from Pattern), reducing reconstruction to a deterministic trajectory solving problem.\n  3. Zero-Shot Temporal Inheritance: Leverages pre-trained video priors for temporal coherence without task-specific training, inheriting dynamic reasoning rather than just pixel textures.\n\n‚ö†Ô∏è CRITICAL: This fused idea represents a conceptual-level innovation, not just a technical combination.\nYour story refinement should reflect THIS NEW CONCEPTUAL INNOVATION in problem_framing, gap_pattern, and innovation_claims.\nThis is the KEY to achieving higher novelty scores - moving from \"combination of techniques\" to \"new perspective on the problem\".\n\n\n\n\n\n\n„ÄêÈíàÂØπÂàõÊñ∞ÊÄßÈóÆÈ¢òÁöÑÁâπÂà´ÊåáÂØº„Äë\nÂΩìÂâçÊñπÊ≥ïË¢´ËØÑÂÆ°ËÆ§‰∏∫\"ÂàõÊñ∞ÊÄß‰∏çË∂≥\"Êàñ\"ÊäÄÊúØÁªÑÂêàÂ∏∏ËßÅ\"„ÄÇ‰Ω†ÈúÄË¶ÅÔºö\n1. Âú® method_skeleton ‰∏≠ÔºåÁ™ÅÂá∫Êñ∞Ê≥®ÂÖ•ÊäÄÊúØÁöÑ**Áã¨ÁâπÂ∫îÁî®ÊñπÂºè**ÔºåÂΩ¢Êàê‰∏é‰ºó‰∏çÂêåÁöÑÊäÄÊúØË∑ØÁ∫ø„ÄÇ\n2. Âú® innovation_claims ‰∏≠ÔºåÊòéÁ°ÆÊåáÂá∫‰Ω†ÁöÑÊäÄÊúØÁªÑÂêà‰∏éÁé∞ÊúâÂ∑•‰ΩúÁöÑ**Êú¨Ë¥®Âå∫Âà´**„ÄÇ\n3. ÈÅøÂÖç‰ΩøÁî®\"ÊèêÂçáÊÄßËÉΩ\"„ÄÅ\"Â¢ûÂº∫ÊïàÊûú\"Á≠âÊ≥õÊ≥õËÄåË∞àÁöÑÊèèËø∞ÔºåË¶ÅÂÖ∑‰ΩìËØ¥ÊòéÊäÄÊúØÂàõÊñ∞ÁÇπ„ÄÇ\n\n\n„ÄêPattern Reference„Äë(Use these to enhance technical depth and narrative)\n\nüí° Solution Approaches (add concrete technical steps if needed):\n  1. Develop the Diffusion Exponential Integrator Sampler (DEIS) using an exponential integrator for discretizing ODEs, leveraging the semilinear structure of diffusion processes to minimize discretization error and reduce the number of required steps.\n  2. Modify the score network parameterization in DDIM to extend its applicability to general diffusion models, enabling efficient deterministic sampling.\n  3. Develop quasi-Taylor samplers using numerical schemes based on Taylor expansion, employing an 'ideal derivative substitution' to simplify the computation of higher-order derivatives.\n\nüìñ Story Packaging Strategy (use 'Reframe/Transform' pattern for claims):\n  1. Transform the challenge of slow sampling in diffusion models by reframing it as an opportunity to innovate on numerical methods, introducing a scalable approach that enhances efficiency without sacrificing quality, thus pushing the boundaries of generative modeling capabilities.\n  2. Reframe diffusion model sampling from a stochastic process to a deterministic one by leveraging numerical insights, thus broadening the applicability and efficiency of diffusion models beyond isotropic cases.\n\nRemember: These are TOOLS to implement the User Idea, not the main focus.\n\n\n‚ö†Ô∏è „ÄêHOW TO USE Fused Idea Guidance„Äë\nIf you received „ÄêConceptual Innovation from Idea Fusion„Äë above, this is THE MOST IMPORTANT guidance:\n- **Title & Abstract**: Must reflect the fused conceptual innovation, not just list techniques\n- **Problem Framing**: Adopt the NEW problem perspective from the fused idea\n- **Gap Pattern**: Explain why existing methods lack this conceptual unity\n- **Innovation Claims**: Frame as \"transforming/reframing X fro", "simulated": false, "prompt_truncated": true, "prompt_len": 15701}, "response": {"ok": true, "text": "```json\n{\n  \"title\": \"Autoregressive Image Diffusion via Physics-Trajectory Synchronization for Zero-Shot MRI Reconstruction\",\n  \"abstract\": \"We propose Autoregressive Image Diffusion (AID), a novel framework for image sequence generation that achieves high-fidelity accelerated MRI reconstruction by sampling the posterior distribution through zero-shot physics-trajectory synchronization. Traditional approaches treat reconstruction as a static inverse problem or require task-specific training, failing to leverage the rich temporal dynamics of pre-trained video priors. We reframe the challenge as aligning the generative trajectory of a video diffusion model with the physical constraints of MRI acquisition in real-time. To achieve this, we introduce the Physics-Aware Exponential Integrator, a mechanism that integrates the MRI pseudo-inverse directly into the kernel of the Diffusion Exponential Integrator Sampler (DEIS). By leveraging the semilinear structure of the diffusion ODE, this structural integration transforms the sampling process from a stochastic walk guided by external gradients into a deterministic trajectory alignment. This allows the model to analytically correct its path to satisfy k-space measurements without fine-tuning, preserving temporal coherence while drastically reducing neural function evaluations.\",\n  \"problem_framing\": \"We reframe accelerated MRI reconstruction from a static image restoration task to a dynamic problem of temporal trajectory synchronization. The core challenge lies in bridging the gap between the generic temporal dynamics of pre-trained video diffusion models and the specific acquisition physics of MRI. Unlike traditional methods that learn static mappings, we assume that the temporal consistency learned by universal video models is sufficient to approximate physiological dynamics, but requires precise alignment with MRI physics. This shifts the objective from generating pixel-perfect frames to warping the generative ODE trajectory so that it naturally converges to solutions consistent with undersampled k-space data, effectively treating the reconstruction as a trajectory control problem.\",\n  \"gap_pattern\": \"Current diffusion-based methods fail in clinical applications due to a fundamental disconnect between generative priors and physical constraints. Existing approaches either treat frames independently, ignoring temporal correlations, or rely on task-specific training that limits generalizability. Furthermore, standard conditional guidance techniques merely nudge the output, requiring hundreds of expensive function evaluations and failing to guarantee adherence to physics. We identify a critical gap where there is no mechanism to structurally unify the generative time-steps of video models with the physical constraints of MRI, leading to inefficient sampling, poor convergence properties, and weak zero-shot generalization across diverse clinical scenarios.\",\n  \"solution\": \"Our solution introduces Autoregressive Image Diffusion (AID) with a Physics-Aware Exponential Integrator, fundamentally transforming how posterior sampling is performed. Instead of relying on task-specific training, we leverage the autoregressive structure of pre-trained video models and synchronize their trajectory with MRI physics. By integrating the pseudo-inverse of the MRI forward model directly into the exponential integrator's structure, we transform the sampling process into a deterministic trajectory alignment problem. This allows the model to analytically correct its path to satisfy k-space constraints on the fly, eliminating the need for extra neural network evaluations. We effectively warp the universal video prior into a task-specific MRI emulator, achieving rapid, high-fidelity reconstruction that respects both temporal coherence and physical laws.\",\n  \"method_skeleton\": \"Adopt a pre-trained video diffusion model to provide the autoregressive prior, factorizing the joint distribution of image sequences into conditional diffusion steps; Formulate the accelerated MRI reconstruction as a constrained posterior sampling problem where the probability flow ODE is modified to include the MRI physics gradient; Develop a Physics-Aware Exponential Integrator that leverages the semilinear structure of the diffusion process to analytically integrate the pseudo-inverse term into the exponential integration kernel, minimizing discretization error; Perform zero-shot reconstruction by solving the modified ODE using the deterministic sampler, dynamically synchronizing the generative trajectory with k-space measurements without fine-tuning the network weights.\",\n  \"innovation_claims\": [\n    \"Transform accelerated MRI reconstruction from a static inverse problem to a dynamic trajectory synchronization task by aligning the generative time-steps of pre-trained video models with MRI physical constraints.\",\n    \"Reframe constraint satisfaction from an external guidance process to an internal structural component by integrating the pseudo-inverse directly into the exponential integrator, enabling zero-shot posterior sampling with drastic efficiency gains and theoretical convergence guarantees.\",\n    \"Shift the paradigm of medical imaging from task-specific model training to general-purpose trajectory warping, achieving high-fidelity dynamic MRI reconstruction by inheriting temporal reasoning from universal video priors.\"\n  ],\n  \"experiments_plan\": \"We conduct a comprehensive evaluation on diverse clinical MRI datasets (cardiac and brain) to validate zero-shot generalizability. We compare AID against state-of-the-art diffusion-based MRI reconstruction methods and standard video generation models, measuring PSNR, SSIM, and temporal metrics. Crucially, we include a theoretical analysis section proving the convergence properties of the Physics-Aware Exponential Integrator and provide ablation studies comparing our modified kernel against standard DEIS and other numerical samplers to demonstrate the reduction in function evaluations and improved trajectory stability.\"\n}\n```", "latency_ms": 33880, "text_truncated": false, "text_len": 6080}}}
{"ts": "2026-01-29T11:12:44.477733+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.3, "max_tokens": 1000, "timeout": 180, "prompt": "\nTranslate the following research paper story from English to Chinese. Keep the translation natural and accurate.\n\nTitle: Autoregressive Image Diffusion via Physics-Trajectory Synchronization for Zero-Shot MRI Reconstruction\nAbstract: We propose Autoregressive Image Diffusion (AID), a novel framework for image sequence generation that achieves high-fidelity accelerated MRI reconstruction by sampling the posterior distribution through zero-shot physics-trajectory synchronization. Traditional approaches treat reconstruction as a static inverse problem or require task-specific training, failing to leverage the rich temporal dynamics of pre-trained video priors. We reframe the challenge as aligning the generative trajectory of a video diffusion model with the physical constraints of MRI acquisition in real-time. To achieve this, we introduce the Physics-Aware Exponential Integrator, a mechanism that integrates the MRI pseudo-inverse directly into the kernel of the Diffusion Exponential Integrator Sampler (DEIS). By leveraging the semilinear structure of the diffusion ODE, this structural integration transforms the sampling process from a stochastic walk guided by external gradients into a deterministic trajectory alignment. This allows the model to analytically correct its path to satisfy k-space measurements without fine-tuning, preserving temporal coherence while drastically reducing neural function evaluations.\nProblem Framing: We reframe accelerated MRI reconstruction from a static image restoration task to a dynamic problem of temporal trajectory synchronization. The core challenge lies in bridging the gap between the generic temporal dynamics of pre-trained video diffusion models and the specific acquisition physics of MRI. Unlike traditional methods that learn static mappings, we assume that the temporal consistency learned by universal video models is sufficient to approximate physiological dynamics, but requires precise alignment with MRI physics. This shifts the objective from generating pixel-perfect frames to warping the generative ODE trajectory so that it naturally converges to solutions consistent with undersampled k-space data, effectively treating the reconstruction as a trajectory control problem.\nGap Pattern: Current diffusion-based methods fail in clinical applications due to a fundamental disconnect between generative priors and physical constraints. Existing approaches either treat frames independently, ignoring temporal correlations, or rely on task-specific training that limits generalizability. Furthermore, standard conditional guidance techniques merely nudge the output, requiring hundreds of expensive function evaluations and failing to guarantee adherence to physics. We identify a critical gap where there is no mechanism to structurally unify the generative time-steps of video models with the physical constraints of MRI, leading to inefficient sampling, poor convergence properties, and weak zero-shot generalization across diverse clinical scenarios.\nSolution: Our solution introduces Autoregressive Image Diffusion (AID) with a Physics-Aware Exponential Integrator, fundamentally transforming how posterior sampling is performed. Instead of relying on task-specific training, we leverage the autoregressive structure of pre-trained video models and synchronize their trajectory with MRI physics. By integrating the pseudo-inverse of the MRI forward model directly into the exponential integrator's structure, we transform the sampling process into a deterministic trajectory alignment problem. This allows the model to analytically correct its path to satisfy k-space constraints on the fly, eliminating the need for extra neural network evaluations. We effectively warp the universal video prior into a task-specific MRI emulator, achieving rapid, high-fidelity reconstruction that respects both temporal coherence and physical laws.\nMethod Skeleton: Adopt a pre-trained video diffusion model to provide the autoregressive prior, factorizing the joint distribution of image sequences into conditional diffusion steps; Formulate the accelerated MRI reconstruction as a constrained posterior sampling problem where the probability flow ODE is modified to include the MRI physics gradient; Develop a Physics-Aware Exponential Integrator that leverages the semilinear structure of the diffusion process to analytically integrate the pseudo-inverse term into the exponential integration kernel, minimizing discretization error; Perform zero-shot reconstruction by solving the modified ODE using the deterministic sampler, dynamically synchronizing the generative trajectory with k-space measurements without fine-tuning the network weights.\nInnovation Claims:\n- Transform accelerated MRI reconstruction from a static inverse problem to a dynamic trajectory synchronization task by aligning the generative time-steps of pre-trained video models with MRI physical constraints.\n- Reframe constraint satisfaction from an external guidance process to an internal structural component by integrating the pseudo-inverse directly into the exponential integrator, enabling zero-shot posterior sampling with drastic efficiency gains and theoretical convergence guarantees.\n- Shift the paradigm of medical imaging from task-specific model training to general-purpose trajectory warping, achieving high-fidelity dynamic MRI reconstruction by inheriting temporal reasoning from universal video priors.\nExperiments Plan: We conduct a comprehensive evaluation on diverse clinical MRI datasets (cardiac and brain) to validate zero-shot generalizability. We compare AID against state-of-the-art diffusion-based MRI reconstruction methods and standard video generation models, measuring PSNR, SSIM, and temporal metrics. Crucially, we include a theoretical analysis section proving the convergence properties of the Physics-Aware Exponential Integrator and provide ablation studies comparing our modified kernel against standard DEIS and other numerical samplers to demonstrate the reduction in function evaluations and improved trajectory stability.\n\nOutput ONLY a JSON format (no other text):\n{\n  \"title\": \"...\",\n  \"abstract\": \"...\",\n  \"problem_framing\": \"...\",\n  \"gap_pattern\": \"...\",\n  \"solution\": \"...\",\n  \"method_skeleton\": \"...\",\n  \"innovation_claims\": [\"...\", \"...\", \"...\"],\n  \"experiments_plan\": \"...\"\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 6369}, "response": {"ok": true, "text": "```json\n{\n  \"title\": \"Âü∫‰∫éÁâ©ÁêÜËΩ®ËøπÂêåÊ≠•ÁöÑËá™ÂõûÂΩíÂõæÂÉèÊâ©Êï£Èõ∂Ê†∑Êú¨MRIÈáçÂª∫\",\n  \"abstract\": \"Êàë‰ª¨ÊèêÂá∫‰∫ÜËá™ÂõûÂΩíÂõæÂÉèÊâ©Êï£ÔºàAIDÔºâÔºåËøôÊòØ‰∏Ä‰∏™Áî®‰∫éÂõæÂÉèÂ∫èÂàóÁîüÊàêÁöÑÊñ∞È¢ñÊ°ÜÊû∂ÔºåÂÆÉÈÄöËøáÈõ∂Ê†∑Êú¨Áâ©ÁêÜËΩ®ËøπÂêåÊ≠•ÈááÊ†∑ÂêéÈ™åÂàÜÂ∏ÉÔºåÂÆûÁé∞‰∫ÜÈ´ò‰øùÁúüÂä†ÈÄüMRIÈáçÂª∫„ÄÇ‰º†ÁªüÊñπÊ≥ïÂ∞ÜÈáçÂª∫ËßÜ‰∏∫ÈùôÊÄÅÈÄÜÈóÆÈ¢òÊàñÈúÄË¶ÅÁâπÂÆö‰ªªÂä°ËÆ≠ÁªÉÔºåÊú™ËÉΩÂà©Áî®È¢ÑËÆ≠ÁªÉËßÜÈ¢ëÂÖàÈ™å‰∏≠‰∏∞ÂØåÁöÑÊó∂Â∫èÂä®ÊÄÅ„ÄÇÊàë‰ª¨Â∞ÜËøô‰∏ÄÊåëÊàòÈáçÊñ∞ÊûÑÂª∫‰∏∫ÂÆûÊó∂Â∞ÜËßÜÈ¢ëÊâ©Êï£Ê®°ÂûãÁöÑÁîüÊàêËΩ®Ëøπ‰∏éMRIÈááÈõÜÁöÑÁâ©ÁêÜÁ∫¶ÊùüÁõ∏ÂØπÈΩê„ÄÇ‰∏∫ÂÆûÁé∞Ëøô‰∏ÄÁõÆÊ†áÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜÁâ©ÁêÜÊÑüÁü•ÊåáÊï∞ÁßØÂàÜÂô®ÔºåËøôÊòØ‰∏ÄÁßçÂ∞ÜMRI‰º™ÈÄÜÁõ¥Êé•ÈõÜÊàêÂà∞Êâ©Êï£ÊåáÊï∞ÁßØÂàÜÈááÊ†∑Âô®ÔºàDEISÔºâÂÜÖÊ†∏‰∏≠ÁöÑÊú∫Âà∂„ÄÇÈÄöËøáÂà©Áî®Êâ©Êï£Â∏∏ÂæÆÂàÜÊñπÁ®ãÔºàODEÔºâÁöÑÂçäÁ∫øÊÄßÁªìÊûÑÔºåËøôÁßçÁªìÊûÑÈõÜÊàêÂ∞ÜÈááÊ†∑ËøáÁ®ã‰ªéÁî±Â§ñÈÉ®Ê¢ØÂ∫¶ÂºïÂØºÁöÑÈöèÊú∫Ê∏∏Ëµ∞ËΩ¨Âèò‰∏∫Á°ÆÂÆöÊÄßËΩ®ËøπÂØπÈΩê„ÄÇËøô‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÂú®Êó†ÈúÄÂæÆË∞ÉÁöÑÊÉÖÂÜµ‰∏ãËß£ÊûêÂú∞Ê†°Ê≠£ÂÖ∂Ë∑ØÂæÑ‰ª•Êª°Ë∂≥kÁ©∫Èó¥ÊµãÈáèÔºåÂú®‰øùÊåÅÊó∂Â∫èËøûË¥ØÊÄßÁöÑÂêåÊó∂Â§ßÂπÖÂáèÂ∞ëÁ•ûÁªèÁΩëÁªúÂáΩÊï∞ËØÑ‰º∞„ÄÇ\",\n  \"problem_framing\": \"Êàë‰ª¨Â∞ÜÂä†ÈÄüMRIÈáçÂª∫‰ªéÈùôÊÄÅÂõæÂÉèÊÅ¢Â§ç‰ªªÂä°ÈáçÊñ∞ÊûÑÂª∫‰∏∫Êó∂Â∫èËΩ®ËøπÂêåÊ≠•ÁöÑÂä®ÊÄÅÈóÆÈ¢ò„ÄÇÊ†∏ÂøÉÊåëÊàòÂú®‰∫éÂº•ÂêàÈ¢ÑËÆ≠ÁªÉËßÜÈ¢ëÊâ©Êï£Ê®°ÂûãÁöÑÈÄöÁî®Êó∂Â∫èÂä®ÊÄÅ‰∏éMRIÁâπÂÆöÈááÈõÜÁâ©ÁêÜ‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇ‰∏éÂ≠¶‰π†ÈùôÊÄÅÊò†Â∞ÑÁöÑ‰º†ÁªüÊñπÊ≥ï‰∏çÂêåÔºåÊàë‰ª¨ÂÅáËÆæÈÄöÁî®ËßÜÈ¢ëÊ®°ÂûãÂ≠¶‰π†Âà∞ÁöÑÊó∂Â∫è‰∏ÄËá¥ÊÄßË∂≥‰ª•Ëøë‰ººÁîüÁêÜÂä®ÊÄÅÔºå‰ΩÜÈúÄË¶Å‰∏éMRIÁâ©ÁêÜËøõË°åÁ≤æÁ°ÆÂØπÈΩê„ÄÇËøôÂ∞ÜÁõÆÊ†á‰ªéÁîüÊàêÂÉèÁ¥†ÂÆåÁæéÁöÑÂ∏ßËΩ¨Âèò‰∏∫Êâ≠Êõ≤ÁîüÊàêODEËΩ®ËøπÔºå‰ΩøÂÖ∂Ëá™ÁÑ∂Êî∂ÊïõÂà∞‰∏éÊ¨†ÈááÊ†∑kÁ©∫Èó¥Êï∞ÊçÆ‰∏ÄËá¥ÁöÑËß£Ôºå‰ªéËÄåÊúâÊïàÂú∞Â∞ÜÈáçÂª∫ËßÜ‰∏∫ËΩ®ËøπÊéßÂà∂ÈóÆÈ¢ò„ÄÇ\",\n  \"gap_pattern\": \"ÂΩìÂâçÁöÑÂü∫‰∫éÊâ©Êï£ÁöÑÊñπÊ≥ïÂú®‰∏¥Â∫äÂ∫îÁî®‰∏≠Â§±Ë¥•ÔºåÂΩíÂõ†‰∫éÁîüÊàêÂÖàÈ™å‰∏éÁâ©ÁêÜÁ∫¶Êùü‰πãÈó¥Â≠òÂú®Ê†πÊú¨ÊÄßÁöÑËÑ±ËäÇ„ÄÇÁé∞ÊúâÊñπÊ≥ïË¶Å‰πàÁã¨Á´ãÂ§ÑÁêÜÂ∏ßÔºåÂøΩÁï•Êó∂Â∫èÁõ∏ÂÖ≥ÊÄßÔºåË¶Å‰πà‰æùËµñÈôêÂà∂Ê≥õÂåñËÉΩÂäõÁöÑÁâπÂÆö‰ªªÂä°ËÆ≠ÁªÉ„ÄÇÊ≠§Â§ñÔºåÊ†áÂáÜÁöÑÊù°‰ª∂ÂºïÂØºÊäÄÊúØ‰ªÖ‰ªÖÊòØÂæÆË∞ÉËæìÂá∫ÔºåÈúÄË¶ÅÊï∞ÁôæÊ¨°ÊòÇË¥µÁöÑÂáΩÊï∞ËØÑ‰º∞Ôºå‰∏îÊó†Ê≥ï‰øùËØÅÈÅµÂÆàÁâ©ÁêÜËßÑÂæã„ÄÇÊàë‰ª¨ÂèëÁé∞‰∫Ü‰∏Ä‰∏™ÂÖ≥ÈîÆÁ©∫ÁôΩÔºåÂç≥Áº∫‰πè‰∏ÄÁßçÊú∫Âà∂Êù•ÁªìÊûÑÊÄßÂú∞Áªü‰∏ÄËßÜÈ¢ëÊ®°ÂûãÁöÑÁîüÊàêÊó∂Èó¥Ê≠•‰∏éMRIÁöÑÁâ©ÁêÜÁ∫¶ÊùüÔºåËøôÂØºËá¥Âú®‰∏çÂêå‰∏¥Â∫äÂú∫ÊôØ‰∏≠ÈááÊ†∑ÊïàÁéá‰Ωé‰∏ã„ÄÅÊî∂ÊïõÊÄßÂ∑Æ‰ª•ÂèäÈõ∂Ê†∑Êú¨Ê≥õÂåñËÉΩÂäõÂº±„ÄÇ\",\n  \"solution\": \"Êàë‰ª¨ÁöÑËß£ÂÜ≥ÊñπÊ°àÂºïÂÖ•‰∫ÜÂ∏¶ÊúâÁâ©ÁêÜÊÑüÁü•ÊåáÊï∞ÁßØÂàÜÂô®ÁöÑËá™ÂõûÂΩíÂõæÂÉèÊâ©Êï£ÔºàAIDÔºâÔºå‰ªéÊ†πÊú¨‰∏äÊîπÂèò‰∫ÜÂêéÈ™åÈááÊ†∑ÁöÑÊâßË°åÊñπÂºè„ÄÇÊàë‰ª¨‰∏ç‰æùËµñÁâπÂÆö‰ªªÂä°ËÆ≠ÁªÉÔºåËÄåÊòØÂà©Áî®È¢ÑËÆ≠ÁªÉËßÜÈ¢ëÊ®°ÂûãÁöÑËá™ÂõûÂΩíÁªìÊûÑÔºåÂπ∂Â∞ÜÂÖ∂ËΩ®Ëøπ‰∏éMRIÁâ©ÁêÜÂêåÊ≠•„ÄÇÈÄöËøáÂ∞ÜMRIÂâçÂêëÊ®°ÂûãÁöÑ‰º™ÈÄÜÁõ¥Êé•ÈõÜÊàêÂà∞ÊåáÊï∞ÁßØÂàÜÂô®ÁöÑÁªìÊûÑ‰∏≠ÔºåÊàë‰ª¨Â∞ÜÈááÊ†∑ËøáÁ®ãËΩ¨Âåñ‰∏∫Á°ÆÂÆöÊÄßËΩ®ËøπÂØπÈΩêÈóÆÈ¢ò„ÄÇËøô‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÂç≥Êó∂Ëß£ÊûêÂú∞Ê†°Ê≠£ÂÖ∂Ë∑ØÂæÑ‰ª•Êª°Ë∂≥kÁ©∫Èó¥Á∫¶ÊùüÔºåÊ∂àÈô§‰∫ÜÂØπÈ¢ùÂ§ñÁ•ûÁªèÁΩëÁªúËØÑ‰º∞ÁöÑÈúÄÊ±Ç„ÄÇÊàë‰ª¨ÊúâÊïàÂú∞Â∞ÜÈÄöÁî®ËßÜÈ¢ëÂÖàÈ™åÊâ≠Êõ≤‰∏∫ÁâπÂÆö‰ªªÂä°ÁöÑMRIÊ®°ÊãüÂô®ÔºåÂÆûÁé∞‰∫ÜÊó¢Â∞äÈáçÊó∂Â∫èËøûË¥ØÊÄßÂèàÈÅµÂÆàÁâ©ÁêÜÂÆöÂæãÁöÑÂø´ÈÄü„ÄÅÈ´ò‰øùÁúüÈáçÂª∫„ÄÇ\",\n  \"method_skeleton\": \"ÈááÁî®È¢ÑËÆ≠ÁªÉÁöÑËßÜÈ¢ëÊâ©Êï£Ê®°ÂûãÊèê‰æõËá™ÂõûÂΩíÂÖàÈ™åÔºåÂ∞ÜÂõæÂÉèÂ∫èÂàóÁöÑËÅîÂêàÂàÜÂ∏ÉÂàÜËß£‰∏∫Êù°‰ª∂Êâ©Êï£Ê≠•È™§ÔºõÂ∞ÜÂä†ÈÄüMRIÈáçÂª∫Ë°®Ëø∞‰∏∫Á∫¶ÊùüÂêéÈ™åÈááÊ†∑ÈóÆÈ¢òÔºåÂÖ∂‰∏≠‰øÆÊîπÊ¶ÇÁéáÊµÅODE‰ª•ÂåÖÂê´MRIÁâ©ÁêÜÊ¢ØÂ∫¶ÔºõÂºÄÂèëÁâ©ÁêÜÊÑüÁü•ÊåáÊï∞ÁßØÂàÜÂô®ÔºåÂà©Áî®Êâ©Êï£ËøáÁ®ãÁöÑÂçäÁ∫øÊÄßÁªìÊûÑÂ∞Ü‰º™ÈÄÜÈ°πËß£ÊûêÂú∞ÈõÜÊàêÂà∞ÊåáÊï∞ÁßØÂàÜÂÜÖÊ†∏‰∏≠ÔºåÊúÄÂ∞èÂåñÁ¶ªÊï£ÂåñËØØÂ∑ÆÔºõ‰ΩøÁî®Á°ÆÂÆöÊÄßÈááÊ†∑Âô®Ê±ÇËß£‰øÆÊîπÂêéÁöÑODEÊâßË°åÈõ∂Ê†∑Êú¨ÈáçÂª∫ÔºåÂä®ÊÄÅÂú∞Â∞ÜÁîüÊàêËΩ®Ëøπ‰∏ékÁ©∫Èó¥ÊµãÈáèÂêåÊ≠•ÔºåËÄåÊó†ÈúÄÂæÆË∞ÉÁΩëÁªúÊùÉÈáç„ÄÇ\",\n  \"innovation_claims\": [\n    \"ÈÄöËøáÂ∞ÜÈ¢ÑËÆ≠ÁªÉËßÜÈ¢ëÊ®°ÂûãÁöÑÁîüÊàêÊó∂Èó¥Ê≠•‰∏éMRIÁâ©ÁêÜÁ∫¶ÊùüÂØπÈΩêÔºåÂ∞ÜÂä†ÈÄüMRIÈáçÂª∫‰ªéÈùôÊÄÅÈÄÜÈóÆÈ¢òËΩ¨Âèò‰∏∫Âä®ÊÄÅËΩ®ËøπÂêåÊ≠•‰ªªÂä°„ÄÇ\",\n    \"ÈÄöËøáÂ∞Ü‰º™ÈÄÜÁõ¥Êé•ÈõÜÊàêÂà∞ÊåáÊï∞ÁßØÂàÜÂô®‰∏≠ÔºåÂ∞ÜÁ∫¶ÊùüÊª°Ë∂≥‰ªéÂ§ñÈÉ®ÂºïÂØºËøáÁ®ãÈáçÊûÑ‰∏∫ÂÜÖÈÉ®ÁªìÊûÑÁªÑ‰ª∂Ôºå‰ªéËÄåÂÆûÁé∞ÂÖ∑ÊúâÊòæËëóÊïàÁéáÊèêÂçáÂíåÁêÜËÆ∫Êî∂Êïõ‰øùËØÅÁöÑÈõ∂Ê†∑Êú¨ÂêéÈ™åÈááÊ†∑„ÄÇ\",\n    \"Â∞ÜÂåªÂ≠¶ÊàêÂÉèÁöÑËåÉÂºè‰ªéÁâπÂÆö‰ªªÂä°Ê®°ÂûãËÆ≠ÁªÉËΩ¨ÁßªÂà∞ÈÄöÁî®ËΩ®ËøπÊâ≠Êõ≤ÔºåÈÄöËøáÁªßÊâøÈÄöÁî®ËßÜÈ¢ëÂÖàÈ™åÁöÑÊó∂Â∫èÊé®ÁêÜËÉΩÂäõÂÆûÁé∞È´ò‰øùÁúüÂä®ÊÄÅMRIÈáçÂª∫„ÄÇ\"\n  ],\n  \"experiments_plan\": \"Êàë‰ª¨Âú®Â§öÊ†∑ÂåñÁöÑ‰∏¥Â∫äMRIÊï∞ÊçÆÈõÜÔºàÂøÉËÑèÂíåÂ§ßËÑëÔºâ‰∏äËøõË°åÁªºÂêàËØÑ‰º∞Ôºå‰ª•È™åËØÅÈõ∂Ê†∑Êú¨Ê≥õÂåñËÉΩÂäõ„ÄÇÊàë‰ª¨Â∞ÜAID‰∏éÊúÄÂÖàËøõÁöÑÂü∫‰∫éÊâ©Êï£ÁöÑMRIÈáçÂª∫ÊñπÊ≥ïÂíåÊ†áÂáÜËßÜÈ¢ëÁîüÊàêÊ®°ÂûãËøõË°åÊØîËæÉÔºåÊµãÈáèPSNR„ÄÅSSIMÂíåÊó∂Â∫èÊåáÊ†á„ÄÇÂÖ≥ÈîÆÁöÑÊòØÔºåÊàë‰ª¨ÂåÖÂê´‰∫Ü‰∏Ä‰∏™ÁêÜËÆ∫ÂàÜÊûêÈÉ®ÂàÜÔºåËØÅÊòéÁâ©ÁêÜÊÑüÁü•ÊåáÊï∞ÁßØÂàÜÂô®ÁöÑÊî∂ÊïõÊÄßË¥®ÔºåÂπ∂Êèê‰æõÊ∂àËûçÁ†îÁ©∂ÔºåÂ∞ÜÊàë‰ª¨‰øÆÊîπÂêéÁöÑÂÜÖÊ†∏‰∏éÊ†áÂáÜDEISÂíåÂÖ∂‰ªñÊï∞ÂÄºÈááÊ†∑Âô®ËøõË°åÊØîËæÉÔºå‰ª•Â±ïÁ§∫ÂáΩÊï∞ËØÑ‰º∞ÁöÑÂáèÂ∞ëÂíåËΩ®ËøπÁ®≥ÂÆöÊÄßÁöÑÊèêÈ´ò„ÄÇ\"\n}\n```", "latency_ms": 54267, "text_truncated": false, "text_len": 1761}}}
{"ts": "2026-01-29T11:13:03.508112+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.0, "max_tokens": 800, "timeout": 180, "prompt": "\nYou are a strict reviewer (Methodology) for top-tier ML/NLP conferences.\nYou must NOT output a direct score. Only compare the Story against anchor papers with real review scores.\n\nAnchors (score10 comes from real review statistics):\n- paper_id: 66arKkGiFy | title: Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models | score10: 5.9\n- paper_id: d7pr2doXn3 | title: Hybrid Regularization Improves Diffusion-based Inverse Problem Solving | score10: 6.0\n- paper_id: t9l63huPRt | title: Lightning-Fast Image Inversion and Editing for Text-to-Image Diffusion Models | score10: 6.3\n- paper_id: TtUh0TOlGX | title: Regularization by Texts for Latent Diffusion Inverse Solvers | score10: 6.5\n- paper_id: 9_gsMA8MRKQ | title: Pseudoinverse-Guided Diffusion Models for Inverse Problems | score10: 6.7\n- paper_id: 1YO4EE3SPB | title: A Variational Perspective on Solving Inverse Problems with Diffusion Models | score10: 5.9\n- paper_id: OnD9zGAGT0k | title: Diffusion Posterior Sampling for General Noisy Inverse Problems | score10: 7.2\n\nStory:\nTitle: Autoregressive Image Diffusion via Physics-Trajectory Synchronization for Zero-Shot MRI Reconstruction\nAbstract: We propose Autoregressive Image Diffusion (AID), a novel framework for image sequence generation that achieves high-fidelity accelerated MRI reconstruction by sampling the posterior distribution through zero-shot physics-trajectory synchronization. Traditional approaches treat reconstruction as a static inverse problem or require task-specific training, failing to leverage the rich temporal dynamics of pre-trained video priors. We reframe the challenge as aligning the generative trajectory of a video diffusion model with the physical constraints of MRI acquisition in real-time. To achieve this, we introduce the Physics-Aware Exponential Integrator, a mechanism that integrates the MRI pseudo-inverse directly into the kernel of the Diffusion Exponential Integrator Sampler (DEIS). By leveraging the semilinear structure of the diffusion ODE, this structural integration transforms the sampling process from a stochastic walk guided by external gradients into a deterministic trajectory alignment. This allows the model to analytically correct its path to satisfy k-space measurements without fine-tuning, preserving temporal coherence while drastically reducing neural function evaluations.\nProblem: We reframe accelerated MRI reconstruction from a static image restoration task to a dynamic problem of temporal trajectory synchronization. The core challenge lies in bridging the gap between the generic temporal dynamics of pre-trained video diffusion models and the specific acquisition physics of MRI. Unlike traditional methods that learn static mappings, we assume that the temporal consistency learned by universal video models is sufficient to approximate physiological dynamics, but requires precise alignment with MRI physics. This shifts the objective from generating pixel-perfect frames to warping the generative ODE trajectory so that it naturally converges to solutions consistent with undersampled k-space data, effectively treating the reconstruction as a trajectory control problem.\nMethod: Adopt a pre-trained video diffusion model to provide the autoregressive prior, factorizing the joint distribution of image sequences into conditional diffusion steps; Formulate the accelerated MRI reconstruction as a constrained posterior sampling problem where the probability flow ODE is modified to include the MRI physics gradient; Develop a Physics-Aware Exponential Integrator that leverages the semilinear structure of the diffusion process to analytically integrate the pseudo-inverse term into the exponential integration kernel, minimizing discretization error; Perform zero-shot reconstruction by solving the modified ODE using the deterministic sampler, dynamically synchronizing the generative trajectory with k-space measurements without fine-tuning the network weights.\nClaims: Transform accelerated MRI reconstruction from a static inverse problem to a dynamic trajectory synchronization task by aligning the generative time-steps of pre-trained video models with MRI physical constraints., Reframe constraint satisfaction from an external guidance process to an internal structural component by integrating the pseudo-inverse directly into the exponential integrator, enabling zero-shot posterior sampling with drastic efficiency gains and theoretical convergence guarantees., Shift the paradigm of medical imaging from task-specific model training to general-purpose trajectory warping, achieving high-fidelity dynamic MRI reconstruction by inheriting temporal reasoning from universal video priors.\nExperiments: We conduct a comprehensive evaluation on diverse clinical MRI datasets (cardiac and brain) to validate zero-shot generalizability. We compare AID against state-of-the-art diffusion-based MRI reconstruction methods and standard video generation models, measuring PSNR, SSIM, and temporal metrics. Crucially, we include a theoretical analysis section proving the convergence properties of the Physics-Aware Exponential Integrator and provide ablation studies comparing our modified kernel against standard DEIS and other numerical samplers to demonstrate the reduction in function evaluations and improved trajectory stability.\n\nTask:\nFor each anchor, decide whether the Story is better, tie, or worse on Methodology, and provide confidence (0-1).\nYou must mention the anchor's score10 in the rationale using the format \"score10: X.X\".\nComparisons must include every anchor exactly once.\nEach rationale must be ONE sentence (<=25 words).\n\nOutput JSON ONLY. No markdown, no extra text:\n{\n  \"comparisons\": [\n    {\"paper_id\":\"...\", \"judgement\":\"better|tie|worse\", \"confidence\":0.0-1.0, \"rationale\":\"...score10: X.X...\"}\n  ],\n  \"main_gaps\": [\"gap1\", \"gap2\", \"gap3\"]\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 5890}, "response": {"ok": true, "text": "```json\n{\n  \"comparisons\": [\n    {\"paper_id\":\"66arKkGiFy\",\"judgement\":\"better\",\"confidence\":0.8,\"rationale\":\"Physics-aware exponential integrator more innovative than plug-and-play posterior sampling. score10: 5.9\"},\n    {\"paper_id\":\"d7pr2doXn3\",\"judgement\":\"better\",\"confidence\":0.75,\"rationale\":\"Direct physics integration into exponential kernel more novel than hybrid regularization. score10: 6.0\"},\n    {\"paper_id\":\"t9l63huPRt\",\"judgement\":\"better\",\"confidence\":0.7,\"rationale\":\"Trajectory synchronization with physics constraints more methodologically rigorous than image inversion. score10: 6.3\"},\n    {\"paper_id\":\"TtUh0TOlGX\",\"judgement\":\"better\",\"confidence\":0.75,\"rationale\":\"Physics-aware exponential integrator more innovative than text-based regularization. score10: 6.5\"},\n    {\"paper_id\":\"9_gsMA8MRKQ\",\"judgement\":\"better\",\"confidence\":0.65,\"rationale\":\"Direct integration of pseudoinverse into exponential kernel more advanced than pseudoinverse guidance. score10: 6.7\"},\n    {\"paper_id\":\"1YO4EE3SPB\",\"judgement\":\"better\",\"confidence\":0.8,\"rationale\":\"Physics-aware exponential integrator more innovative than variational perspective. score10: 5.9\"},\n    {\"paper_id\":\"OnD9zGAGT0k\",\"judgement\":\"tie\",\"confidence\":0.6,\"rationale\":\"Both address posterior sampling but with different approaches; theoretical analysis comparable. score10: 7.2\"}\n  ],\n  \"main_gaps\": [\n    \"Limited evaluation on only cardiac and brain MRI datasets\",\n    \"Potential lack of comparison with non-diffusion-based state-of-the-art methods\",\n    \"Limited discussion of computational complexity of physics-aware exponential integrator\",\n    \"Potential lack of extensive ablation studies on different components of the method\",\n    \"Limited discussion of failure cases or limitations of the approach\"\n  ]\n}\n```", "latency_ms": 19028, "text_truncated": false, "text_len": 1795}}}
{"ts": "2026-01-29T11:16:41.627038+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.0, "max_tokens": 800, "timeout": 180, "prompt": "\nYou are a strict reviewer (Novelty) for top-tier ML/NLP conferences.\nYou must NOT output a direct score. Only compare the Story against anchor papers with real review scores.\n\nAnchors (score10 comes from real review statistics):\n- paper_id: 66arKkGiFy | title: Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models | score10: 5.9\n- paper_id: d7pr2doXn3 | title: Hybrid Regularization Improves Diffusion-based Inverse Problem Solving | score10: 6.0\n- paper_id: t9l63huPRt | title: Lightning-Fast Image Inversion and Editing for Text-to-Image Diffusion Models | score10: 6.3\n- paper_id: TtUh0TOlGX | title: Regularization by Texts for Latent Diffusion Inverse Solvers | score10: 6.5\n- paper_id: 9_gsMA8MRKQ | title: Pseudoinverse-Guided Diffusion Models for Inverse Problems | score10: 6.7\n- paper_id: 1YO4EE3SPB | title: A Variational Perspective on Solving Inverse Problems with Diffusion Models | score10: 5.9\n- paper_id: OnD9zGAGT0k | title: Diffusion Posterior Sampling for General Noisy Inverse Problems | score10: 7.2\n\nStory:\nTitle: Autoregressive Image Diffusion via Physics-Trajectory Synchronization for Zero-Shot MRI Reconstruction\nAbstract: We propose Autoregressive Image Diffusion (AID), a novel framework for image sequence generation that achieves high-fidelity accelerated MRI reconstruction by sampling the posterior distribution through zero-shot physics-trajectory synchronization. Traditional approaches treat reconstruction as a static inverse problem or require task-specific training, failing to leverage the rich temporal dynamics of pre-trained video priors. We reframe the challenge as aligning the generative trajectory of a video diffusion model with the physical constraints of MRI acquisition in real-time. To achieve this, we introduce the Physics-Aware Exponential Integrator, a mechanism that integrates the MRI pseudo-inverse directly into the kernel of the Diffusion Exponential Integrator Sampler (DEIS). By leveraging the semilinear structure of the diffusion ODE, this structural integration transforms the sampling process from a stochastic walk guided by external gradients into a deterministic trajectory alignment. This allows the model to analytically correct its path to satisfy k-space measurements without fine-tuning, preserving temporal coherence while drastically reducing neural function evaluations.\nProblem: We reframe accelerated MRI reconstruction from a static image restoration task to a dynamic problem of temporal trajectory synchronization. The core challenge lies in bridging the gap between the generic temporal dynamics of pre-trained video diffusion models and the specific acquisition physics of MRI. Unlike traditional methods that learn static mappings, we assume that the temporal consistency learned by universal video models is sufficient to approximate physiological dynamics, but requires precise alignment with MRI physics. This shifts the objective from generating pixel-perfect frames to warping the generative ODE trajectory so that it naturally converges to solutions consistent with undersampled k-space data, effectively treating the reconstruction as a trajectory control problem.\nMethod: Adopt a pre-trained video diffusion model to provide the autoregressive prior, factorizing the joint distribution of image sequences into conditional diffusion steps; Formulate the accelerated MRI reconstruction as a constrained posterior sampling problem where the probability flow ODE is modified to include the MRI physics gradient; Develop a Physics-Aware Exponential Integrator that leverages the semilinear structure of the diffusion process to analytically integrate the pseudo-inverse term into the exponential integration kernel, minimizing discretization error; Perform zero-shot reconstruction by solving the modified ODE using the deterministic sampler, dynamically synchronizing the generative trajectory with k-space measurements without fine-tuning the network weights.\nClaims: Transform accelerated MRI reconstruction from a static inverse problem to a dynamic trajectory synchronization task by aligning the generative time-steps of pre-trained video models with MRI physical constraints., Reframe constraint satisfaction from an external guidance process to an internal structural component by integrating the pseudo-inverse directly into the exponential integrator, enabling zero-shot posterior sampling with drastic efficiency gains and theoretical convergence guarantees., Shift the paradigm of medical imaging from task-specific model training to general-purpose trajectory warping, achieving high-fidelity dynamic MRI reconstruction by inheriting temporal reasoning from universal video priors.\nExperiments: We conduct a comprehensive evaluation on diverse clinical MRI datasets (cardiac and brain) to validate zero-shot generalizability. We compare AID against state-of-the-art diffusion-based MRI reconstruction methods and standard video generation models, measuring PSNR, SSIM, and temporal metrics. Crucially, we include a theoretical analysis section proving the convergence properties of the Physics-Aware Exponential Integrator and provide ablation studies comparing our modified kernel against standard DEIS and other numerical samplers to demonstrate the reduction in function evaluations and improved trajectory stability.\n\nTask:\nFor each anchor, decide whether the Story is better, tie, or worse on Novelty, and provide confidence (0-1).\nYou must mention the anchor's score10 in the rationale using the format \"score10: X.X\".\nComparisons must include every anchor exactly once.\nEach rationale must be ONE sentence (<=25 words).\n\nOutput JSON ONLY. No markdown, no extra text:\n{\n  \"comparisons\": [\n    {\"paper_id\":\"...\", \"judgement\":\"better|tie|worse\", \"confidence\":0.0-1.0, \"rationale\":\"...score10: X.X...\"}\n  ],\n  \"main_gaps\": [\"gap1\", \"gap2\", \"gap3\"]\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 5882}, "response": {"ok": true, "text": "```json\n{\n  \"comparisons\": [\n    {\"paper_id\":\"66arKkGiFy\",\"judgement\":\"better\",\"confidence\":0.7,\"rationale\":\"Story's physics-aware integration is more novel than handling mismatched models (score10: 5.9).\"},\n    {\"paper_id\":\"d7pr2doXn3\",\"judgement\":\"better\",\"confidence\":0.7,\"rationale\":\"Story's direct physics integration into exponential integrator is more novel than hybrid regularization (score10: 6.0).\"},\n    {\"paper_id\":\"t9l63huPRt\",\"judgement\":\"better\",\"confidence\":0.6,\"rationale\":\"Story's physics-aware trajectory synchronization for MRI is more novel than fast image inversion (score10: 6.3).\"},\n    {\"paper_id\":\"TtUh0TOlGX\",\"judgement\":\"better\",\"confidence\":0.6,\"rationale\":\"Story's physics integration into exponential integrator is more novel than text-based regularization (score10: 6.5).\"},\n    {\"paper_id\":\"9_gsMA8MRKQ\",\"judgement\":\"tie\",\"confidence\":0.5,\"rationale\":\"Both use pseudoinverse guidance, but Story's integration into exponential integrator offers similar novelty (score10: 6.7).\"},\n    {\"paper_id\":\"1YO4EE3SPB\",\"judgement\":\"better\",\"confidence\":0.7,\"rationale\":\"Story's trajectory synchronization for MRI is more novel than variational perspective (score10: 5.9).\"},\n    {\"paper_id\":\"OnD9zGAGT0k\",\"judgement\":\"worse\",\"confidence\":0.6,\"rationale\":\"Story's specific MRI application is less novel than general inverse problem framework (score10: 7.2).\"}\n  ],\n  \"main_gaps\": [\"Limited evaluation on only cardiac and brain MRI datasets, lacking broader validation\", \"Theoretical analysis of convergence properties needs more rigorous empirical validation\", \"Comparison with state-of-the-art methods might be insufficient to fully demonstrate advantages\"]\n}\n```", "latency_ms": 218116, "text_truncated": false, "text_len": 1685}}}
{"ts": "2026-01-29T11:18:56.560129+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.0, "max_tokens": 800, "timeout": 180, "prompt": "\nYou are a strict reviewer (Storyteller) for top-tier ML/NLP conferences.\nYou must NOT output a direct score. Only compare the Story against anchor papers with real review scores.\n\nAnchors (score10 comes from real review statistics):\n- paper_id: 66arKkGiFy | title: Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models | score10: 5.9\n- paper_id: d7pr2doXn3 | title: Hybrid Regularization Improves Diffusion-based Inverse Problem Solving | score10: 6.0\n- paper_id: t9l63huPRt | title: Lightning-Fast Image Inversion and Editing for Text-to-Image Diffusion Models | score10: 6.3\n- paper_id: TtUh0TOlGX | title: Regularization by Texts for Latent Diffusion Inverse Solvers | score10: 6.5\n- paper_id: 9_gsMA8MRKQ | title: Pseudoinverse-Guided Diffusion Models for Inverse Problems | score10: 6.7\n- paper_id: 1YO4EE3SPB | title: A Variational Perspective on Solving Inverse Problems with Diffusion Models | score10: 5.9\n- paper_id: OnD9zGAGT0k | title: Diffusion Posterior Sampling for General Noisy Inverse Problems | score10: 7.2\n\nStory:\nTitle: Autoregressive Image Diffusion via Physics-Trajectory Synchronization for Zero-Shot MRI Reconstruction\nAbstract: We propose Autoregressive Image Diffusion (AID), a novel framework for image sequence generation that achieves high-fidelity accelerated MRI reconstruction by sampling the posterior distribution through zero-shot physics-trajectory synchronization. Traditional approaches treat reconstruction as a static inverse problem or require task-specific training, failing to leverage the rich temporal dynamics of pre-trained video priors. We reframe the challenge as aligning the generative trajectory of a video diffusion model with the physical constraints of MRI acquisition in real-time. To achieve this, we introduce the Physics-Aware Exponential Integrator, a mechanism that integrates the MRI pseudo-inverse directly into the kernel of the Diffusion Exponential Integrator Sampler (DEIS). By leveraging the semilinear structure of the diffusion ODE, this structural integration transforms the sampling process from a stochastic walk guided by external gradients into a deterministic trajectory alignment. This allows the model to analytically correct its path to satisfy k-space measurements without fine-tuning, preserving temporal coherence while drastically reducing neural function evaluations.\nProblem: We reframe accelerated MRI reconstruction from a static image restoration task to a dynamic problem of temporal trajectory synchronization. The core challenge lies in bridging the gap between the generic temporal dynamics of pre-trained video diffusion models and the specific acquisition physics of MRI. Unlike traditional methods that learn static mappings, we assume that the temporal consistency learned by universal video models is sufficient to approximate physiological dynamics, but requires precise alignment with MRI physics. This shifts the objective from generating pixel-perfect frames to warping the generative ODE trajectory so that it naturally converges to solutions consistent with undersampled k-space data, effectively treating the reconstruction as a trajectory control problem.\nMethod: Adopt a pre-trained video diffusion model to provide the autoregressive prior, factorizing the joint distribution of image sequences into conditional diffusion steps; Formulate the accelerated MRI reconstruction as a constrained posterior sampling problem where the probability flow ODE is modified to include the MRI physics gradient; Develop a Physics-Aware Exponential Integrator that leverages the semilinear structure of the diffusion process to analytically integrate the pseudo-inverse term into the exponential integration kernel, minimizing discretization error; Perform zero-shot reconstruction by solving the modified ODE using the deterministic sampler, dynamically synchronizing the generative trajectory with k-space measurements without fine-tuning the network weights.\nClaims: Transform accelerated MRI reconstruction from a static inverse problem to a dynamic trajectory synchronization task by aligning the generative time-steps of pre-trained video models with MRI physical constraints., Reframe constraint satisfaction from an external guidance process to an internal structural component by integrating the pseudo-inverse directly into the exponential integrator, enabling zero-shot posterior sampling with drastic efficiency gains and theoretical convergence guarantees., Shift the paradigm of medical imaging from task-specific model training to general-purpose trajectory warping, achieving high-fidelity dynamic MRI reconstruction by inheriting temporal reasoning from universal video priors.\nExperiments: We conduct a comprehensive evaluation on diverse clinical MRI datasets (cardiac and brain) to validate zero-shot generalizability. We compare AID against state-of-the-art diffusion-based MRI reconstruction methods and standard video generation models, measuring PSNR, SSIM, and temporal metrics. Crucially, we include a theoretical analysis section proving the convergence properties of the Physics-Aware Exponential Integrator and provide ablation studies comparing our modified kernel against standard DEIS and other numerical samplers to demonstrate the reduction in function evaluations and improved trajectory stability.\n\nTask:\nFor each anchor, decide whether the Story is better, tie, or worse on Storyteller, and provide confidence (0-1).\nYou must mention the anchor's score10 in the rationale using the format \"score10: X.X\".\nComparisons must include every anchor exactly once.\nEach rationale must be ONE sentence (<=25 words).\n\nOutput JSON ONLY. No markdown, no extra text:\n{\n  \"comparisons\": [\n    {\"paper_id\":\"...\", \"judgement\":\"better|tie|worse\", \"confidence\":0.0-1.0, \"rationale\":\"...score10: X.X...\"}\n  ],\n  \"main_gaps\": [\"gap1\", \"gap2\", \"gap3\"]\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 5890}, "response": {"ok": true, "text": "```json\n{\n  \"comparisons\": [\n    {\"paper_id\":\"66arKkGiFy\", \"judgement\":\"better\", \"confidence\":0.8, \"rationale\":\"Story's physics-trajectory synchronization is more innovative than mismatched model handling, score10: 5.9\"},\n    {\"paper_id\":\"d7pr2doXn3\", \"judgement\":\"tie\", \"confidence\":0.6, \"rationale\":\"Story's physics integration is different but not necessarily superior to hybrid regularization, score10: 6.0\"},\n    {\"paper_id\":\"t9l63huPRt\", \"judgement\":\"tie\", \"confidence\":0.6, \"rationale\":\"Story's medical imaging application is different but not necessarily superior to image inversion/editing, score10: 6.3\"},\n    {\"paper_id\":\"TtUh0TOlGX\", \"judgement\":\"tie\", \"confidence\":0.6, \"rationale\":\"Story's physics-aware approach is different but not necessarily superior to text-based regularization, score10: 6.5\"},\n    {\"paper_id\":\"9_gsMA8MRKQ\", \"judgement\":\"tie\", \"confidence\":0.6, \"rationale\":\"Story's kernel integration complements rather than surpasses pseudoinverse guidance approach, score10: 6.7\"},\n    {\"paper_id\":\"1YO4EE3SPB\", \"judgement\":\"better\", \"confidence\":0.8, \"rationale\":\"Story's trajectory synchronization approach is more novel than variational perspective, score10: 5.9\"},\n    {\"paper_id\":\"OnD9zGAGT0k\", \"judgement\":\"worse\", \"confidence\":0.6, \"rationale\":\"Story's specialized MRI application is less general than general noisy inverse problem approach, score10: 7.2\"}\n  ],\n  \"main_gaps\": [\"Limited evaluation on only cardiac and brain MRI datasets\", \"Lack of comparison with non-diffusion reconstruction methods\", \"Unclear generalizability to other medical imaging modalities\"]\n}\n```", "latency_ms": 134931, "text_truncated": false, "text_len": 1603}}}
{"ts": "2026-01-29T11:19:14.832822+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.0, "max_tokens": 800, "timeout": 180, "prompt": "\nYou are a strict reviewer (Methodology) for top-tier ML/NLP conferences.\nYou must NOT output a direct score. Only compare the Story against anchor papers with real review scores.\n\nAnchors (score10 comes from real review statistics):\n- paper_id: 66arKkGiFy | title: Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models | score10: 5.9\n- paper_id: d7pr2doXn3 | title: Hybrid Regularization Improves Diffusion-based Inverse Problem Solving | score10: 6.0\n- paper_id: t9l63huPRt | title: Lightning-Fast Image Inversion and Editing for Text-to-Image Diffusion Models | score10: 6.3\n- paper_id: TtUh0TOlGX | title: Regularization by Texts for Latent Diffusion Inverse Solvers | score10: 6.5\n- paper_id: 9_gsMA8MRKQ | title: Pseudoinverse-Guided Diffusion Models for Inverse Problems | score10: 6.7\n- paper_id: 1YO4EE3SPB | title: A Variational Perspective on Solving Inverse Problems with Diffusion Models | score10: 5.9\n- paper_id: OnD9zGAGT0k | title: Diffusion Posterior Sampling for General Noisy Inverse Problems | score10: 7.2\n- paper_id: U3PBITXNG6 | title: InverseBench: Benchmarking Plug-and-Play Diffusion Priors for Inverse Problems in Physical Sciences | score10: 6.5\n- paper_id: 6EUtjXAvmj | title: Variational Diffusion Posterior Sampling with Midpoint Guidance | score10: 6.7\n\nStory:\nTitle: Autoregressive Image Diffusion via Physics-Trajectory Synchronization for Zero-Shot MRI Reconstruction\nAbstract: We propose Autoregressive Image Diffusion (AID), a novel framework for image sequence generation that achieves high-fidelity accelerated MRI reconstruction by sampling the posterior distribution through zero-shot physics-trajectory synchronization. Traditional approaches treat reconstruction as a static inverse problem or require task-specific training, failing to leverage the rich temporal dynamics of pre-trained video priors. We reframe the challenge as aligning the generative trajectory of a video diffusion model with the physical constraints of MRI acquisition in real-time. To achieve this, we introduce the Physics-Aware Exponential Integrator, a mechanism that integrates the MRI pseudo-inverse directly into the kernel of the Diffusion Exponential Integrator Sampler (DEIS). By leveraging the semilinear structure of the diffusion ODE, this structural integration transforms the sampling process from a stochastic walk guided by external gradients into a deterministic trajectory alignment. This allows the model to analytically correct its path to satisfy k-space measurements without fine-tuning, preserving temporal coherence while drastically reducing neural function evaluations.\nProblem: We reframe accelerated MRI reconstruction from a static image restoration task to a dynamic problem of temporal trajectory synchronization. The core challenge lies in bridging the gap between the generic temporal dynamics of pre-trained video diffusion models and the specific acquisition physics of MRI. Unlike traditional methods that learn static mappings, we assume that the temporal consistency learned by universal video models is sufficient to approximate physiological dynamics, but requires precise alignment with MRI physics. This shifts the objective from generating pixel-perfect frames to warping the generative ODE trajectory so that it naturally converges to solutions consistent with undersampled k-space data, effectively treating the reconstruction as a trajectory control problem.\nMethod: Adopt a pre-trained video diffusion model to provide the autoregressive prior, factorizing the joint distribution of image sequences into conditional diffusion steps; Formulate the accelerated MRI reconstruction as a constrained posterior sampling problem where the probability flow ODE is modified to include the MRI physics gradient; Develop a Physics-Aware Exponential Integrator that leverages the semilinear structure of the diffusion process to analytically integrate the pseudo-inverse term into the exponential integration kernel, minimizing discretization error; Perform zero-shot reconstruction by solving the modified ODE using the deterministic sampler, dynamically synchronizing the generative trajectory with k-space measurements without fine-tuning the network weights.\nClaims: Transform accelerated MRI reconstruction from a static inverse problem to a dynamic trajectory synchronization task by aligning the generative time-steps of pre-trained video models with MRI physical constraints., Reframe constraint satisfaction from an external guidance process to an internal structural component by integrating the pseudo-inverse directly into the exponential integrator, enabling zero-shot posterior sampling with drastic efficiency gains and theoretical convergence guarantees., Shift the paradigm of medical imaging from task-specific model training to general-purpose trajectory warping, achieving high-fidelity dynamic MRI reconstruction by inheriting temporal reasoning from universal video priors.\nExperiments: We conduct a comprehensive evaluation on diverse clinical MRI datasets (cardiac and brain) to validate zero-shot generalizability. We compare AID against state-of-the-art diffusion-based MRI reconstruction methods and standard video generation models, measuring PSNR, SSIM, and temporal metrics. Crucially, we include a theoretical analysis section proving the convergence properties of the Physics-Aware Exponential Integrator and provide ablation studies comparing our modified kernel against standard DEIS and other numerical samplers to demonstrate the reduction in function evaluations and improved trajectory stability.\n\nTask:\nFor each anchor, decide whether the Story is better, tie, or worse on Methodology, and provide confidence (0-1).\nYou must mention the anchor's score10 in the rationale using the format \"score10: X.X\".\nComparisons must include every anchor exactly once.\nEach rationale must be ONE sentence (<=25 words).\n\nOutput JSON ONLY. No markdown, no extra text:\n{\n  \"comparisons\": [\n    {\"paper_id\":\"...\", \"judgement\":\"better|tie|worse\", \"confidence\":0.0-1.0, \"rationale\":\"...score10: X.X...\"}\n  ],\n  \"main_gaps\": [\"gap1\", \"gap2\", \"gap3\"]\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 6148}, "response": {"ok": true, "text": "```json\n{\n  \"comparisons\": [\n    {\"paper_id\":\"66arKkGiFy\",\"judgement\":\"better\",\"confidence\":0.8,\"rationale\":\"Physics-aware exponential integrator more innovative than standard posterior sampling. score10: 5.9\"},\n    {\"paper_id\":\"d7pr2doXn3\",\"judgement\":\"better\",\"confidence\":0.75,\"rationale\":\"Trajectory synchronization approach more novel than hybrid regularization. score10: 6.0\"},\n    {\"paper_id\":\"t9l63huPRt\",\"judgement\":\"better\",\"confidence\":0.7,\"rationale\":\"Physics integration more methodologically sophisticated than image inversion. score10: 6.3\"},\n    {\"paper_id\":\"TtUh0TOlGX\",\"judgement\":\"better\",\"confidence\":0.75,\"rationale\":\"Structural integration more innovative than text-based regularization. score10: 6.5\"},\n    {\"paper_id\":\"9_gsMA8MRKQ\",\"judgement\":\"better\",\"confidence\":0.7,\"rationale\":\"Kernel integration more advanced than pseudoinverse guidance. score10: 6.7\"},\n    {\"paper_id\":\"1YO4EE3SPB\",\"judgement\":\"better\",\"confidence\":0.8,\"rationale\":\"Trajectory synchronization more novel than variational perspective. score10: 5.9\"},\n    {\"paper_id\":\"OnD9zGAGT0k\",\"judgement\":\"worse\",\"confidence\":0.6,\"rationale\":\"Less generalizable than posterior sampling for noisy inverse problems. score10: 7.2\"},\n    {\"paper_id\":\"U3PBITXNG6\",\"judgement\":\"better\",\"confidence\":0.7,\"rationale\":\"Physics-aware integration more innovative than benchmarking approach. score10: 6.5\"},\n    {\"paper_id\":\"6EUtjXAvmj\",\"judgement\":\"better\",\"confidence\":0.75,\"rationale\":\"Structural integration more novel than midpoint guidance approach. score10: 6.7\"}\n  ],\n  \"main_gaps\": [\n    \"Limited evaluation on only cardiac and brain MRI datasets\",\n    \"Potential computational complexity of physics-aware exponential integrator\",\n    \"Lack of analysis on handling highly undersampled k-space data\"\n  ]\n}\n```", "latency_ms": 18268, "text_truncated": false, "text_len": 1791}}}
{"ts": "2026-01-29T11:20:17.685843+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.0, "max_tokens": 800, "timeout": 180, "prompt": "\nYou are a strict reviewer (Novelty) for top-tier ML/NLP conferences.\nYou must NOT output a direct score. Only compare the Story against anchor papers with real review scores.\n\nAnchors (score10 comes from real review statistics):\n- paper_id: 66arKkGiFy | title: Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models | score10: 5.9\n- paper_id: d7pr2doXn3 | title: Hybrid Regularization Improves Diffusion-based Inverse Problem Solving | score10: 6.0\n- paper_id: t9l63huPRt | title: Lightning-Fast Image Inversion and Editing for Text-to-Image Diffusion Models | score10: 6.3\n- paper_id: TtUh0TOlGX | title: Regularization by Texts for Latent Diffusion Inverse Solvers | score10: 6.5\n- paper_id: 9_gsMA8MRKQ | title: Pseudoinverse-Guided Diffusion Models for Inverse Problems | score10: 6.7\n- paper_id: 1YO4EE3SPB | title: A Variational Perspective on Solving Inverse Problems with Diffusion Models | score10: 5.9\n- paper_id: OnD9zGAGT0k | title: Diffusion Posterior Sampling for General Noisy Inverse Problems | score10: 7.2\n- paper_id: U3PBITXNG6 | title: InverseBench: Benchmarking Plug-and-Play Diffusion Priors for Inverse Problems in Physical Sciences | score10: 6.5\n- paper_id: 6EUtjXAvmj | title: Variational Diffusion Posterior Sampling with Midpoint Guidance | score10: 6.7\n\nStory:\nTitle: Autoregressive Image Diffusion via Physics-Trajectory Synchronization for Zero-Shot MRI Reconstruction\nAbstract: We propose Autoregressive Image Diffusion (AID), a novel framework for image sequence generation that achieves high-fidelity accelerated MRI reconstruction by sampling the posterior distribution through zero-shot physics-trajectory synchronization. Traditional approaches treat reconstruction as a static inverse problem or require task-specific training, failing to leverage the rich temporal dynamics of pre-trained video priors. We reframe the challenge as aligning the generative trajectory of a video diffusion model with the physical constraints of MRI acquisition in real-time. To achieve this, we introduce the Physics-Aware Exponential Integrator, a mechanism that integrates the MRI pseudo-inverse directly into the kernel of the Diffusion Exponential Integrator Sampler (DEIS). By leveraging the semilinear structure of the diffusion ODE, this structural integration transforms the sampling process from a stochastic walk guided by external gradients into a deterministic trajectory alignment. This allows the model to analytically correct its path to satisfy k-space measurements without fine-tuning, preserving temporal coherence while drastically reducing neural function evaluations.\nProblem: We reframe accelerated MRI reconstruction from a static image restoration task to a dynamic problem of temporal trajectory synchronization. The core challenge lies in bridging the gap between the generic temporal dynamics of pre-trained video diffusion models and the specific acquisition physics of MRI. Unlike traditional methods that learn static mappings, we assume that the temporal consistency learned by universal video models is sufficient to approximate physiological dynamics, but requires precise alignment with MRI physics. This shifts the objective from generating pixel-perfect frames to warping the generative ODE trajectory so that it naturally converges to solutions consistent with undersampled k-space data, effectively treating the reconstruction as a trajectory control problem.\nMethod: Adopt a pre-trained video diffusion model to provide the autoregressive prior, factorizing the joint distribution of image sequences into conditional diffusion steps; Formulate the accelerated MRI reconstruction as a constrained posterior sampling problem where the probability flow ODE is modified to include the MRI physics gradient; Develop a Physics-Aware Exponential Integrator that leverages the semilinear structure of the diffusion process to analytically integrate the pseudo-inverse term into the exponential integration kernel, minimizing discretization error; Perform zero-shot reconstruction by solving the modified ODE using the deterministic sampler, dynamically synchronizing the generative trajectory with k-space measurements without fine-tuning the network weights.\nClaims: Transform accelerated MRI reconstruction from a static inverse problem to a dynamic trajectory synchronization task by aligning the generative time-steps of pre-trained video models with MRI physical constraints., Reframe constraint satisfaction from an external guidance process to an internal structural component by integrating the pseudo-inverse directly into the exponential integrator, enabling zero-shot posterior sampling with drastic efficiency gains and theoretical convergence guarantees., Shift the paradigm of medical imaging from task-specific model training to general-purpose trajectory warping, achieving high-fidelity dynamic MRI reconstruction by inheriting temporal reasoning from universal video priors.\nExperiments: We conduct a comprehensive evaluation on diverse clinical MRI datasets (cardiac and brain) to validate zero-shot generalizability. We compare AID against state-of-the-art diffusion-based MRI reconstruction methods and standard video generation models, measuring PSNR, SSIM, and temporal metrics. Crucially, we include a theoretical analysis section proving the convergence properties of the Physics-Aware Exponential Integrator and provide ablation studies comparing our modified kernel against standard DEIS and other numerical samplers to demonstrate the reduction in function evaluations and improved trajectory stability.\n\nTask:\nFor each anchor, decide whether the Story is better, tie, or worse on Novelty, and provide confidence (0-1).\nYou must mention the anchor's score10 in the rationale using the format \"score10: X.X\".\nComparisons must include every anchor exactly once.\nEach rationale must be ONE sentence (<=25 words).\n\nOutput JSON ONLY. No markdown, no extra text:\n{\n  \"comparisons\": [\n    {\"paper_id\":\"...\", \"judgement\":\"better|tie|worse\", \"confidence\":0.0-1.0, \"rationale\":\"...score10: X.X...\"}\n  ],\n  \"main_gaps\": [\"gap1\", \"gap2\", \"gap3\"]\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 6140}, "response": {"ok": true, "text": "```json\n{\n  \"comparisons\": [\n    {\"paper_id\":\"66arKkGiFy\",\"judgement\":\"better\",\"confidence\":0.8,\"rationale\":\"The Story's physics-aware exponential integration for MRI reconstruction is more novel than addressing mismatched models (score10: 5.9).\"},\n    {\"paper_id\":\"d7pr2doXn3\",\"judgement\":\"better\",\"confidence\":0.8,\"rationale\":\"The Story's trajectory synchronization approach for MRI reconstruction is more innovative than hybrid regularization (score10: 6.0).\"},\n    {\"paper_id\":\"t9l63huPRt\",\"judgement\":\"better\",\"confidence\":0.7,\"rationale\":\"The Story's physics-aware exponential integration for MRI reconstruction is more novel than fast image inversion (score10: 6.3).\"},\n    {\"paper_id\":\"TtUh0TOlGX\",\"judgement\":\"better\",\"confidence\":0.8,\"rationale\":\"The Story's video diffusion approach for MRI reconstruction is more innovative than text-based regularization (score10: 6.5).\"},\n    {\"paper_id\":\"9_gsMA8MRKQ\",\"judgement\":\"better\",\"confidence\":0.7,\"rationale\":\"The Story's direct integration of pseudoinverse into exponential integrator is more novel than pseudoinverse guidance (score10: 6.7).\"},\n    {\"paper_id\":\"1YO4EE3SPB\",\"judgement\":\"better\",\"confidence\":0.8,\"rationale\":\"The Story's physics-aware exponential integration for MRI reconstruction is more novel than variational perspective (score10: 5.9).\"},\n    {\"paper_id\":\"OnD9zGAGT0k\",\"judgement\":\"better\",\"confidence\":0.6,\"rationale\":\"The Story's video diffusion approach for MRI reconstruction is more innovative than general posterior sampling (score10: 7.2).\"},\n    {\"paper_id\":\"U3PBITXNG6\",\"judgement\":\"better\",\"confidence\":0.9,\"rationale\":\"The Story's physics-aware exponential integration for MRI reconstruction is more novel than a benchmark paper (score10: 6.5).\"},\n    {\"paper_id\":\"6EUtjXAvmj\",\"judgement\":\"better\",\"confidence\":0.7,\"rationale\":\"The Story's video diffusion approach for MRI reconstruction is more innovative than midpoint guidance (score10: 6.7).\"}\n  ],\n  \"main_gaps\": [\"Limited evaluation on diverse MRI datasets\", \"Lack of comparison with state-of-the-art non-diffusion methods\", \"Missing computational complexity analysis\", \"Limited theoretical justification for using video diffusion models\", \"Potential overfitting to specific MRI sequences\"]\n}\n```", "latency_ms": 62850, "text_truncated": false, "text_len": 2243}}}
{"ts": "2026-01-29T11:24:25.384415+00:00", "run_id": "run_20260129_105111_11134_466119", "type": "llm", "data": {"request": {"model": "Pro/zai-org/GLM-4.7", "url": "https://api.siliconflow.cn/v1/chat/completions", "temperature": 0.0, "max_tokens": 800, "timeout": 180, "prompt": "\nYou are a strict reviewer (Storyteller) for top-tier ML/NLP conferences.\nYou must NOT output a direct score. Only compare the Story against anchor papers with real review scores.\n\nAnchors (score10 comes from real review statistics):\n- paper_id: 66arKkGiFy | title: Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models | score10: 5.9\n- paper_id: d7pr2doXn3 | title: Hybrid Regularization Improves Diffusion-based Inverse Problem Solving | score10: 6.0\n- paper_id: t9l63huPRt | title: Lightning-Fast Image Inversion and Editing for Text-to-Image Diffusion Models | score10: 6.3\n- paper_id: TtUh0TOlGX | title: Regularization by Texts for Latent Diffusion Inverse Solvers | score10: 6.5\n- paper_id: 9_gsMA8MRKQ | title: Pseudoinverse-Guided Diffusion Models for Inverse Problems | score10: 6.7\n- paper_id: 1YO4EE3SPB | title: A Variational Perspective on Solving Inverse Problems with Diffusion Models | score10: 5.9\n- paper_id: OnD9zGAGT0k | title: Diffusion Posterior Sampling for General Noisy Inverse Problems | score10: 7.2\n- paper_id: U3PBITXNG6 | title: InverseBench: Benchmarking Plug-and-Play Diffusion Priors for Inverse Problems in Physical Sciences | score10: 6.5\n- paper_id: 6EUtjXAvmj | title: Variational Diffusion Posterior Sampling with Midpoint Guidance | score10: 6.7\n\nStory:\nTitle: Autoregressive Image Diffusion via Physics-Trajectory Synchronization for Zero-Shot MRI Reconstruction\nAbstract: We propose Autoregressive Image Diffusion (AID), a novel framework for image sequence generation that achieves high-fidelity accelerated MRI reconstruction by sampling the posterior distribution through zero-shot physics-trajectory synchronization. Traditional approaches treat reconstruction as a static inverse problem or require task-specific training, failing to leverage the rich temporal dynamics of pre-trained video priors. We reframe the challenge as aligning the generative trajectory of a video diffusion model with the physical constraints of MRI acquisition in real-time. To achieve this, we introduce the Physics-Aware Exponential Integrator, a mechanism that integrates the MRI pseudo-inverse directly into the kernel of the Diffusion Exponential Integrator Sampler (DEIS). By leveraging the semilinear structure of the diffusion ODE, this structural integration transforms the sampling process from a stochastic walk guided by external gradients into a deterministic trajectory alignment. This allows the model to analytically correct its path to satisfy k-space measurements without fine-tuning, preserving temporal coherence while drastically reducing neural function evaluations.\nProblem: We reframe accelerated MRI reconstruction from a static image restoration task to a dynamic problem of temporal trajectory synchronization. The core challenge lies in bridging the gap between the generic temporal dynamics of pre-trained video diffusion models and the specific acquisition physics of MRI. Unlike traditional methods that learn static mappings, we assume that the temporal consistency learned by universal video models is sufficient to approximate physiological dynamics, but requires precise alignment with MRI physics. This shifts the objective from generating pixel-perfect frames to warping the generative ODE trajectory so that it naturally converges to solutions consistent with undersampled k-space data, effectively treating the reconstruction as a trajectory control problem.\nMethod: Adopt a pre-trained video diffusion model to provide the autoregressive prior, factorizing the joint distribution of image sequences into conditional diffusion steps; Formulate the accelerated MRI reconstruction as a constrained posterior sampling problem where the probability flow ODE is modified to include the MRI physics gradient; Develop a Physics-Aware Exponential Integrator that leverages the semilinear structure of the diffusion process to analytically integrate the pseudo-inverse term into the exponential integration kernel, minimizing discretization error; Perform zero-shot reconstruction by solving the modified ODE using the deterministic sampler, dynamically synchronizing the generative trajectory with k-space measurements without fine-tuning the network weights.\nClaims: Transform accelerated MRI reconstruction from a static inverse problem to a dynamic trajectory synchronization task by aligning the generative time-steps of pre-trained video models with MRI physical constraints., Reframe constraint satisfaction from an external guidance process to an internal structural component by integrating the pseudo-inverse directly into the exponential integrator, enabling zero-shot posterior sampling with drastic efficiency gains and theoretical convergence guarantees., Shift the paradigm of medical imaging from task-specific model training to general-purpose trajectory warping, achieving high-fidelity dynamic MRI reconstruction by inheriting temporal reasoning from universal video priors.\nExperiments: We conduct a comprehensive evaluation on diverse clinical MRI datasets (cardiac and brain) to validate zero-shot generalizability. We compare AID against state-of-the-art diffusion-based MRI reconstruction methods and standard video generation models, measuring PSNR, SSIM, and temporal metrics. Crucially, we include a theoretical analysis section proving the convergence properties of the Physics-Aware Exponential Integrator and provide ablation studies comparing our modified kernel against standard DEIS and other numerical samplers to demonstrate the reduction in function evaluations and improved trajectory stability.\n\nTask:\nFor each anchor, decide whether the Story is better, tie, or worse on Storyteller, and provide confidence (0-1).\nYou must mention the anchor's score10 in the rationale using the format \"score10: X.X\".\nComparisons must include every anchor exactly once.\nEach rationale must be ONE sentence (<=25 words).\n\nOutput JSON ONLY. No markdown, no extra text:\n{\n  \"comparisons\": [\n    {\"paper_id\":\"...\", \"judgement\":\"better|tie|worse\", \"confidence\":0.0-1.0, \"rationale\":\"...score10: X.X...\"}\n  ],\n  \"main_gaps\": [\"gap1\", \"gap2\", \"gap3\"]\n}\n", "simulated": false, "prompt_truncated": false, "prompt_len": 6148}, "response": {"ok": true, "text": "{\n  \"comparisons\": [\n    {\"paper_id\":\"66arKkGiFy\", \"judgement\":\"better\", \"confidence\":0.8, \"rationale\":\"Physics integration more novel than mismatched models, score10: 5.9\"},\n    {\"paper_id\":\"d7pr2doXn3\", \"judgement\":\"better\", \"confidence\":0.8, \"rationale\":\"Trajectory synchronization more innovative than hybrid regularization, score10: 6.0\"},\n    {\"paper_id\":\"t9l63huPRt\", \"judgement\":\"better\", \"confidence\":0.7, \"rationale\":\"MRI physics integration more specialized than image inversion, score10: 6.3\"},\n    {\"paper_id\":\"TtUh0TOlGX\", \"judgement\":\"better\", \"confidence\":0.8, \"rationale\":\"Direct physics integration more sophisticated than text regularization, score10: 6.5\"},\n    {\"paper_id\":\"9_gsMA8MRKQ\", \"judgement\":\"better\", \"confidence\":0.6, \"rationale\":\"Kernel integration more innovative than pseudoinverse guidance, score10: 6.7\"},\n    {\"paper_id\":\"1YO4EE3SPB\", \"judgement\":\"better\", \"confidence\":0.8, \"rationale\":\"Trajectory synchronization more novel than variational perspective, score10: 5.9\"},\n    {\"paper_id\":\"OnD9zGAGT0k\", \"judgement\":\"tie\", \"confidence\":0.5, \"rationale\":\"Both innovative approaches to inverse problems, score10: 7.2\"},\n    {\"paper_id\":\"U3PBITXNG6\", \"judgement\":\"better\", \"confidence\":0.8, \"rationale\":\"Technical contribution more substantial than benchmark paper, score10: 6.5\"},\n    {\"paper_id\":\"6EUtjXAvmj\", \"judgement\":\"better\", \"confidence\":0.6, \"rationale\":\"Physics integration more innovative than midpoint guidance, score10: 6.7\"}\n  ],\n  \"main_gaps\": [\"Limited discussion of computational complexity compared to baselines\", \"Potential scalability issues for high-resolution MRI sequences\", \"Lack of comparison with non-diffusion based state-of-the-art methods\"]\n}", "latency_ms": 247694, "text_truncated": false, "text_len": 1705}}}
