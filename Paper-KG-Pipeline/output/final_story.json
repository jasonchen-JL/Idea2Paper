{
  "title": "Mitigating Text-Dominant Bias in Audio-Text Models via Modality Reliability Routing",
  "abstract": "Current Audio-Text Large Models (ATLMs) suffer from 'Text-Dominant Bias,' where textual semantics override acoustic cues, leading to failures in adversarial scenarios involving sarcasm or misleading content. We address this by reframing robust emotion recognition as a problem of dynamic Modality Reliability assessment. We introduce a lightweight routing framework that quantifies 'Text Interference' using audio energy and temporal evidence. This mechanism trains a gating adapter to dynamically select between a Joint Expert (Audio+Text) and an Audio-only Expert during inference. By routing to the Audio Expert when text reliability is low, our approach effectively mitigates misleading text while maintaining high inference efficiency. Experiments on IEMOCAP and MELD demonstrate superior robustness in faithful, adversarial, and irrelevant settings, alongside significantly reduced computational costs.",
  "problem_framing": "We reframe multimodal emotion recognition from a static semantic aggregation task to a dynamic Modality Reliability assessment challenge. Traditional approaches assume consistent input modalities, failing to account for 'Text-Dominant Bias' where textual content misleadingly dominates acoustic cues. This perspective shifts the focus from designing complex fusion layers to developing intelligent routing mechanisms that can identify and suppress unreliable textual interference, ensuring robustness in real-world scenarios involving sarcasm or conflicting information.",
  "gap_pattern": "Existing Audio-Text Large Models fail to address Text-Dominant Bias because they rely on static fusion mechanisms that treat all modalities as equally trustworthy regardless of context. These methods lack a mechanism to quantify 'Text Interference,' leading to performance degradation in adversarial settings where text contradicts audio. Furthermore, attempting to fix this through heavy ensemble fusion often ignores the critical constraint of inference efficiency. Current solutions do not reframe the problem as one of conditional routing based on evidence-based reliability, resulting in systems that are both computationally expensive and brittle to misleading inputs.",
  "solution": "We propose a Modality Reliability Routing framework designed to overcome Text-Dominant Bias through efficient expert selection. Drawing inspiration from efficiency-focused synthesis, we construct 'Text Interference' representations derived from audio energy and temporal evidence to quantify the trustworthiness of the textual modality. This evidence feeds a lightweight gating adapter that learns to weigh modality importance dynamically. During inference, the system employs a dynamic routing strategy: it selects a Joint Expert when modalities align (Faithful) but switches to an Audio-only Expert when text interference is detected (Adversarial/Irrelevant). This approach transforms the fusion process into a conditional decision, optimizing for both robustness against misleading text and computational efficiency.",
  "method_skeleton": "Construct 'Text Interference' representations utilizing audio energy and temporal evidence to quantify modality reliability; Train a lightweight gating adapter to learn modality weights based on the calculated interference levels, ensuring minimal parameter increase; Implement a dynamic routing strategy during inference to switch between a 'Joint Expert' and an 'Audio-only Expert' depending on the reliability score.",
  "innovation_claims": [
    "Transform the mitigation of Text-Dominant Bias in Audio-Text Large Models from static fusion to a dynamic Modality Reliability Routing paradigm, enabling the system to identify and bypass misleading textual information.",
    "Reframe the detection of adversarial inputs as a quantification of 'Text Interference' using audio energy and temporal evidence, allowing for precise, evidence-based modality selection without expensive fine-tuning.",
    "Achieve a balance between robustness and efficiency by introducing a lightweight dynamic routing mechanism that selectively activates experts, significantly reducing inference latency while maintaining high accuracy on adversarial and irrelevant data."
  ],
  "experiments_plan": "Evaluation on IEMOCAP and MELD datasets with constructed adversarial and irrelevant splits. Metrics include Accuracy, F1-score, Inference Latency, and FLOPs. Comparisons against standard Audio-Text LLMs and static fusion baselines. Ablations study the impact of the routing mechanism, the Audio-only expert, and computational cost."
}