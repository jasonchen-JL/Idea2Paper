{
  "user_idea": "我们研究音频-文本大模型的文本主导偏见：在 faithful/adversarial/irrelevant 三类设定下，提出基于模态可信度的路由/融合框架。通过构造“文本干扰”表示能量与时序证据，训练轻量门控/适配器，在推理时选择 Joint 或 Audio 专家，实现对抗文本误导下的稳健情绪识别",
  "success": true,
  "iterations": 1,
  "selected_patterns": {
    "stability": [
      "pattern_57",
      "pattern_51",
      "pattern_45",
      "pattern_59",
      "pattern_114"
    ],
    "novelty": [
      "pattern_7",
      "pattern_58",
      "pattern_114",
      "pattern_66",
      "pattern_8"
    ],
    "domain_distance": [
      "pattern_7",
      "pattern_51",
      "pattern_58",
      "pattern_114",
      "pattern_8"
    ]
  },
  "final_story": {
    "title": "Overcoming Text-Dominant Bias via Modality Reliability-based Dynamic Routing",
    "abstract": "Audio-text large models frequently exhibit text-dominant bias, where textual semantics override acoustic evidence, leading to failures in adversarial or irrelevant settings. We propose a novel framework centered on Modality Reliability to mitigate this bias and achieve robust sentiment recognition. By constructing fine-grained Text Interference representations that quantify energy and temporal mismatches, we train lightweight gating adapters to assess modality trustworthiness. This mechanism enables Dynamic Routing, automatically selecting either a Joint or Audio expert during inference. Our approach transforms the fusion process from static aggregation to adaptive reliability assessment, ensuring the model remains faithful to acoustic cues when text is misleading.",
    "problem_framing": "We reframe the challenge of multimodal sentiment analysis from static feature fusion to a dynamic reliability assessment problem. Current models struggle because they implicitly assume text is the dominant truth-teller, leading to systematic failures in adversarial settings where textual content contradicts acoustic reality. Our approach transforms this perspective by treating modality selection as a function of measured reliability, rather than relying on fixed architectural priors that inevitably favor text.",
    "gap_pattern": "Existing fusion methods for audio-text models fail to address text-dominant bias because they lack fine-grained mechanisms to detect 'text interference.' They rely on indiscriminate attention or concatenation, assuming uniform reliability across faithful, adversarial, and irrelevant contexts. This paradigm fails to distinguish between helpful text and misleading signals, resulting in models that are easily hijacked by textual content, rendering the audio modality effectively dormant in critical inference scenarios.",
    "solution": "We introduce a Modality Reliability-based Routing framework that shifts the paradigm from passive fusion to active expert selection. By implementing fine-grained Text Interference signals—derived from energy and temporal evidence—we calculate a dynamic reliability score for the textual modality. This score drives a constrained gating mechanism that routes inputs to a Joint expert when modalities are consistent, or an Audio expert when text interference is detected. This ensures that acoustic evidence acts as a robust anchor, preventing the model from being misled by adversarial text.",
    "method_skeleton": "Construct Text Interference Representations by calculating energy and temporal evidence mismatches between audio and text streams to quantify local modality reliability; Train a Lightweight Gating Adapter using a constrained optimization objective that learns to map interference signals to routing weights; Implement a Dynamic Routing Mechanism at inference that selects the Joint or Audio expert based on the thresholded reliability score from the adapter.",
    "innovation_claims": [
      "Transform multimodal fusion from static aggregation to adaptive routing by quantifying text interference, enabling the model to dynamically suppress misleading text in favor of audio evidence.",
      "Shift sentiment recognition from text-reliant to reliability-aware processing by introducing energy-based modality scoring, ensuring robustness across faithful, adversarial, and irrelevant settings.",
      "Reframe the handling of irrelevant text from noise filtering to expert-based selection, utilizing lightweight adapters to switch between integrated and audio-only processing without sacrificing model capacity."
    ],
    "experiments_plan": "We evaluate on standard multimodal sentiment datasets (e.g., MOSI, IEMOCAP) restructured into faithful, adversarial, and irrelevant splits. We compare accuracy and robustness against state-of-the-art fusion baselines to demonstrate the effectiveness of our reliability-based routing."
  },
  "review_history": [
    {
      "pass": true,
      "avg_score": 7.013333333333228,
      "reviews": [
        {
          "reviewer": "Reviewer A",
          "role": "Methodology",
          "score": 6.359999999999908,
          "feedback": "Main gaps: Limited evaluation on only two datasets, Lack of comparison with recent state-of-the-art methods, Potential overfitting to specific types of text-dominant bias. Anchored against 7 papers."
        },
        {
          "reviewer": "Reviewer B",
          "role": "Novelty",
          "score": 7.7399999999998785,
          "feedback": "Main gaps: Limited theoretical justification for the reliability metric, Potential scalability concerns with dynamic routing in larger models, Lack of analysis on computational overhead of the proposed approach. Anchored against 7 papers."
        },
        {
          "reviewer": "Reviewer C",
          "role": "Storyteller",
          "score": 6.939999999999896,
          "feedback": "Main gaps: Limited evaluation on diverse multimodal tasks, Scalability concerns for larger models, Lack of theoretical analysis. Anchored against 7 papers."
        }
      ],
      "main_issue": "stability",
      "suggestions": [
        "从stability维度选择稳健Pattern",
        "注入成熟方法增强鲁棒性"
      ],
      "audit": {
        "pattern_id": "pattern_57",
        "anchors": [
          {
            "paper_id": "ULGbw2URE3",
            "title": "L3Ms — Lagrange Large Language Models",
            "pattern_id": "pattern_57",
            "score10": 5.859999999999999,
            "review_count": 5,
            "dispersion10": 1.08,
            "weight": 0.8614228217442572
          },
          {
            "paper_id": "FJWT0692hw",
            "title": "SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling with Backtracking",
            "pattern_id": "pattern_57",
            "score10": 6.004,
            "review_count": 5,
            "dispersion10": 0.7200000000000006,
            "weight": 1.0417206216442176
          },
          {
            "paper_id": "0tAXMiSufG",
            "title": "BOND: Aligning LLMs with Best-of-N Distillation",
            "pattern_id": "pattern_57",
            "score10": 6.13,
            "review_count": 6,
            "dispersion10": 0.9000000000000008,
            "weight": 1.0241632363449014
          },
          {
            "paper_id": "oF6e2WwxX0",
            "title": "TIS-DPO: Token-level Importance Sampling for Direct Preference Optimization With Estimated Weights",
            "pattern_id": "pattern_57",
            "score10": 6.327999999999999,
            "review_count": 5,
            "dispersion10": 1.7999999999999996,
            "weight": 0.6399140961528769
          },
          {
            "paper_id": "d94x0gWTUX",
            "title": "Tool-Augmented Reward Modeling",
            "pattern_id": "pattern_57",
            "score10": 6.49,
            "review_count": 4,
            "dispersion10": 0.9000000000000008,
            "weight": 0.8470725854916313
          },
          {
            "paper_id": "QEHrmQPBdd",
            "title": "RM-Bench: Benchmarking Reward Models of Language Models with Subtlety and Style",
            "pattern_id": "pattern_57",
            "score10": 6.715,
            "review_count": 4,
            "dispersion10": 0.18000000000000016,
            "weight": 1.3639304342661864
          },
          {
            "paper_id": "LNLjU5C5dK",
            "title": "Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment",
            "pattern_id": "pattern_57",
            "score10": 6.183999999999999,
            "review_count": 5,
            "dispersion10": 0.9000000000000008,
            "weight": 0.9430312995937128
          }
        ],
        "role_details": {
          "Methodology": {
            "comparisons": [
              {
                "paper_id": "ULGbw2URE3",
                "judgement": "better",
                "confidence": 0.6,
                "rationale": "Story's dynamic routing is more innovative than L3Ms' Lagrange formulation, score10: 5.9"
              },
              {
                "paper_id": "FJWT0692hw",
                "judgement": "better",
                "confidence": 0.6,
                "rationale": "Story's modality reliability is more novel than SequenceMatch's backtracking, score10: 6.0"
              },
              {
                "paper_id": "0tAXMiSufG",
                "judgement": "better",
                "confidence": 0.6,
                "rationale": "Story's dynamic routing is more innovative than BOND's distillation, score10: 6.1"
              },
              {
                "paper_id": "oF6e2WwxX0",
                "judgement": "tie",
                "confidence": 0.5,
                "rationale": "Both papers introduce novel methodological approaches, score10: 6.3"
              },
              {
                "paper_id": "d94x0gWTUX",
                "judgement": "worse",
                "confidence": 0.6,
                "rationale": "Tool-Augmented Reward Modeling is more rigorous than Story's methodology, score10: 6.5"
              },
              {
                "paper_id": "QEHrmQPBdd",
                "judgement": "worse",
                "confidence": 0.6,
                "rationale": "RM-Bench's benchmarking is more rigorous than Story's methodology, score10: 6.7"
              },
              {
                "paper_id": "LNLjU5C5dK",
                "judgement": "tie",
                "confidence": 0.5,
                "rationale": "Both papers introduce novel methodological approaches, score10: 6.2"
              }
            ],
            "main_gaps": [
              "Limited evaluation on only two datasets",
              "Lack of comparison with recent state-of-the-art methods",
              "Potential overfitting to specific types of text-dominant bias",
              "Limited analysis of the dynamic routing mechanism",
              "Lack of computational efficiency analysis"
            ],
            "score": 6.359999999999908,
            "loss": 0.16823557117266907,
            "avg_confidence": 0.5714285714285714,
            "monotonic_violations": 0
          },
          "Novelty": {
            "comparisons": [
              {
                "paper_id": "ULGbw2URE3",
                "judgement": "better",
                "confidence": 0.8,
                "rationale": "Dynamic routing for modality reliability is more novel than applying Lagrangian methods to LLMs. score10: 5.9"
              },
              {
                "paper_id": "FJWT0692hw",
                "judgement": "better",
                "confidence": 0.75,
                "rationale": "Novel approach to text-dominant bias surpasses imitation learning with backtracking in innovation. score10: 6.0"
              },
              {
                "paper_id": "0tAXMiSufG",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "Modality reliability-based routing offers more novelty than best-of-N distillation for alignment. score10: 6.1"
              },
              {
                "paper_id": "oF6e2WwxX0",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "Dynamic fusion based on reliability is more innovative than token-level importance sampling for DPO. score10: 6.3"
              },
              {
                "paper_id": "d94x0gWTUX",
                "judgement": "better",
                "confidence": 0.75,
                "rationale": "Novel text interference quantification surpasses tool augmentation of reward models in innovation. score10: 6.5"
              },
              {
                "paper_id": "QEHrmQPBdd",
                "judgement": "better",
                "confidence": 0.8,
                "rationale": "Technical innovation in dynamic routing exceeds benchmarking contribution for reward models. score10: 6.7"
              },
              {
                "paper_id": "LNLjU5C5dK",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "Reliability-based dynamic routing is more novel than leveraging fine-grained quality signals. score10: 6.2"
              }
            ],
            "main_gaps": [
              "Limited theoretical justification for the reliability metric",
              "Potential scalability concerns with dynamic routing in larger models",
              "Lack of analysis on computational overhead of the proposed approach"
            ],
            "score": 7.7399999999998785,
            "loss": 0.02155020169102061,
            "avg_confidence": 0.7428571428571429,
            "monotonic_violations": 0
          },
          "Storyteller": {
            "comparisons": [
              {
                "paper_id": "ULGbw2URE3",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "Story's dynamic routing for multimodal bias is more innovative than L3Ms' constraints, score10: 5.9"
              },
              {
                "paper_id": "FJWT0692hw",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "Story's targeted solution for text-dominant bias is more impactful than sequence modeling, score10: 6.0"
              },
              {
                "paper_id": "0tAXMiSufG",
                "judgement": "better",
                "confidence": 0.6,
                "rationale": "Story's adaptive multimodal fusion is more novel than distillation techniques, score10: 6.1"
              },
              {
                "paper_id": "oF6e2WwxX0",
                "judgement": "tie",
                "confidence": 0.5,
                "rationale": "Both papers address specific problems with innovative approaches, score10: 6.3"
              },
              {
                "paper_id": "d94x0gWTUX",
                "judgement": "tie",
                "confidence": 0.5,
                "rationale": "Both papers introduce novel mechanisms for their domains, score10: 6.5"
              },
              {
                "paper_id": "QEHrmQPBdd",
                "judgement": "better",
                "confidence": 0.6,
                "rationale": "Story's solution to text-dominant bias is more innovative than benchmarking, score10: 6.7"
              },
              {
                "paper_id": "LNLjU5C5dK",
                "judgement": "tie",
                "confidence": 0.5,
                "rationale": "Both papers address important problems with novel approaches, score10: 6.2"
              }
            ],
            "main_gaps": [
              "Limited evaluation on diverse multimodal tasks",
              "Scalability concerns for larger models",
              "Lack of theoretical analysis"
            ],
            "score": 6.939999999999896,
            "loss": 0.1397930148721958,
            "avg_confidence": 0.5857142857142856,
            "monotonic_violations": 1
          }
        },
        "anchors_rounds": [
          [
            {
              "paper_id": "ULGbw2URE3",
              "title": "L3Ms — Lagrange Large Language Models",
              "pattern_id": "pattern_57",
              "score10": 5.859999999999999,
              "review_count": 5,
              "dispersion10": 1.08,
              "weight": 0.8614228217442572
            },
            {
              "paper_id": "FJWT0692hw",
              "title": "SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling with Backtracking",
              "pattern_id": "pattern_57",
              "score10": 6.004,
              "review_count": 5,
              "dispersion10": 0.7200000000000006,
              "weight": 1.0417206216442176
            },
            {
              "paper_id": "0tAXMiSufG",
              "title": "BOND: Aligning LLMs with Best-of-N Distillation",
              "pattern_id": "pattern_57",
              "score10": 6.13,
              "review_count": 6,
              "dispersion10": 0.9000000000000008,
              "weight": 1.0241632363449014
            },
            {
              "paper_id": "oF6e2WwxX0",
              "title": "TIS-DPO: Token-level Importance Sampling for Direct Preference Optimization With Estimated Weights",
              "pattern_id": "pattern_57",
              "score10": 6.327999999999999,
              "review_count": 5,
              "dispersion10": 1.7999999999999996,
              "weight": 0.6399140961528769
            },
            {
              "paper_id": "d94x0gWTUX",
              "title": "Tool-Augmented Reward Modeling",
              "pattern_id": "pattern_57",
              "score10": 6.49,
              "review_count": 4,
              "dispersion10": 0.9000000000000008,
              "weight": 0.8470725854916313
            },
            {
              "paper_id": "QEHrmQPBdd",
              "title": "RM-Bench: Benchmarking Reward Models of Language Models with Subtlety and Style",
              "pattern_id": "pattern_57",
              "score10": 6.715,
              "review_count": 4,
              "dispersion10": 0.18000000000000016,
              "weight": 1.3639304342661864
            },
            {
              "paper_id": "LNLjU5C5dK",
              "title": "Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment",
              "pattern_id": "pattern_57",
              "score10": 6.183999999999999,
              "review_count": 5,
              "dispersion10": 0.9000000000000008,
              "weight": 0.9430312995937128
            }
          ]
        ],
        "pass": {
          "mode": "two_of_three_q75_and_avg_ge_q50",
          "used_distribution": "pattern",
          "pattern_paper_count": 111,
          "q50": 6.13,
          "q75": 6.327999999999999,
          "count_roles_ge_q75": 3,
          "roles_ge_q75": {
            "Methodology": true,
            "Novelty": true,
            "Storyteller": true
          },
          "avg_ge_q50": true,
          "avg_score": 7.013333333333228
        }
      }
    }
  ],
  "results_dir": "results/run_20260202_055504_6507_531158",
  "novelty_report": {
    "run_id": "run_20260202_055504_6507_531158",
    "created_at": "2026-02-02T07:44:06.837886+00:00",
    "user_idea": "我们研究音频-文本大模型的文本主导偏见：在 faithful/adversarial/irrelevant 三类设定下，提出基于模态可信度的路由/融合框架。通过构造“文本干扰”表示能量与时序证据，训练轻量门控/适配器，在推理时选择 Joint 或 Audio 专家，实现对抗文本误导下的稳健情绪识别",
    "embedding_available": true,
    "embedding_model": "Qwen/Qwen3-Embedding-8B",
    "top_k": 100,
    "thresholds": {
      "high": 0.88,
      "medium": 0.82
    },
    "risk_level": "low",
    "max_similarity": 0.5963850021362305,
    "candidates": [
      {
        "paper_id": "TPZRq4FALB",
        "title": "Test-time Adaptation against Multi-modal Reliability Bias",
        "pattern_id": "",
        "domain": "Machine Learning",
        "text_hash": "85ecbb7da83a1aaae886311195041898f0bd5a40aeffc5097b95fc79d213ed50",
        "cosine": 0.5963850021362305,
        "keyword_overlap": 0.08108108108108109
      },
      {
        "paper_id": "ePJrZLIqpV",
        "title": "Rethinking Audio-Visual Adversarial Vulnerability from Temporal and Modality Perspectives",
        "pattern_id": "",
        "domain": "Machine Learning",
        "text_hash": "d3f943cf44bf7e970363fa0aedc8716afdd67cc46e915d54ff2861ebe664249d",
        "cosine": 0.5668509602546692,
        "keyword_overlap": 0.07894736842105263
      },
      {
        "paper_id": "AV7OXVlAyi",
        "title": "Mitigating Modality Prior-Induced Hallucinations in Multimodal Large Language Models via Deciphering Attention Causality",
        "pattern_id": "pattern_13",
        "domain": "Machine Learning",
        "text_hash": "2b00d0adacffa9b4b76e94a68ebe21328497754c613a608494520d4cccc2d32e",
        "cosine": 0.5544014573097229,
        "keyword_overlap": 0.11372549019607843
      },
      {
        "paper_id": "vtT09dYPGI",
        "title": "Routing Experts: Learning to Route Dynamic Experts in Existing Multi-modal Large Language Models",
        "pattern_id": "pattern_74",
        "domain": "Machine Learning",
        "text_hash": "59b22728a0b85817d085cc72b342dae6e768ff39578b9a159327d2d8445e6d8c",
        "cosine": 0.5399153232574463,
        "keyword_overlap": 0.11969111969111969
      },
      {
        "paper_id": "l60EM8md3t",
        "title": "Revisiting Deep Audio-Text Retrieval Through the Lens of Transportation",
        "pattern_id": "",
        "domain": "Machine Learning",
        "text_hash": "283fd505312f835e0c070c65fdd13e3d83bcd45f433e9e03aed7bb9a3e4e5108",
        "cosine": 0.5366950035095215,
        "keyword_overlap": 0.08235294117647059
      },
      {
        "paper_id": "1SYUKPeM12",
        "title": "Aligned Better, Listen Better for Audio-Visual Large Language Models",
        "pattern_id": "pattern_13",
        "domain": "Machine Learning",
        "text_hash": "e80f050a72eb521e9a39c1ad0e8bf7d83712f9be0580d5b59057d0d81b9fcc27",
        "cosine": 0.5312134027481079,
        "keyword_overlap": 0.1
      },
      {
        "paper_id": "74vnDs1R97",
        "title": "Wayward Concepts In Multimodal Models",
        "pattern_id": "pattern_51",
        "domain": "Machine Learning",
        "text_hash": "e3575cced82c01c31692bb5ad0e1b47a531a5a79bf5f4da6c81d24b34c00224a",
        "cosine": 0.5265761613845825,
        "keyword_overlap": 0.08300395256916997
      },
      {
        "paper_id": "H-T3F0dMbyj",
        "title": "CLIPSep: Learning Text-queried Sound Separation with Noisy Unlabeled Videos",
        "pattern_id": "pattern_7",
        "domain": "Machine Learning",
        "text_hash": "eb4f5bb7908e3c70f31e81e249b34175823164cc723accd9cda3bcc4ffcfb121",
        "cosine": 0.5243499279022217,
        "keyword_overlap": 0.09019607843137255
      },
      {
        "paper_id": "vbmSSIhKAM",
        "title": "VoxDialogue: Can Spoken Dialogue Systems Understand Information Beyond Words?",
        "pattern_id": "pattern_58",
        "domain": "Natural Language Processing",
        "text_hash": "7774ff496e604d63f22e6484690265ff5fec1017bc86a0ca9d5a457451c90865",
        "cosine": 0.5201357007026672,
        "keyword_overlap": 0.07434944237918216
      },
      {
        "paper_id": "QsA3YzNUxA",
        "title": "Is Your Multimodal Language Model Oversensitive to Safe Queries?",
        "pattern_id": "",
        "domain": "Natural Language Processing",
        "text_hash": "64df7fdc506738da7e13192c30d071f24d3a5f4fdaf1fc1a5f01969049bba016",
        "cosine": 0.5149638056755066,
        "keyword_overlap": 0.08396946564885496
      }
    ],
    "notes": [
      "index_reused"
    ],
    "report_path": "results/run_20260202_055504_6507_531158/novelty_report.json",
    "pivot_attempts": 0,
    "action": "pivot"
  },
  "recall_audit": {
    "final_top_k": [
      {
        "pattern_id": "pattern_7",
        "name": "Reframing Audio Understanding Through Multimodal and Probabilistic Learning",
        "final_score": 2.474976572969851,
        "path1_score": 1.7213249039064422,
        "path2_score": 0.0,
        "path3_score": 0.7536516690634086,
        "cluster_size": 41
      },
      {
        "pattern_id": "pattern_58",
        "name": "Reframing Dialogue System Challenges",
        "final_score": 0.5128803872894196,
        "path1_score": 0.4400013396156977,
        "path2_score": 0.0,
        "path3_score": 0.07287904767372198,
        "cluster_size": 17
      },
      {
        "pattern_id": "pattern_57",
        "name": "Preference Alignment Through Distributional Modeling",
        "final_score": 0.30065407269232813,
        "path1_score": 0.21875833134011288,
        "path2_score": 0.0,
        "path3_score": 0.08189574135221524,
        "cluster_size": 111
      },
      {
        "pattern_id": "pattern_114",
        "name": "Reframing Video Generation Challenges",
        "final_score": 0.2854420301220971,
        "path1_score": 0.20265463607399292,
        "path2_score": 0.0,
        "path3_score": 0.08278739404810422,
        "cluster_size": 44
      },
      {
        "pattern_id": "pattern_8",
        "name": "Reframing Speech Synthesis Efficiency",
        "final_score": 0.14661099612023606,
        "path1_score": 0.0,
        "path2_score": 0.0,
        "path3_score": 0.14661099612023606,
        "cluster_size": 33
      },
      {
        "pattern_id": "pattern_33",
        "name": "Transformer Training Stability Paradigms",
        "final_score": 0.07825587092494557,
        "path1_score": 0.0,
        "path2_score": 0.0,
        "path3_score": 0.07825587092494557,
        "cluster_size": 31
      },
      {
        "pattern_id": "pattern_51",
        "name": "Adversarial Vulnerabilities and Robustness in Large Language Models",
        "final_score": 0.020000000000000004,
        "path1_score": 0.0,
        "path2_score": 0.020000000000000004,
        "path3_score": 0.0,
        "cluster_size": 92
      },
      {
        "pattern_id": "pattern_59",
        "name": "Data driven backdoor attack strategies",
        "final_score": 0.020000000000000004,
        "path1_score": 0.0,
        "path2_score": 0.020000000000000004,
        "path3_score": 0.0,
        "cluster_size": 51
      },
      {
        "pattern_id": "pattern_45",
        "name": "Personalized Privacy Accounting",
        "final_score": 0.020000000000000004,
        "path1_score": 0.0,
        "path2_score": 0.020000000000000004,
        "path3_score": 0.0,
        "cluster_size": 100
      },
      {
        "pattern_id": "pattern_66",
        "name": "Adversarial Transferability Reframing",
        "final_score": 0.016000000000000004,
        "path1_score": 0.0,
        "path2_score": 0.016000000000000004,
        "path3_score": 0.0,
        "cluster_size": 23
      }
    ],
    "path1": {
      "top_ideas": [
        {
          "idea_id": "idea_5431",
          "similarity": 0.5905706019769511,
          "snippet": "Introduce a novel adversarial attack framework, AdvWave, that effectively jailbreaks large audio-language models while maintaining audio stealthiness.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_7273",
          "similarity": 0.5731957830148035,
          "snippet": "Introduce a comprehensive benchmark to evaluate audio understanding models on complex, expert-level tasks across multiple audio domains.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_8256",
          "similarity": 0.5724538131188435,
          "snippet": "Introduce a spatial-aware model to generate controllable and immersive stereo audio from text, leveraging a large-scale multimodal dataset.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_7643",
          "similarity": 0.5698447398804021,
          "snippet": "Introduce a comprehensive framework for generating natural language explanations of audio differences using large language models and novel datasets.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_4641",
          "similarity": 0.5604307295566653,
          "snippet": "Leverage bi-modal semantic similarity to enable weakly-supervised audio separation by using language descriptions as a proxy for single-source audio supervision.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_684",
          "similarity": 0.5575136990165491,
          "snippet": "Integrate contrastive learning with masked data modeling to enhance joint audio-visual representation learning.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_5293",
          "similarity": 0.5505212521821985,
          "snippet": "Introduce a novel evaluation protocol to assess audio foundation models on their ability to handle turn-taking dynamics in conversations.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_6236",
          "similarity": 0.5494820968570456,
          "snippet": "Introduce a benchmark to evaluate spoken dialogue systems' ability to interpret multi-modal audio cues beyond text.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_5355",
          "similarity": 0.5484116226064176,
          "snippet": "Introduce a generative audio model capable of following text instructions and achieving compositional audio transformations through a novel dataset and inference technique.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_5541",
          "similarity": 0.5468958283502822,
          "snippet": "Introduce a natural language-based speech evaluation corpus and an alignment approach to enhance audio LLMs' ability to assess speech quality.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_7438",
          "similarity": 0.5379040598625446,
          "snippet": "Enhance audio classification accuracy by using text-to-audio diffusion models to generate synthetic data aligned with small-scale datasets.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_5968",
          "similarity": 0.5283200253358297,
          "snippet": "Utilize synthetic audio doppelgängers to enhance contrastive learning by generating diverse and causally manipulated audio variations.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_6706",
          "similarity": 0.526478534698108,
          "snippet": "Introduce a cooperative diffusion framework that aligns audio and video generation using a discriminator-guided joint guidance module.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_1972",
          "similarity": 0.5241112130267457,
          "snippet": "Develop an auto-regressive model to generate high-fidelity audio samples conditioned on text inputs, overcoming challenges of source separation and data scarcity.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_5612",
          "similarity": 0.5233202974820639,
          "snippet": "Introduce a self-supervised learning framework, CAV2vec, to enhance audio-visual speech recognition by addressing joint audio-visual corruption.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_8125",
          "similarity": 0.5232739396879981,
          "snippet": "Enhance deepfake audio detection by focusing on high-frequency features through frequency-selective adversarial training.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_2391",
          "similarity": 0.5109695720154371,
          "snippet": "Introduce a method to convert audio sequences into concise discrete tokens for efficient retrieval across various audio types.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_866",
          "similarity": 0.5066365901849823,
          "snippet": "Enable realistic video synthesis from open domain text prompts by leveraging a novel causal model and joint training on image-text and video-text data.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_1496",
          "similarity": 0.4960455156561936,
          "snippet": "Identify vocoder-specific fingerprints in generated audio to enable source attribution in forensic applications.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_5104",
          "similarity": 0.49485337823826037,
          "snippet": "Introduce a joint inference framework for fully unsupervised adaptation of large language and vision-language models, eliminating the need for manual prompt engineering and labeled examples.",
          "pattern_count": 0
        }
      ],
      "pattern_scores_topn": [
        {
          "pattern_id": "pattern_7",
          "score": 1.7213249039064422
        },
        {
          "pattern_id": "pattern_58",
          "score": 0.4400013396156977
        },
        {
          "pattern_id": "pattern_57",
          "score": 0.21875833134011288
        },
        {
          "pattern_id": "pattern_114",
          "score": 0.20265463607399292
        }
      ]
    },
    "path2": {
      "top_domains": [
        {
          "domain_id": "domain_11",
          "name": "Security & Privacy",
          "weight": 1.0,
          "paper_count": 236
        }
      ],
      "pattern_scores_topn": [
        {
          "pattern_id": "pattern_45",
          "score": 0.020000000000000004
        },
        {
          "pattern_id": "pattern_51",
          "score": 0.020000000000000004
        },
        {
          "pattern_id": "pattern_59",
          "score": 0.020000000000000004
        },
        {
          "pattern_id": "pattern_66",
          "score": 0.016000000000000004
        },
        {
          "pattern_id": "pattern_12",
          "score": 0.016000000000000004
        }
      ]
    },
    "path3": {
      "top_papers": [
        {
          "paper_id": "CYK7RfcOzQ4",
          "similarity": 0.5934568778418134,
          "title": "AudioGen: Textually Guided Audio Generation",
          "quality": 0.726,
          "review_count": 5
        },
        {
          "paper_id": "5-Df3tljit7",
          "similarity": 0.5813019642858354,
          "title": "Defending against Adversarial Audio via Diffusion Model",
          "quality": 0.7010000000000001,
          "review_count": 5
        },
        {
          "paper_id": "TeVAZXr3yv",
          "similarity": 0.5988290817956903,
          "title": "MMAU: A Massive Multi-Task Audio Understanding and Reasoning Benchmark",
          "quality": 0.616,
          "review_count": 5
        },
        {
          "paper_id": "l4fMj4Vnly",
          "similarity": 0.5894818969853043,
          "title": "ADIFF: Explaining audio difference using natural language",
          "quality": 0.616,
          "review_count": 5
        },
        {
          "paper_id": "v8Mi8KU6056",
          "similarity": 0.5411520977176486,
          "title": "wav2tok: Deep Sequence Tokenizer for Audio Retrieval",
          "quality": 0.6625000000000001,
          "review_count": 6
        },
        {
          "paper_id": "U42TkrEDzb",
          "similarity": 0.5921703728207518,
          "title": "Audio Large Language Models Can Be Descriptive Speech Quality Evaluators",
          "quality": 0.5880000000000001,
          "review_count": 5
        },
        {
          "paper_id": "qPx3i9sMxv",
          "similarity": 0.5494159698103142,
          "title": "Both Ears Wide Open: Towards Language-Driven Spatial Audio Generation",
          "quality": 0.616,
          "review_count": 5
        },
        {
          "paper_id": "B2Fqu7Y2cd",
          "similarity": 0.5760646573604059,
          "title": "Fugatto 1: Foundational Generative Audio Transformer Opus 1",
          "quality": 0.585,
          "review_count": 4
        },
        {
          "paper_id": "2GcR9bO620",
          "similarity": 0.5651715665881771,
          "title": "I Can Hear You: Selective Robust Training for Deepfake Audio Detection",
          "quality": 0.596,
          "review_count": 5
        },
        {
          "paper_id": "90Db4RUBc7",
          "similarity": 0.5658512579028526,
          "title": "Joint Fine-tuning and Conversion of Pretrained Speech and Language Models towards Linear Complexity",
          "quality": 0.5880000000000001,
          "review_count": 5
        },
        {
          "paper_id": "2e4ECh0ikn",
          "similarity": 0.6023061791216693,
          "title": "Talking Turns: Benchmarking Audio Foundation Models on Turn-Taking Dynamics",
          "quality": 0.5499999999999999,
          "review_count": 6
        },
        {
          "paper_id": "4N97bz1sP6",
          "similarity": 0.5632372384464233,
          "title": "Weakly-supervised Audio Separation via Bi-modal Semantic Similarity",
          "quality": 0.585,
          "review_count": 4
        },
        {
          "paper_id": "agbiPPuSeQ",
          "similarity": 0.5854480892892995,
          "title": "MMDisCo: Multi-Modal Discriminator-Guided Cooperative Diffusion for Joint Audio and Video Generation",
          "quality": 0.5559999999999999,
          "review_count": 5
        },
        {
          "paper_id": "FyMjfDQ9RO",
          "similarity": 0.5448145791483149,
          "title": "Sylber: Syllabic Embedding Representation of Speech from Raw Audio",
          "quality": 0.588,
          "review_count": 5
        },
        {
          "paper_id": "LbEWwJOufy",
          "similarity": 0.4928947690906981,
          "title": "TANGO: Co-Speech Gesture Video Reenactment with Hierarchical Audio Motion Embedding and Diffusion Interpolation",
          "quality": 0.648,
          "review_count": 5
        },
        {
          "paper_id": "yBlVlS2Fd9",
          "similarity": 0.536992182820744,
          "title": "WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling",
          "quality": 0.576,
          "review_count": 5
        },
        {
          "paper_id": "XRtyVELwr6",
          "similarity": 0.5424834309067207,
          "title": "Contrastive Learning from Synthetic Audio Doppelgängers",
          "quality": 0.568,
          "review_count": 5
        },
        {
          "paper_id": "odU59TxdiB",
          "similarity": 0.5133568420691389,
          "title": "SSLAM: Enhancing Self-Supervised Models with Audio Mixtures for Polyphonic Soundscapes",
          "quality": 0.596,
          "review_count": 5
        },
        {
          "paper_id": "bR1J7SpzrD",
          "similarity": 0.5186610814975181,
          "title": "Synthio: Augmenting Small-Scale Audio Classification Datasets with Synthetic Data",
          "quality": 0.588,
          "review_count": 5
        },
        {
          "paper_id": "53T6FlFulCV",
          "similarity": 0.49732941263771097,
          "title": "SoundCount: Sound Counting from Raw Audio with Dyadic Decomposition Neural Network",
          "quality": 0.6075,
          "review_count": 6
        }
      ],
      "pattern_scores_topn": [
        {
          "pattern_id": "pattern_7",
          "score": 0.7536516690634086
        },
        {
          "pattern_id": "pattern_8",
          "score": 0.14661099612023606
        },
        {
          "pattern_id": "pattern_114",
          "score": 0.08278739404810422
        },
        {
          "pattern_id": "pattern_57",
          "score": 0.08189574135221524
        },
        {
          "pattern_id": "pattern_33",
          "score": 0.07825587092494557
        },
        {
          "pattern_id": "pattern_58",
          "score": 0.07287904767372198
        }
      ]
    }
  },
  "review_summary": {
    "total_reviews": 1,
    "final_score": 7.013333333333228
  },
  "refinement_summary": {
    "total_refinements": 0,
    "issues_addressed": []
  },
  "verification_summary": {
    "collision_detected": false,
    "max_similarity": 0.5963850021362305
  }
}